[
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 5,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_61785_[1, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.335211"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 4,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_16205_[1, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]\n7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]\n8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]\n39      0x7f80422f628b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]\n7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]\n8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]\n39      0x7f80422f628b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.556136"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 0,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_72716_[1, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.562302"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 5,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_671_[1, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.568908"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 0,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_91737_[1, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.575161"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 0,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_22663_[1, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.587252"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 3,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_14408_[1, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.625383"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 2,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_78664_[1, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[1, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.662385"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 5,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_62253_[2, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.861200"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 7,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_63314_[2, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]\n7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]\n8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]\n39      0x7fa6a368428b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]\n7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]\n8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]\n39      0x7fa6a368428b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.955674"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 5,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_72358_[4, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[4, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.130252"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 1,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_72698_[2, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]\n7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]\n8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]\n39      0x7f36e3e1528b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]\n7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]\n8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]\n39      0x7f36e3e1528b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.031066"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 0,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_40256_[2, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.959509"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 3,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_22625_[2, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.639595"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 2,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_41382_[2, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.676727"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 4,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_77934_[4, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[4, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]\n7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]\n8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]\n39      0x7f80422f628b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]\n7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]\n8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]\n39      0x7f80422f628b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.178315"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 7,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_98738_[8, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[8, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]\n7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]\n8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]\n39      0x7fa6a368428b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]\n7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]\n8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]\n39      0x7fa6a368428b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.390797"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 5,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_47291_[8, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[8, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.397836"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 6,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_92505_[16, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[16, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]\n7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]\n8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]\n39      0x7f337fc4e28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]\n7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]\n8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]\n39      0x7f337fc4e28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.757976"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 1,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_30353_[4, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[4, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]\n7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]\n8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]\n39      0x7f36e3e1528b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]\n7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]\n8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]\n39      0x7f36e3e1528b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.283161"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 0,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_48076_[2, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.971654"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 3,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_75970_[2, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[2, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:22.985744"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 2,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_51442_[4, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[4, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.052120"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 4,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_11140_[4, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[4, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]\n7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]\n8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]\n39      0x7f80422f628b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]\n7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]\n8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]\n25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]\n39      0x7f80422f628b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.190639"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 7,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_31882_[16, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[16, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]\n7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]\n8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]\n39      0x7fa6a368428b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]\n7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]\n8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]\n25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]\n39      0x7fa6a368428b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.614563"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 5,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_25470_[8, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[8, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]\n7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]\n8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]\n25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]\n39      0x7f015f02c28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.411326"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 6,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_98305_[16, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[16, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]\n7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]\n8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]\n39      0x7f337fc4e28b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]\n7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]\n8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]\n25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]\n39      0x7f337fc4e28b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.772070"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 1,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_19884_[8, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[8, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]\n7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]\n8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]\n39      0x7f36e3e1528b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]\n7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]\n8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]\n25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]\n39      0x7f36e3e1528b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.295969"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 0,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_27708_[4, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[4, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]\n7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]\n8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]\n25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]\n39      0x7fdb8aa3728b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.210964"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 3,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_17689_[16, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[16, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]\n7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]\n8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]\n25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]\n39      0x7ff782b1028b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.642984"
  },
  {
    "module": "trtllm.mla_bmm_gen_post",
    "device_id": 2,
    "task_id": "trtllm.mla_bmm_gen_post_run_mla_gen_post_15034_[4, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "task_params": "[4, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt']",
    "error_type": "RuntimeError",
    "error_message": "DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37",
    "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 126, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_mla_bmm.py\", line 140, in run_mla_gen_post\n    torch.ops.trtllm.fp8_block_scaling_bmm_out(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1158, in __call__\n    return self._op(*args, **(kwargs or {}))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)\n1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770\n2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229\n3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121\n4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157\n5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120\n6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]\n7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]\n8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239\n9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553\n10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n12            0x58208f /usr/bin/python() [0x58208f]\n13            0x54b30c PyObject_Call + 108\n14            0x5db55b _PyEval_EvalFrameDefault + 19483\n15            0x54a9d2 _PyObject_Call_Prepend + 194\n16            0x5a3628 /usr/bin/python() [0x5a3628]\n17            0x54b30c PyObject_Call + 108\n18            0x5db55b _PyEval_EvalFrameDefault + 19483\n19            0x54cccd /usr/bin/python() [0x54cccd]\n20            0x54a4ca PyObject_CallMethod + 330\n21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071\n22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994\n23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352\n24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]\n25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]\n26            0x58208f /usr/bin/python() [0x58208f]\n27            0x54b30c PyObject_Call + 108\n28            0x5db55b _PyEval_EvalFrameDefault + 19483\n29            0x54a9d2 _PyObject_Call_Prepend + 194\n30            0x5a3628 /usr/bin/python() [0x5a3628]\n31            0x549185 _PyObject_MakeTpCall + 117\n32            0x5d73c9 _PyEval_EvalFrameDefault + 2697\n33            0x5d58eb PyEval_EvalCode + 347\n34            0x608a23 PyRun_StringFlags + 211\n35            0x6b3e9e PyRun_SimpleStringFlags + 62\n36            0x6bcb61 Py_RunMain + 1153\n37            0x6bc57d Py_BytesMain + 45\n38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]\n39      0x7f8cc864928b __libc_start_main + 139\n40            0x657ce5 _start + 37\n",
    "timestamp": "2025-10-04T00:42:23.065101"
  }
]