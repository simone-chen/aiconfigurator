2025-10-04 00:09:40,759|INFO|root|main|Starting collection with 8 GPU processes
2025-10-04 00:09:50,820|INFO|root|collect_trtllm|TensorRT LLM version: 1.0.0
2025-10-04 00:09:50,845|INFO|root|collect_module_safe|Starting collection: trtllm.attention_context
2025-10-04 00:09:50,866|INFO|root|collect_module_safe|Generated 9800 test cases for trtllm.attention_context
2025-10-04 00:09:52,561|INFO|root|start_process|Started worker process 511 on device 0
2025-10-04 00:09:52,563|INFO|root|start_process|Started worker process 512 on device 1
2025-10-04 00:09:52,564|INFO|root|start_process|Started worker process 513 on device 2
2025-10-04 00:09:52,565|INFO|root|start_process|Started worker process 514 on device 3
2025-10-04 00:09:52,565|INFO|root|start_process|Started worker process 515 on device 4
2025-10-04 00:09:52,566|INFO|root|start_process|Started worker process 516 on device 5
2025-10-04 00:09:52,567|INFO|root|start_process|Started worker process 517 on device 6
2025-10-04 00:09:52,568|INFO|root|start_process|Started worker process 518 on device 7
2025-10-04 00:10:04,475|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.attention_context
2025-10-04 00:10:04,872|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.attention_context
2025-10-04 00:10:04,970|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.attention_context
2025-10-04 00:10:05,694|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_context
2025-10-04 00:10:05,737|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.attention_context
2025-10-04 00:10:05,741|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.attention_context
2025-10-04 00:10:05,751|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.attention_context
2025-10-04 00:10:05,854|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.attention_context
2025-10-04 00:10:11,471|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30464_[4, 16384, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:11,670|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87706_[4, 16384, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:11,907|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_98637_[4, 16384, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:14,757|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96684_[2, 16384, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:16,570|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_51476_[8, 16384, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:18,123|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_82106_[8, 16384, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:18,270|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_37673_[2, 16384, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:18,494|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_82144_[8, 16384, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:18,690|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_2703_[8, 16384, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:19,107|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_98022_[4, 16384, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:19,820|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_74211_[2, 16384, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:19,916|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_67417_[1, 16384, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:20,227|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_14404_[1, 16384, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:20,765|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_33823_[1, 16384, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:21,406|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_22631_[2, 16384, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:21,563|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80470_[1, 16384, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:22,232|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_71273_[2, 16384, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:22,446|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_87413_[1, 16384, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:23,730|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77337_[4, 16384, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:26,894|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_67211_[4, 12288, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:27,695|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80064_[4, 12288, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:28,306|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_79112_[8, 12288, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:28,421|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_58017_[4, 12288, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:29,259|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46967_[8, 12288, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:30,441|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_73763_[2, 12288, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:30,522|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96658_[8, 12288, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:30,657|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_23325_[2, 12288, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:31,628|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_55567_[2, 12288, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:31,784|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_52033_[1, 12288, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:32,138|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_912_[4, 12288, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:32,861|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_40430_[1, 12288, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:32,874|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34919_[2, 12288, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:33,007|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_86324_[1, 12288, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:33,403|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95052_[1, 12288, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:34,064|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72531_[1, 12288, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:34,288|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69385_[8, 12288, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:34,654|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_3054_[4, 12288, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:34,956|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_42658_[2, 12288, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:37,837|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_63521_[4, 10240, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:38,278|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_7234_[4, 10240, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:38,653|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_8264_[4, 10240, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:40,018|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_22551_[8, 10240, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:40,828|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_54719_[2, 10240, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:40,969|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_13441_[8, 10240, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:41,030|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_7233_[8, 10240, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:41,884|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_36125_[2, 10240, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:42,209|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88753_[8, 10240, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:42,348|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_28073_[4, 10240, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:42,823|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_53611_[1, 10240, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:42,823|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78897_[2, 10240, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:43,091|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_7035_[2, 10240, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:43,207|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_68380_[1, 10240, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:43,332|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83809_[1, 10240, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:43,762|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42940_[2, 10240, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:43,793|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_76633_[1, 10240, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:43,889|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95242_[1, 10240, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:45,178|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_25547_[4, 10240, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:49,354|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50497_[8, 8192, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:49,537|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_55046_[8, 8192, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:51,033|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_73613_[8, 8192, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:54,140|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_37755_[4, 8192, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:54,630|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_89194_[16, 8192, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:55,846|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54613_[16, 8192, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:56,376|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_28453_[16, 8192, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:56,698|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10776_[8, 8192, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:56,853|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94639_[16, 8192, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:57,396|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_58240_[4, 8192, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:57,762|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58396_[4, 8192, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:58,068|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_6889_[4, 8192, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:58,214|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_68944_[2, 8192, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:58,445|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_30195_[2, 8192, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:59,000|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_24478_[1, 8192, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:59,045|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_48434_[2, 8192, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:59,265|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_65947_[1, 8192, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:59,294|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_63037_[4, 8192, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:59,463|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_5951_[2, 8192, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:59,880|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_61538_[1, 8192, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:10:59,927|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14548_[1, 8192, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:00,187|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91476_[1, 8192, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:00,891|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_58378_[2, 8192, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:04,172|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_15721_[8, 8192, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:04,368|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25987_[8, 6144, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:05,112|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_12476_[8, 6144, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:08,565|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_55181_[16, 6144, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:08,987|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_70036_[16, 6144, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:09,052|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_20335_[8, 6144, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:09,380|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_73666_[16, 6144, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:09,741|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63238_[8, 6144, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:10,156|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_17129_[16, 6144, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:10,666|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_16515_[4, 6144, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:11,156|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7031_[4, 6144, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:11,268|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_82560_[2, 6144, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:11,320|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80119_[4, 6144, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:11,837|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_76861_[2, 6144, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:11,946|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_26941_[4, 6144, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:12,120|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22885_[4, 6144, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:12,366|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_80145_[2, 6144, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:12,411|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_47686_[1, 6144, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:12,585|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82309_[1, 6144, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:12,681|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_7764_[2, 6144, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:12,767|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_85239_[1, 6144, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:12,999|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12250_[1, 6144, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:13,103|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_57884_[2, 6144, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:13,112|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_20155_[1, 6144, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:13,306|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74794_[8, 6144, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:18,781|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_14506_[16, 4096, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:18,818|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_32032_[16, 4096, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:19,213|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_94722_[16, 4096, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:21,948|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_26430_[8, 4096, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:24,567|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31361_[32, 4096, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:24,818|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15697_[32, 4096, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:25,271|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97670_[8, 4096, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:25,657|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60181_[16, 4096, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:26,038|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85624_[32, 4096, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:26,128|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93817_[32, 4096, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:27,122|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_49688_[4, 4096, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:27,627|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87488_[4, 4096, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:27,660|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_18864_[8, 4096, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:27,741|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_54284_[8, 4096, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:27,798|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_80720_[4, 4096, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:28,208|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_19669_[8, 4096, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:28,367|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_76099_[2, 4096, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:28,495|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90503_[2, 4096, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:28,597|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37556_[2, 4096, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:28,895|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31810_[1, 4096, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:28,897|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83311_[4, 4096, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:28,991|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_6276_[1, 4096, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:29,114|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12439_[2, 4096, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:29,315|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_51457_[1, 4096, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:29,333|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_16146_[1, 4096, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:29,513|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_60446_[1, 4096, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:29,708|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_9275_[4, 4096, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:29,894|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3340_[2, 4096, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:30,605|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_52407_[16, 4096, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:33,878|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77324_[16, 3072, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:34,288|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27627_[16, 3072, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:34,975|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_10167_[16, 3072, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:37,274|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_90788_[8, 3072, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:37,893|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_40857_[32, 3072, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:38,640|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_16519_[32, 3072, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:39,007|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58827_[32, 3072, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:39,095|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_44096_[16, 3072, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:39,351|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_54029_[32, 3072, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:39,596|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99878_[8, 3072, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:40,192|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_96677_[8, 3072, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:40,201|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54554_[4, 3072, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:40,449|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_1860_[4, 3072, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:40,782|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_72579_[4, 3072, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:40,952|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_65855_[8, 3072, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,074|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10839_[2, 3072, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,144|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75158_[8, 3072, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,342|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_18672_[2, 3072, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,525|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29186_[4, 3072, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,540|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62709_[2, 3072, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,636|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42921_[1, 3072, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,719|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_84242_[2, 3072, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,830|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62114_[1, 3072, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,860|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_66047_[1, 3072, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,921|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_39107_[2, 3072, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:41,998|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_35452_[1, 3072, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:42,092|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_56770_[1, 3072, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:42,429|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_60055_[4, 3072, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:42,858|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_12767_[16, 3072, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:47,631|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11063_[32, 2048, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:48,043|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85713_[32, 2048, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:48,688|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_641_[32, 2048, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:51,416|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37755_[16, 2048, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:53,497|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_91236_[64, 2048, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:53,622|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_96908_[64, 2048, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:54,292|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_70135_[32, 2048, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:54,680|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53033_[64, 2048, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:54,742|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25001_[16, 2048, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:55,424|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_84112_[64, 2048, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:56,167|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_94265_[8, 2048, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:56,175|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91913_[8, 2048, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:56,590|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_39256_[16, 2048, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:56,725|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_49901_[16, 2048, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,054|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_16606_[16, 2048, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,079|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_87680_[8, 2048, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,324|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_57284_[4, 2048, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,453|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_750_[4, 2048, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,858|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_5634_[4, 2048, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,880|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_67027_[2, 2048, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,936|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_19206_[8, 2048, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:57,961|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_26714_[4, 2048, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,364|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35326_[2, 2048, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,404|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87269_[2, 2048, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,463|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_17765_[4, 2048, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,478|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_17132_[2, 2048, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,522|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_65319_[2, 2048, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,567|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_17605_[1, 2048, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,628|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_23085_[1, 2048, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,660|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63207_[1, 2048, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,692|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39164_[1, 2048, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,723|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_28915_[1, 2048, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:58,861|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78274_[8, 2048, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:11:59,193|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19985_[32, 2048, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:02,803|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_73179_[32, 1536, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:03,089|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_80582_[32, 1536, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:03,527|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60513_[32, 1536, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:05,584|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40987_[16, 1536, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:07,035|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76146_[64, 1536, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:07,816|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42296_[64, 1536, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:07,884|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_87594_[16, 1536, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:07,927|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_72003_[32, 1536, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:08,582|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97038_[64, 1536, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:08,612|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21233_[64, 1536, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:09,058|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_63525_[8, 1536, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:09,429|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_25487_[16, 1536, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:09,528|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49354_[16, 1536, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:09,751|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14258_[8, 1536, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:09,870|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_95491_[8, 1536, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,125|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_89149_[4, 1536, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,349|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_53640_[4, 1536, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,363|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34738_[16, 1536, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,378|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46968_[8, 1536, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,478|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35879_[4, 1536, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,661|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34284_[2, 1536, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,684|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_64993_[2, 1536, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,817|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_3335_[2, 1536, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,821|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39427_[4, 1536, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,965|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_83549_[1, 1536, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,975|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_91268_[1, 1536, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:10,995|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_52431_[8, 1536, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:11,013|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74283_[2, 1536, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:11,137|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_48242_[1, 1536, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:11,144|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80356_[1, 1536, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:11,145|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47113_[4, 1536, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:11,158|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_6163_[1, 1536, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:11,234|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_75358_[2, 1536, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:13,531|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_13746_[32, 1536, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:17,018|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33624_[64, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:17,098|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_21072_[64, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:19,321|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24633_[64, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:22,420|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_87938_[32, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:22,742|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_20238_[128, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:22,878|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_95188_[128, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:23,766|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_67130_[64, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:24,123|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_94819_[128, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:25,315|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69470_[32, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:25,578|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79201_[32, 1024, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:25,716|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_3920_[128, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:25,726|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_11100_[16, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:25,944|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82230_[32, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:26,187|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_15310_[32, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:26,667|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29425_[8, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:26,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_55499_[16, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:26,947|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61438_[8, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,228|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57577_[16, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,466|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_77240_[16, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,527|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_98772_[8, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,613|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_56373_[4, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,747|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_40542_[8, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,869|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84941_[4, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,962|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_98335_[4, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:27,967|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_29646_[8, 1024, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,099|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_49014_[4, 1024, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,104|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_39233_[2, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,126|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42633_[4, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,190|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_6505_[2, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,219|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_25206_[64, 1024, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,230|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_11008_[1, 1024, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,237|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_28303_[2, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,286|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_63138_[16, 1024, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,304|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95390_[1, 1024, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,334|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_6733_[2, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,343|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_93508_[1, 1024, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,369|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_40393_[2, 1024, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,374|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_85210_[1, 1024, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:28,419|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12432_[1, 1024, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:34,323|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23327_[128, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:34,488|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99856_[128, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:34,704|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_86706_[128, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:37,404|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72328_[64, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:39,928|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49254_[256, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:40,084|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_24696_[256, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:40,668|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_79257_[64, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:41,013|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81967_[256, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:41,056|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_88459_[128, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:41,463|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12316_[256, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:42,461|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33556_[32, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:42,541|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98864_[32, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:43,034|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92255_[32, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:43,049|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_58430_[64, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:43,477|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_69529_[64, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:43,710|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_60767_[64, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:43,775|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_88755_[16, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:43,820|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29767_[16, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,262|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_96529_[8, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,298|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_80287_[32, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,327|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_73785_[16, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,638|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_91475_[16, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,708|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29166_[8, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,730|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95296_[8, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,755|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21741_[16, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,773|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_17499_[8, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,902|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56967_[8, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,934|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75323_[4, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:44,956|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_67818_[4, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,001|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37304_[4, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,044|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_76118_[2, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,064|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39851_[4, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,068|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_77062_[2, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,120|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_99646_[1, 512, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,126|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86124_[2, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,142|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_34386_[32, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,172|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_88272_[2, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,186|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_68082_[1, 512, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,216|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_9798_[1, 512, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,228|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13061_[1, 512, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,233|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_26661_[2, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,257|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45650_[1, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,296|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57008_[4, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:45,322|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50679_[128, 512, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:48,123|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50786_[128, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:48,335|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69311_[128, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:48,340|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6665_[128, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:49,750|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_8613_[64, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:50,877|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73704_[256, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:50,930|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56366_[256, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:51,329|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_15772_[64, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:51,379|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_30427_[256, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:51,506|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10112_[128, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:51,785|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_26928_[256, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,114|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90206_[32, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,252|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54977_[32, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,402|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29709_[64, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,596|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_89502_[64, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,651|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_77918_[32, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,719|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88469_[64, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,812|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29788_[16, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:52,982|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34205_[16, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,011|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_36521_[32, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,069|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_76238_[16, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,156|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_29883_[16, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,179|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91138_[8, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,209|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69000_[8, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,337|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_89267_[4, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,380|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81261_[8, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,419|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_17896_[8, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,481|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59254_[4, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,496|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_60570_[8, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,504|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37897_[4, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,518|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81404_[16, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,556|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_4376_[2, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,563|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_87513_[4, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,574|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_67025_[4, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,578|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29842_[2, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,588|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_13034_[2, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,611|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_1844_[1, 256, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,650|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_5141_[2, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,653|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87563_[1, 256, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,665|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_72584_[1, 256, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,680|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_96581_[1, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,686|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35773_[2, 256, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,687|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_29793_[32, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,706|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73699_[1, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:53,809|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_77403_[128, 256, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:55,130|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_80845_[128, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:55,162|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_92204_[128, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:55,360|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_98532_[128, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:56,068|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56297_[64, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:56,498|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84499_[256, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:56,612|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_85806_[256, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:56,801|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1506_[256, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:56,840|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7411_[128, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:56,877|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37900_[64, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,040|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21392_[256, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,252|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_17373_[32, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,284|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45000_[32, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,294|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_60001_[64, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,384|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_91975_[64, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,468|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69261_[32, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,478|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63067_[64, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,483|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_30183_[16, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,603|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_32089_[16, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,704|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_82653_[16, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,717|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_52577_[32, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,730|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_6454_[16, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,746|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_89432_[8, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,813|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55357_[8, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,820|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_79294_[8, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,845|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_81584_[8, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,864|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_35484_[8, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,875|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90414_[4, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,880|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25413_[4, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,889|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_24270_[16, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,936|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98554_[2, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,957|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32909_[4, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,965|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60021_[4, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,968|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_39630_[2, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,982|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_86257_[128, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:57,983|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86079_[4, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,023|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_53005_[2, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,028|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94891_[1, 128, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,027|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80090_[32, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,030|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37438_[1, 128, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,038|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37613_[2, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,043|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_82938_[1, 128, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,054|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_87139_[2, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,060|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93112_[1, 128, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,077|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_7687_[1, 128, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,784|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66637_[128, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,806|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28911_[128, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:58,825|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_29152_[128, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,182|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_79989_[64, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,488|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48178_[256, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,594|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_65087_[64, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,596|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_71718_[256, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,670|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_9103_[128, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,745|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_3110_[256, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,753|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95305_[256, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,877|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91487_[32, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,906|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_96645_[64, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,967|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_54427_[32, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,975|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_25561_[64, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:12:59,983|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_30623_[32, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,032|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_15944_[64, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,116|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_84401_[16, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,121|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1952_[16, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,125|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_75800_[16, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,144|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_57437_[32, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,197|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_98864_[16, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,194|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_22210_[8, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,222|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_78217_[16, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,222|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_59707_[8, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,224|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_89625_[32, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,227|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_66255_[128, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,259|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_58058_[8, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,277|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_79025_[4, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,294|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_64167_[4, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,312|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46916_[4, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,311|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59426_[8, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,317|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_87793_[4, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,338|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_25044_[8, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,353|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_93096_[2, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,366|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5415_[1, 64, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,388|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19264_[4, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,391|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78321_[2, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,388|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59977_[2, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,399|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_61955_[2, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,400|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_64854_[2, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,414|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_25064_[1, 64, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,423|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37649_[1, 64, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,435|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_88476_[1, 64, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,440|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69895_[1, 64, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,794|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_3659_[128, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,816|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_69658_[128, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:00,832|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_64934_[128, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,029|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_8913_[64, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,182|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_72111_[256, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,191|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33547_[256, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,241|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54272_[128, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,241|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59368_[256, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,247|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_87951_[256, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,253|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2763_[64, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,363|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10646_[32, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,363|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_68816_[32, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,397|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_17351_[32, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,421|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_21409_[64, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,425|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_21370_[64, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,442|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34552_[64, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,457|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_94545_[16, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,488|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7785_[16, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,523|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_5195_[32, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,531|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76160_[16, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,541|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_91912_[128, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,549|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_47415_[16, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,559|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35775_[16, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,565|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30854_[8, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,585|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_62374_[32, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,598|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21232_[8, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,611|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_17919_[8, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,619|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80308_[8, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,623|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_57824_[4, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,632|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7804_[4, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,633|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_85538_[8, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,644|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_88197_[4, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,660|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_70439_[2, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,662|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85276_[4, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,700|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_42263_[4, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,703|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_27712_[2, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,710|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43868_[1, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,715|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_52589_[2, 32, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,716|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42785_[1, 32, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,722|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31945_[2, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,730|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93614_[1, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,740|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_94801_[2, 32, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,743|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2443_[1, 32, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,755|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_8556_[1, 32, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,941|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96010_[128, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,960|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68017_[128, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:01,977|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_49315_[128, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,096|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_73508_[64, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,131|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_37644_[256, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,144|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_36453_[256, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,163|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_78608_[256, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,181|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99361_[256, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,191|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_35069_[128, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,209|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40883_[64, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,243|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56797_[32, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,275|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53649_[64, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,280|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_64970_[64, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,296|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50919_[64, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,311|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_68259_[32, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,311|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_74320_[32, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,320|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69938_[128, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,331|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_10308_[16, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,352|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_98364_[32, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,374|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_92923_[8, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,376|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_63590_[16, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,387|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_99259_[32, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,391|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_53877_[16, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,398|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_54251_[8, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,412|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69700_[16, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,416|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59864_[16, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,443|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_18219_[8, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,465|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_10719_[4, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,471|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_87361_[4, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,472|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_24862_[4, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,493|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48765_[8, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,496|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_53095_[8, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,497|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_3746_[4, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,498|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_46913_[2, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,503|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_29418_[4, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,509|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_37585_[2, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,524|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93354_[2, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,541|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_56435_[1, 16, 96, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,550|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7106_[1, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,556|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80936_[2, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,556|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_45371_[1, 16, 96, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,557|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_38884_[1, 16, 96, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,564|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_39860_[2, 16, 96, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:02,575|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45507_[1, 16, 96, 96, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:06,461|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_55208_[4, 16384, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:06,584|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_58501_[4, 16384, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:06,655|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77407_[4, 16384, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:08,607|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15778_[2, 16384, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:10,383|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_16791_[8, 16384, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:10,651|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_18707_[8, 16384, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:10,714|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56937_[8, 16384, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:10,735|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_18260_[2, 16384, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:11,739|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20841_[1, 16384, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:12,001|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_76116_[8, 16384, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:12,501|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48323_[4, 16384, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:12,514|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_71472_[2, 16384, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:12,622|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_73489_[2, 16384, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:12,819|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46104_[1, 16384, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:13,047|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_17068_[2, 16384, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:13,083|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_2471_[1, 16384, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:13,563|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41637_[1, 16384, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:13,701|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_22984_[1, 16384, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:14,117|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_71907_[4, 16384, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:16,341|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38197_[4, 12288, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:16,656|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58847_[4, 12288, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:17,208|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62741_[4, 12288, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:18,320|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_1061_[8, 12288, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:18,703|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_962_[8, 12288, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:18,931|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_97334_[2, 12288, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:19,400|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_80252_[8, 12288, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:19,799|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_28190_[2, 12288, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:19,875|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_42185_[4, 12288, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:20,146|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_88346_[8, 12288, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:20,489|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22996_[2, 12288, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:20,544|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_87062_[1, 12288, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:20,704|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_96342_[1, 12288, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:20,740|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_21698_[2, 12288, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:20,981|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_29951_[1, 12288, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:20,990|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_44381_[2, 12288, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:21,394|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66226_[1, 12288, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:21,622|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_23928_[1, 12288, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:22,176|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66844_[4, 12288, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:23,781|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50201_[4, 10240, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:24,051|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_6111_[4, 10240, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:24,742|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40167_[4, 10240, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:25,699|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80081_[8, 10240, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:25,711|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9645_[8, 10240, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:26,113|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_10401_[2, 10240, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:26,141|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_84954_[8, 10240, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:26,844|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_80521_[4, 10240, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:26,954|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_42702_[2, 10240, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,046|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_6868_[2, 10240, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,047|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_67857_[8, 10240, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,460|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13457_[1, 10240, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,596|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80673_[1, 10240, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,641|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_48605_[2, 10240, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,739|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57446_[2, 10240, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,768|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27673_[1, 10240, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,835|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_20175_[1, 10240, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:27,958|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92501_[1, 10240, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:28,380|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_69629_[4, 10240, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:31,582|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_91013_[8, 8192, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:31,879|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_97976_[8, 8192, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:32,464|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_16012_[8, 8192, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:34,292|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37650_[4, 8192, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:35,923|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93028_[16, 8192, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:36,232|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92272_[16, 8192, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:36,544|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_64234_[8, 8192, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:36,552|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_76487_[4, 8192, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:36,600|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6923_[16, 8192, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:37,507|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_88834_[2, 8192, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:37,529|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_90025_[4, 8192, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:37,686|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74777_[2, 8192, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:37,826|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_91544_[16, 8192, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:38,119|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_99331_[4, 8192, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:38,342|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65374_[1, 8192, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:38,682|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_18121_[2, 8192, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:38,689|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86051_[4, 8192, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:38,731|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91171_[1, 8192, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:38,827|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_40514_[2, 8192, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:38,971|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12418_[1, 8192, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:39,280|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_12933_[1, 8192, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:39,309|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_70407_[1, 8192, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:39,320|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_18762_[8, 8192, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:39,418|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40201_[2, 8192, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:42,291|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43946_[8, 6144, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:42,421|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_36677_[8, 6144, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:42,541|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13021_[8, 6144, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:44,261|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_70638_[4, 6144, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:44,726|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_53106_[16, 6144, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:44,846|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55258_[16, 6144, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:45,283|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_88970_[16, 6144, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:45,717|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80417_[4, 6144, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:45,902|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45905_[8, 6144, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:46,229|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97876_[16, 6144, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:46,327|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56757_[4, 6144, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:46,538|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_17846_[2, 6144, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:46,702|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99930_[4, 6144, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:46,722|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_40427_[4, 6144, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:46,770|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_85442_[2, 6144, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,091|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48502_[1, 6144, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,124|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68013_[2, 6144, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,138|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30369_[1, 6144, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,190|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78318_[1, 6144, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,288|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_27269_[2, 6144, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,463|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_31336_[2, 6144, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,601|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56502_[1, 6144, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:47,701|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_93978_[1, 6144, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:48,072|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_87221_[8, 6144, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:51,360|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_15209_[16, 4096, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:51,445|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_66291_[16, 4096, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:52,424|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_88244_[16, 4096, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:54,559|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_65143_[8, 4096, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:54,830|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24951_[32, 4096, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:55,535|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75213_[32, 4096, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:55,940|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_85395_[32, 4096, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:56,066|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40703_[16, 4096, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:56,512|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64315_[8, 4096, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:56,725|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_79268_[32, 4096, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:57,106|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_59096_[8, 4096, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:57,124|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_78666_[4, 4096, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:57,178|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_89002_[8, 4096, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:57,629|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_81759_[4, 4096, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:57,694|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85339_[2, 4096, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:57,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_41796_[4, 4096, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,015|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30262_[8, 4096, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,135|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7957_[2, 4096, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,212|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_81746_[2, 4096, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,391|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46130_[4, 4096, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,479|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40305_[1, 4096, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,499|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72997_[2, 4096, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,501|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_43031_[1, 4096, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,603|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_343_[2, 4096, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,750|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_32042_[1, 4096, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,847|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_18950_[1, 4096, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,856|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_57373_[1, 4096, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:58,880|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10745_[4, 4096, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:13:59,153|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_93188_[16, 4096, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:01,810|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_37583_[16, 3072, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:01,881|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_76425_[16, 3072, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:02,268|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_6297_[16, 3072, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:03,941|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_7081_[8, 3072, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:04,429|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_49664_[32, 3072, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:04,431|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_28961_[32, 3072, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:05,080|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_16281_[32, 3072, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:05,323|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_51870_[16, 3072, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:05,441|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_61552_[8, 3072, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:05,931|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_8888_[32, 3072, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,042|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_20488_[8, 3072, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,166|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_57854_[4, 3072, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,229|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27743_[4, 3072, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,252|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_84444_[8, 3072, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,353|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_58424_[8, 3072, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,596|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67455_[2, 3072, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,649|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_94415_[2, 3072, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,779|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13859_[2, 3072, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:06,809|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41278_[4, 3072, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,016|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85699_[4, 3072, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,038|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95894_[1, 3072, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,072|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_69086_[1, 3072, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,120|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81443_[2, 3072, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,217|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_16924_[1, 3072, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,255|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_64217_[1, 3072, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,265|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59096_[1, 3072, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,358|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_44386_[2, 3072, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,430|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29761_[4, 3072, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:07,519|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_34890_[16, 3072, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:11,150|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_97284_[32, 2048, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:11,288|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_25482_[32, 2048, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:11,632|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_55473_[32, 2048, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:13,886|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57058_[16, 2048, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:14,579|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38730_[64, 2048, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:14,928|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87239_[64, 2048, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:15,869|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_92324_[16, 2048, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:15,989|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3319_[32, 2048, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:16,268|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_88502_[64, 2048, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:16,271|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_76042_[64, 2048, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:16,893|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49286_[16, 2048, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,031|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_53727_[16, 2048, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,091|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_75878_[8, 2048, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,267|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_50757_[8, 2048, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,345|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_64471_[16, 2048, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,434|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99965_[8, 2048, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,595|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_28537_[4, 2048, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,773|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78295_[4, 2048, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:17,907|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81339_[4, 2048, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,075|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_17651_[2, 2048, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,127|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23666_[4, 2048, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,179|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_70802_[8, 2048, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,240|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_73371_[2, 2048, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,379|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58858_[2, 2048, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,392|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99105_[2, 2048, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,393|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54398_[1, 2048, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,456|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19621_[2, 2048, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,513|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56456_[4, 2048, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,527|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_70906_[1, 2048, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,565|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78759_[1, 2048, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,584|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_86254_[1, 2048, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,586|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49526_[1, 2048, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:18,783|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_6285_[32, 2048, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:19,066|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_56385_[8, 2048, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:21,570|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77314_[32, 1536, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:21,861|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_53132_[32, 1536, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:22,254|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30185_[32, 1536, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:23,799|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_53201_[16, 1536, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:24,415|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_66880_[64, 1536, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:24,696|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_29486_[64, 1536, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:24,782|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78739_[64, 1536, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:25,213|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15078_[32, 1536, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:25,520|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_86679_[16, 1536, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:25,848|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_30278_[64, 1536, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:25,943|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_60073_[8, 1536, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:25,968|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_73044_[16, 1536, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,246|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_41825_[16, 1536, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,318|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_67070_[8, 1536, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,456|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_71742_[16, 1536, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,616|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64694_[4, 1536, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,696|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_81963_[8, 1536, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,729|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66253_[4, 1536, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,879|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_27472_[4, 1536, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,983|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_50070_[8, 1536, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,993|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_237_[2, 1536, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:26,998|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_56039_[8, 1536, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,133|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_76496_[2, 1536, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,154|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82610_[4, 1536, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,161|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_73113_[4, 1536, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,208|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73641_[2, 1536, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,240|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20452_[2, 1536, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,242|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69936_[1, 1536, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,294|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_90856_[1, 1536, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,297|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_44976_[1, 1536, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,299|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61486_[1, 1536, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,322|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_39782_[2, 1536, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,338|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_25935_[1, 1536, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:27,453|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_68466_[32, 1536, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:31,057|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50872_[64, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:31,211|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_93461_[64, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:31,512|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75351_[64, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:33,383|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75290_[32, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:34,930|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_33937_[128, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:35,400|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_33676_[128, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:35,486|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_19458_[32, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:35,754|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82025_[128, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:35,939|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_98838_[64, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:36,500|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_63495_[128, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:36,784|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42485_[16, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:36,896|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_71640_[32, 1024, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:37,145|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27409_[32, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:37,149|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_58288_[16, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:37,576|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_50984_[16, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:37,633|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_56257_[8, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:37,661|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_54606_[8, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:37,763|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69560_[32, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,051|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37554_[16, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,070|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_64481_[4, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,142|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_98461_[8, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,315|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_39509_[8, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,365|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86776_[4, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,382|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_31742_[4, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,440|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71985_[4, 1024, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,455|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8434_[16, 1024, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,459|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_25356_[8, 1024, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,483|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_48904_[4, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,515|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_92815_[2, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,523|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_22886_[2, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,555|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33356_[1, 1024, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,585|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_25892_[1, 1024, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,595|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94542_[2, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,617|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95919_[1, 1024, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,641|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_40913_[2, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,646|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_9921_[1, 1024, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,678|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_72857_[1, 1024, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,719|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43409_[2, 1024, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:38,879|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_65033_[64, 1024, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:42,492|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61840_[128, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:42,598|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66256_[128, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:42,959|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5903_[128, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:44,830|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29184_[64, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:46,802|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64190_[256, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:47,025|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50890_[64, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:47,207|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_88094_[256, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:47,273|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_71291_[128, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:48,104|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_75454_[256, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:48,223|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8470_[256, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:48,264|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39770_[32, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:48,278|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28587_[64, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,054|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50235_[64, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,285|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99790_[32, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,402|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_97544_[32, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,483|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_6914_[32, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,529|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21289_[128, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,579|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_58277_[16, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,580|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_83151_[64, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,797|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_33140_[16, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,842|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13338_[16, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,851|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22480_[8, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:49,857|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94034_[8, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,015|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22817_[16, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,027|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58779_[4, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,102|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_132_[8, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,134|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25553_[32, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,155|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39298_[16, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,161|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59012_[4, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,181|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_667_[8, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,184|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_98025_[4, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,242|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_90467_[2, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,259|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_89526_[2, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,286|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_36706_[2, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,290|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_16577_[4, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,301|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_80855_[4, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,301|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_65341_[2, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,333|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54756_[1, 512, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,345|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_56050_[1, 512, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,363|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_41872_[8, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,378|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25624_[2, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,375|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_22336_[1, 512, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,389|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_82127_[1, 512, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:50,398|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_72379_[1, 512, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:52,312|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_62523_[128, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:52,347|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33196_[128, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:52,488|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11221_[128, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:53,423|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_26862_[64, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:54,424|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_52019_[256, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:54,519|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1106_[256, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:54,634|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_19368_[64, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:54,656|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_53865_[256, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:54,833|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63123_[128, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,157|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_21186_[32, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,232|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90048_[256, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,338|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24806_[64, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,370|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54296_[32, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,558|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_31718_[64, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,653|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64984_[16, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,798|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_48436_[32, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,803|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_94594_[64, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,859|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80728_[32, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,866|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_3198_[16, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,956|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_9150_[16, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:55,997|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_91317_[8, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,017|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46175_[8, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,067|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45041_[128, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,116|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_16186_[8, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,137|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_77803_[16, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,142|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_94659_[16, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,144|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_32371_[4, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,174|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52221_[8, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,222|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_89777_[8, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,226|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_94822_[4, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,254|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_42303_[2, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,261|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_92999_[4, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,271|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_64514_[32, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,273|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_47458_[4, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,276|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73185_[4, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,273|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_9936_[2, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,284|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59858_[2, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,320|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_35368_[2, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,341|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_43261_[1, 256, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,349|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73068_[1, 256, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,356|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13740_[2, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,362|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49191_[1, 256, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,366|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_74745_[1, 256, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:56,407|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10874_[1, 256, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:57,331|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_21302_[128, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:57,352|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93749_[128, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:57,458|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95221_[128, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:57,944|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_15740_[64, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,357|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_94898_[256, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,367|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_94216_[256, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,520|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_11905_[64, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,607|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35716_[128, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,694|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_83911_[256, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,798|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_82388_[256, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,811|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_9761_[64, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,898|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78272_[32, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:58,926|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_61031_[64, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,010|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_26175_[64, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,025|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_63692_[32, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,091|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_21749_[16, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,117|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_40641_[32, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,171|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21313_[128, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,169|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_98042_[16, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,172|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_83521_[32, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,192|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_54143_[16, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,265|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_7717_[8, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,290|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_51334_[8, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,279|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22499_[8, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,299|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66383_[16, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,333|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99998_[8, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,335|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_12368_[8, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,353|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54454_[16, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,357|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7012_[4, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,366|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_96263_[32, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,367|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50817_[4, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,410|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38742_[2, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,430|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_50330_[4, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,433|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73496_[2, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,437|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_39614_[4, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,443|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_83747_[2, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,469|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60991_[4, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,469|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25187_[1, 128, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,486|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26595_[2, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,509|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67494_[2, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,511|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55273_[1, 128, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,518|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65218_[1, 128, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,529|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32240_[1, 128, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:14:59,529|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45550_[1, 128, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,041|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_40897_[128, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,048|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7517_[128, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,081|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_12_[128, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,325|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95968_[64, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,546|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_51080_[256, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,552|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_1427_[256, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,599|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72336_[256, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,620|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43151_[64, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,685|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97063_[128, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,733|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52666_[256, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,760|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_2485_[32, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,820|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_90182_[64, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,835|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_31579_[32, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,851|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21559_[64, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,884|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_11093_[64, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,912|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62153_[32, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,926|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_88281_[16, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,933|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_68194_[16, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:00,940|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_29631_[32, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,014|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46317_[16, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,029|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75736_[8, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,033|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_94573_[32, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,035|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60169_[8, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,043|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27110_[16, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,066|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_86041_[16, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,082|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45444_[4, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,088|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31280_[128, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,092|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_9875_[8, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,119|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_64600_[8, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,129|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_76189_[4, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,142|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_9129_[4, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,150|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49312_[2, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,184|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95448_[4, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,194|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_597_[8, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,194|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21453_[4, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,200|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_41362_[2, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,212|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32732_[2, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,224|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_88350_[2, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,240|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_26385_[1, 64, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,238|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_35991_[1, 64, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,242|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_30006_[2, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,263|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93303_[1, 64, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,263|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_67411_[1, 64, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,263|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_39195_[1, 64, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,541|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_9302_[128, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,539|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_77992_[128, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,555|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50946_[128, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,720|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_5567_[64, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,781|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58252_[256, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,781|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32118_[256, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,818|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_77654_[256, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,867|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_21969_[64, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,902|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_44224_[128, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,915|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99914_[256, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,943|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45226_[64, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,943|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59892_[32, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,950|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_71645_[64, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,968|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_90032_[64, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:01,999|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20021_[32, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,038|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_19446_[32, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,051|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_15598_[16, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,057|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_36773_[32, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,076|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50545_[16, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,075|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72999_[32, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,085|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_78777_[16, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,088|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20502_[16, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,089|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31509_[128, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,113|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_12155_[4, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,125|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_4881_[8, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,139|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_60672_[8, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,151|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10737_[16, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,183|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46462_[8, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,187|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_17806_[4, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,197|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_67428_[4, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,200|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58102_[4, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,207|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_67046_[8, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,230|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_61747_[8, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,235|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_72334_[2, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,246|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_40506_[4, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,257|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_86362_[2, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,270|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_24563_[2, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,265|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39699_[2, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,279|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50051_[1, 32, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,286|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_30806_[2, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,291|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_8612_[1, 32, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,293|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97182_[1, 32, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,297|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59631_[1, 32, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,311|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_83143_[1, 32, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,448|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_70097_[128, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,462|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_17703_[128, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,476|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8784_[128, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,564|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_34665_[256, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,590|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45337_[64, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,598|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_13232_[256, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,604|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_62652_[256, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,627|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47876_[256, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,629|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12839_[128, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,651|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69465_[64, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,676|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24404_[32, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,714|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_2212_[64, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,715|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_23434_[64, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,729|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43272_[128, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,731|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_72843_[32, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,732|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35890_[64, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,741|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_70428_[32, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,762|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_24079_[16, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,806|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78054_[32, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,803|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99032_[32, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,814|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50070_[16, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,817|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_31166_[8, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,827|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31790_[16, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,835|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11327_[16, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,831|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69675_[8, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,849|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88358_[8, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,865|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_51917_[4, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,869|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_77744_[16, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,897|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_9567_[8, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,903|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_96136_[4, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,909|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_98024_[2, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,927|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_51274_[8, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,927|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78353_[4, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,933|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61566_[4, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,950|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_48016_[2, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,950|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23662_[4, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,951|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7840_[2, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,963|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_84190_[1, 16, 64, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,967|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33370_[2, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,973|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_97753_[1, 16, 64, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,981|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_45423_[1, 16, 64, 64, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,989|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62103_[2, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,993|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_8280_[1, 16, 64, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:02,993|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76817_[1, 16, 64, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:05,972|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97283_[4, 16384, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:05,975|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_73199_[4, 16384, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:06,217|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_89535_[4, 16384, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:07,633|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34934_[2, 16384, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:09,315|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_92114_[2, 16384, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:09,567|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_61330_[8, 16384, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:09,851|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_98112_[4, 16384, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:10,095|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56860_[8, 16384, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:10,134|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_27186_[8, 16384, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:10,188|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_97796_[2, 16384, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:10,439|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_27827_[8, 16384, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:10,927|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21124_[1, 16384, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:11,022|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_41027_[1, 16384, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:11,085|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_76067_[1, 16384, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:11,140|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_42316_[2, 16384, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:11,266|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84885_[4, 16384, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:11,474|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_85903_[1, 16384, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:11,573|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13984_[2, 16384, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:12,048|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_7321_[1, 16384, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:13,775|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_68762_[4, 12288, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:13,812|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_36727_[4, 12288, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:14,612|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_48454_[4, 12288, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:15,643|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23223_[8, 12288, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:15,647|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_77798_[8, 12288, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:15,974|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95614_[2, 12288, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:16,309|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70694_[8, 12288, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:16,650|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_9651_[4, 12288, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:16,790|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72933_[2, 12288, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:16,978|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_962_[2, 12288, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,061|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24169_[8, 12288, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,105|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_4992_[2, 12288, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,267|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92308_[1, 12288, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,402|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30475_[1, 12288, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,453|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_46943_[4, 12288, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,455|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_70571_[2, 12288, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,624|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_17507_[1, 12288, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,788|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_77525_[1, 12288, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:17,955|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59987_[1, 12288, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:19,408|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66067_[4, 10240, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:19,624|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_46645_[4, 10240, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:20,089|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_33553_[4, 10240, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:20,785|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_73239_[8, 10240, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:21,115|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45256_[8, 10240, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:21,127|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52667_[2, 10240, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:21,590|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_36922_[8, 10240, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:21,753|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54668_[2, 10240, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:21,779|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_70316_[4, 10240, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,185|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72481_[8, 10240, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,222|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_16739_[2, 10240, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,321|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_95062_[2, 10240, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,324|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_57218_[1, 10240, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,326|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_1837_[2, 10240, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,344|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79721_[1, 10240, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,720|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96504_[1, 10240, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,853|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71654_[1, 10240, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,856|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_7798_[4, 10240, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:22,954|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39338_[1, 10240, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:25,848|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_84354_[8, 8192, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:25,908|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_77983_[8, 8192, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:26,105|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_97841_[8, 8192, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:27,623|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_66754_[4, 8192, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:28,125|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_71431_[16, 8192, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:28,974|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_72254_[16, 8192, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:29,208|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_50441_[4, 8192, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:29,701|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27046_[8, 8192, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:29,802|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_86032_[4, 8192, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:29,944|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32373_[16, 8192, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:30,041|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_4119_[16, 8192, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:30,246|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_38335_[4, 8192, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:30,500|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_80591_[2, 8192, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:30,715|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_42152_[2, 8192, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:30,895|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99280_[2, 8192, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:30,920|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97517_[1, 8192, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:30,981|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_5545_[4, 8192, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:31,038|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_19544_[8, 8192, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:31,099|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45849_[1, 8192, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:31,103|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_51456_[2, 8192, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:31,330|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_76012_[1, 8192, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:31,445|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_69225_[1, 8192, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:31,461|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_52748_[1, 8192, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:31,494|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92759_[2, 8192, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:33,602|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11240_[8, 6144, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:33,697|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_10727_[8, 6144, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:33,882|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30699_[8, 6144, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:34,999|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48291_[4, 6144, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:35,455|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_1622_[16, 6144, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:35,932|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33016_[16, 6144, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:36,268|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_83023_[4, 6144, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:36,431|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_14916_[16, 6144, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:36,564|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57842_[8, 6144, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:36,758|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_43640_[4, 6144, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:36,912|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56624_[4, 6144, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,043|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_25269_[2, 6144, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,078|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_40501_[16, 6144, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,186|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45440_[2, 6144, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,462|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82873_[4, 6144, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,463|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10396_[2, 6144, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,497|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99983_[1, 6144, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,526|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_40179_[1, 6144, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,723|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81694_[2, 6144, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,775|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_46734_[8, 6144, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,786|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_18133_[1, 6144, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,888|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_2777_[1, 6144, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,889|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_12203_[1, 6144, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:37,954|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39142_[2, 6144, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:40,717|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_19977_[16, 4096, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:40,951|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91790_[16, 4096, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:41,136|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_83703_[16, 4096, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:42,653|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7671_[8, 4096, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:43,867|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9116_[32, 4096, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:44,075|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12568_[32, 4096, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:44,303|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_36468_[8, 4096, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:44,485|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_98676_[16, 4096, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:44,651|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_6871_[32, 4096, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:45,234|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_17953_[8, 4096, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:45,262|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_21549_[4, 4096, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:45,372|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_33499_[32, 4096, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:45,598|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_35509_[4, 4096, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:45,661|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31490_[8, 4096, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:45,976|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69028_[16, 4096, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,014|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48553_[2, 4096, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,082|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86514_[2, 4096, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,108|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_81881_[8, 4096, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,148|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64491_[4, 4096, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,244|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87376_[4, 4096, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,321|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54603_[1, 4096, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,367|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_40686_[1, 4096, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,393|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33647_[2, 4096, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,479|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_58069_[1, 4096, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,519|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_25757_[2, 4096, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,572|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_85647_[2, 4096, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,579|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_27087_[4, 4096, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,597|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78826_[1, 4096, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:46,688|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78289_[1, 4096, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:48,727|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_14028_[16, 3072, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:48,827|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_94882_[16, 3072, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:49,094|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69547_[16, 3072, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:50,362|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_93281_[8, 3072, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:50,935|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_70701_[32, 3072, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:51,183|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_51100_[32, 3072, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:51,435|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_49_[32, 3072, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:51,532|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_55533_[8, 3072, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:51,577|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2946_[16, 3072, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,082|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75164_[8, 3072, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,157|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_14294_[4, 3072, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,199|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_65386_[4, 3072, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,244|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_41557_[8, 3072, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,531|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55928_[2, 3072, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,615|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61568_[32, 3072, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,617|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85693_[8, 3072, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,744|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61554_[4, 3072, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,847|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42057_[2, 3072, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:52,984|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59124_[4, 3072, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,002|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_85613_[2, 3072, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,034|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_67203_[2, 3072, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,043|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55658_[1, 3072, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,081|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35230_[2, 3072, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,160|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_90768_[1, 3072, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,172|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54336_[4, 3072, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,201|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_73723_[1, 3072, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,237|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_13644_[1, 3072, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,252|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_79571_[1, 3072, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:53,354|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74857_[16, 3072, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:56,053|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69344_[32, 2048, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:56,283|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_87411_[32, 2048, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:56,539|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_85442_[32, 2048, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:57,957|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_75103_[16, 2048, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:59,023|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10083_[64, 2048, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:59,296|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_61784_[64, 2048, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:59,742|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_48312_[16, 2048, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:15:59,848|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_52517_[32, 2048, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:00,061|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9375_[64, 2048, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:00,580|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29409_[16, 2048, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:00,630|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99138_[8, 2048, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:00,671|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_63089_[16, 2048, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:00,885|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73212_[8, 2048, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,147|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_32649_[64, 2048, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,197|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_19778_[16, 2048, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,309|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_82431_[4, 2048, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,459|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_6102_[8, 2048, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,555|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34368_[4, 2048, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,652|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75233_[4, 2048, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,663|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_89317_[8, 2048, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,745|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_7365_[4, 2048, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,767|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52977_[2, 2048, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,829|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_93668_[4, 2048, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,889|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_14765_[2, 2048, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:01,943|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30433_[2, 2048, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,013|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_97544_[1, 2048, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,021|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_78226_[8, 2048, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,069|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26710_[1, 2048, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,084|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_49920_[1, 2048, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,092|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46560_[1, 2048, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,094|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55191_[2, 2048, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,141|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83493_[2, 2048, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,160|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59471_[1, 2048, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:02,485|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13992_[32, 2048, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:04,240|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_3463_[32, 1536, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:04,396|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45279_[32, 1536, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:04,833|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_49959_[32, 1536, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:06,256|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_64446_[16, 1536, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:06,530|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74165_[64, 1536, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:06,656|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23294_[64, 1536, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:07,052|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63522_[64, 1536, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:07,180|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37348_[32, 1536, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:07,394|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61159_[16, 1536, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:07,617|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_22655_[16, 1536, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:07,800|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97918_[8, 1536, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:07,834|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_24339_[16, 1536, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,010|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_40016_[64, 1536, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,064|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60671_[8, 1536, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,205|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_20736_[16, 1536, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,262|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40001_[32, 1536, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,293|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_77860_[8, 1536, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,308|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35953_[4, 1536, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,404|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_66182_[4, 1536, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,461|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50186_[2, 1536, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,537|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25067_[4, 1536, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,576|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83961_[8, 1536, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,578|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_1972_[2, 1536, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,641|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81178_[2, 1536, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,641|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69467_[4, 1536, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,664|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_74500_[1, 1536, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,747|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31208_[2, 1536, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,769|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_16195_[2, 1536, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,771|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39261_[1, 1536, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,772|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_34101_[4, 1536, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,776|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25825_[1, 1536, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,800|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_89342_[1, 1536, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,830|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63119_[8, 1536, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:08,847|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_26096_[1, 1536, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:11,666|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_72318_[64, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:11,843|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81143_[64, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:12,085|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_7944_[64, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:13,624|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41137_[32, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:14,544|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78618_[128, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:15,326|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93907_[128, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:15,422|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_877_[32, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:15,566|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_93969_[64, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:15,841|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_2450_[128, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:16,171|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_79613_[32, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:16,204|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_9062_[32, 1024, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:16,346|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_33798_[16, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:16,608|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_84613_[16, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,066|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45068_[8, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,069|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53932_[16, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,109|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_41665_[128, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,174|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_93684_[64, 1024, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,225|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_48789_[16, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,323|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_38328_[32, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,433|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_43044_[4, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,484|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53720_[8, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,513|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69015_[8, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,535|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_32276_[8, 1024, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,545|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_38471_[4, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,630|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72754_[8, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,664|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_59632_[2, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,667|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75345_[4, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,688|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_67122_[2, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,718|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_28815_[16, 1024, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,738|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_48720_[4, 1024, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,771|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_60019_[2, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,774|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_10386_[1, 1024, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,775|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_11302_[4, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,798|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57994_[1, 1024, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,821|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19139_[2, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,826|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96482_[1, 1024, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,835|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_17083_[2, 1024, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,866|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_38447_[1, 1024, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:17,872|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_81960_[1, 1024, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:20,672|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_61954_[128, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:20,865|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87337_[128, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:21,113|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43322_[128, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:22,520|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_47711_[64, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:23,706|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_11389_[256, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:24,047|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_82223_[256, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:24,219|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_81221_[64, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:24,473|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27272_[256, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:24,559|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_2302_[128, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:25,170|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75029_[64, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:25,230|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_19567_[32, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:25,352|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_14177_[64, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:25,430|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7330_[32, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:25,786|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_27062_[256, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:25,818|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71203_[16, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:25,996|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67199_[64, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,117|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_61447_[32, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,136|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_60145_[128, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,193|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_16956_[16, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,288|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_96773_[16, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,310|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83769_[32, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,347|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_6480_[8, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,415|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14826_[32, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,447|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_16595_[8, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,479|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_60359_[16, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,513|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99383_[16, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,523|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_4224_[4, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,553|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_36242_[8, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,558|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29456_[4, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,581|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_22360_[8, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,600|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_12223_[4, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,637|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92471_[2, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,639|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_42869_[4, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,654|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_14025_[4, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,661|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_72091_[2, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,671|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_701_[2, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,676|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_19555_[1, 512, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,719|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20438_[2, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,740|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_17787_[1, 512, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,745|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_97396_[8, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,745|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_22858_[2, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,747|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92408_[1, 512, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,759|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_10848_[1, 512, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:26,786|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_64327_[1, 512, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:28,232|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85215_[128, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:28,289|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_5935_[128, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:28,452|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40717_[128, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:29,180|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_74420_[64, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:29,681|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_861_[256, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:29,908|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77139_[256, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,044|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94836_[256, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,050|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71985_[64, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,212|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_74823_[128, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,454|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_85549_[32, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,505|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10378_[64, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,580|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11421_[64, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,624|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62464_[256, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,637|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_77909_[32, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,848|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86105_[16, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,876|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99577_[16, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,936|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_67014_[32, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,941|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40848_[64, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:30,975|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34100_[128, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,023|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_76627_[32, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,058|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_83412_[8, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,076|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_47490_[16, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,090|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_81927_[8, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,151|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48205_[16, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,155|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_86306_[8, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,190|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25801_[4, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,200|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56600_[32, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,207|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83880_[16, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,214|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22170_[4, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,223|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_98168_[8, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,252|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_18685_[2, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,256|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_2040_[8, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,270|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69979_[4, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,299|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92136_[2, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,317|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_4720_[4, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,321|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_22116_[2, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,321|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_77850_[4, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,343|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_64798_[1, 256, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,350|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_41531_[2, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,367|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_79311_[1, 256, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,383|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_63425_[1, 256, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,385|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_58026_[1, 256, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,393|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_87488_[2, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:31,397|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50868_[1, 256, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:32,129|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_32449_[128, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:32,162|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_34644_[128, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:32,259|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_44839_[128, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:32,685|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_64609_[64, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:32,792|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47204_[256, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:32,869|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_93862_[256, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,044|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_36829_[256, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,087|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83597_[64, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,153|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_89973_[128, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,217|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99726_[64, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,297|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46318_[64, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,302|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_72346_[32, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,340|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_22880_[256, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,366|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_54107_[64, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,376|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_77414_[32, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,469|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_17849_[32, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,477|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13858_[16, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,480|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_22241_[16, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,515|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_15407_[16, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,546|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_84741_[8, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,555|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_72764_[128, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,588|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_93946_[32, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,598|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_43056_[8, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,608|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69052_[16, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,599|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_27081_[16, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,641|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80803_[8, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,673|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53954_[8, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,674|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_9908_[32, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,678|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_61628_[4, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,690|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22013_[4, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,696|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_30695_[8, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,696|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_43943_[4, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,723|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_8922_[4, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,731|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_37162_[2, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,741|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_94263_[4, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,757|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_85587_[2, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,781|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34464_[2, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,790|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_11938_[1, 128, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,805|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_7905_[2, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,812|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29147_[1, 128, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,815|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63900_[2, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,821|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99486_[1, 128, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,827|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97394_[1, 128, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:33,833|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11327_[1, 128, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,214|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_55748_[128, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,225|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_84957_[128, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,255|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27020_[128, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,481|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86022_[64, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,595|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45717_[256, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,597|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_14988_[256, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,690|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31649_[256, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,715|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71298_[64, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,748|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_15260_[128, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,806|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78727_[64, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,845|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_4707_[64, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,853|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_68418_[32, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,872|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13888_[64, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,874|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_47423_[32, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,887|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_28554_[128, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,939|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_81350_[16, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,944|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_66759_[256, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,963|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_3933_[32, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,966|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_33811_[16, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:34,974|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_36721_[16, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,001|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8765_[32, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,013|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_20289_[32, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,017|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88149_[16, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,052|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_84891_[8, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,065|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_99427_[8, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,069|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_10261_[8, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,074|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93792_[8, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,074|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41663_[4, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,108|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_22389_[16, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,121|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7229_[2, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,142|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_14993_[4, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,151|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10170_[8, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,156|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_85597_[4, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,168|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50923_[4, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,169|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_835_[4, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,188|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_24656_[2, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,193|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_40476_[2, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,199|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_29878_[2, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,218|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_31075_[1, 64, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,229|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_92261_[1, 64, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,245|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8404_[1, 64, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,248|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56821_[1, 64, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,248|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_39572_[2, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,254|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86600_[1, 64, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,465|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37550_[128, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,475|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_76285_[128, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,486|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99507_[128, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,605|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35394_[256, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,617|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_65094_[64, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,643|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_25187_[256, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,703|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57129_[256, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,720|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_18848_[64, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,734|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23649_[64, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,759|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48703_[128, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,778|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28290_[256, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,781|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_28506_[32, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,794|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_64683_[64, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,811|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_57538_[64, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,839|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26020_[32, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,844|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_79327_[128, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,882|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3851_[16, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,884|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_77425_[16, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,888|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80420_[32, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,897|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24321_[32, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,904|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59376_[32, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,910|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3912_[16, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,932|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85969_[16, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,976|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91090_[16, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,984|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_37946_[4, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,991|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59143_[8, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:35,998|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99180_[8, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,001|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88482_[8, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,006|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14101_[8, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,007|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_91612_[8, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,010|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_79357_[4, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,031|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_2195_[2, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,060|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_48534_[2, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,063|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_8565_[4, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,075|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_94827_[4, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,088|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88977_[4, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,095|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27773_[2, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,104|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_15144_[1, 32, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,114|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_21263_[2, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,118|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90695_[1, 32, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,118|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3798_[2, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,125|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20435_[1, 32, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,127|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3854_[1, 32, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,133|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93568_[1, 32, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,237|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32296_[128, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,249|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_79775_[128, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,261|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42120_[128, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,342|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78173_[256, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,348|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30481_[64, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,356|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78453_[256, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,374|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42943_[256, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,402|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21798_[256, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,417|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66085_[128, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,432|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_4866_[128, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,435|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_65546_[64, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,447|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_61086_[64, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,490|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_5996_[64, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,499|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5664_[32, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,502|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_7970_[64, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,511|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_49202_[32, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,521|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_86911_[32, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,528|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72123_[32, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,538|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71184_[32, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,567|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38672_[16, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,569|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_41379_[16, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,578|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_38749_[8, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,609|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_77065_[8, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,623|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85184_[16, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,626|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13615_[16, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,631|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_14557_[8, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,634|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_27453_[16, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,655|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_48762_[4, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,661|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90214_[8, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,661|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_90699_[8, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,662|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_70941_[4, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,681|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_28648_[4, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,691|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57263_[2, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,696|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59304_[2, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,708|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94630_[2, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,714|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_19117_[4, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,736|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59158_[1, 16, 48, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,743|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_36615_[1, 16, 48, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,750|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_25449_[4, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,761|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_11615_[2, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,761|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97666_[1, 16, 48, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,767|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55891_[1, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,767|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_81184_[2, 16, 48, 48, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:36,767|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_12112_[1, 16, 48, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:39,173|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_76488_[4, 16384, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:39,386|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72239_[4, 16384, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:39,557|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_88983_[4, 16384, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:40,749|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_18261_[2, 16384, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:41,830|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_93461_[8, 16384, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:42,015|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25372_[8, 16384, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:42,201|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_91180_[2, 16384, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:42,451|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_86919_[8, 16384, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:42,496|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37881_[4, 16384, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:43,021|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24505_[2, 16384, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:43,113|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_70558_[1, 16384, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:43,197|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_71905_[1, 16384, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:43,290|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_8235_[2, 16384, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:43,428|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_76748_[8, 16384, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:43,732|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80337_[2, 16384, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:43,775|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_81390_[1, 16384, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:44,018|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_65335_[1, 16384, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:44,033|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_32330_[1, 16384, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:44,078|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2117_[4, 16384, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:45,837|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27775_[4, 12288, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:45,924|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81090_[4, 12288, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:46,157|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41422_[4, 12288, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:47,207|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_15928_[8, 12288, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:47,210|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_82204_[2, 12288, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:47,282|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34472_[8, 12288, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,024|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59518_[8, 12288, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,173|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_15562_[2, 12288, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,304|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15646_[2, 12288, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,312|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_64223_[4, 12288, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,576|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_58898_[2, 12288, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,645|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7203_[1, 12288, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,852|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_662_[8, 12288, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,859|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24224_[1, 12288, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,868|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_91200_[2, 12288, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:48,919|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75065_[1, 12288, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:49,296|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62306_[1, 12288, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:49,392|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_53412_[1, 12288, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:49,421|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_84060_[4, 12288, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:50,943|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_36940_[4, 10240, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:51,013|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_47449_[4, 10240, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:51,158|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_89492_[4, 10240, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:51,733|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_85879_[8, 10240, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:51,987|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_87208_[2, 10240, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:52,075|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_1614_[8, 10240, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:52,470|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27651_[8, 10240, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:52,563|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10306_[2, 10240, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:52,878|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48789_[2, 10240, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:52,989|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_4439_[1, 10240, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,082|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_17006_[8, 10240, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,163|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_47554_[2, 10240, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,176|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86186_[4, 10240, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,344|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7261_[1, 10240, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,406|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_72055_[4, 10240, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,460|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_21400_[2, 10240, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,469|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83344_[1, 10240, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,676|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_52156_[1, 10240, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:53,687|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_76216_[1, 10240, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:55,849|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34887_[8, 8192, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:56,340|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_85207_[8, 8192, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:56,408|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_84580_[8, 8192, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:57,951|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37100_[4, 8192, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:58,119|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_60416_[16, 8192, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:58,449|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86853_[16, 8192, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:59,112|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48049_[16, 8192, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:59,144|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_61037_[8, 8192, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:59,283|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_19414_[4, 8192, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:59,506|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72473_[4, 8192, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:59,779|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23670_[2, 8192, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:16:59,990|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_40815_[16, 8192, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,017|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_7113_[2, 8192, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,126|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_28206_[4, 8192, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,188|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_18436_[4, 8192, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,237|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_39174_[2, 8192, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,419|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11211_[1, 8192, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,562|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60431_[1, 8192, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,630|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_94546_[1, 8192, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,702|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_87245_[1, 8192, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,706|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_74670_[2, 8192, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,790|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_24889_[8, 8192, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,923|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_86454_[1, 8192, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:00,965|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_51943_[2, 8192, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:02,608|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97729_[8, 6144, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:02,836|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43316_[8, 6144, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:03,080|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45333_[8, 6144, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:04,124|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21979_[4, 6144, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:04,241|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83570_[16, 6144, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:04,616|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_69240_[16, 6144, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:04,974|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_32835_[16, 6144, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,097|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_42365_[4, 6144, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,321|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_21666_[4, 6144, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,338|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64694_[8, 6144, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,613|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92891_[4, 6144, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,633|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59219_[2, 6144, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,727|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55563_[16, 6144, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,916|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_22507_[8, 6144, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,930|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15264_[2, 6144, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,967|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_95711_[2, 6144, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:05,985|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_22721_[1, 6144, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:06,020|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_76942_[4, 6144, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:06,171|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_48277_[1, 6144, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:06,223|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37293_[1, 6144, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:06,271|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_88850_[2, 6144, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:06,313|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_81623_[1, 6144, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:06,337|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91961_[1, 6144, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:06,432|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_56612_[2, 6144, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:08,756|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_67011_[16, 4096, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:08,907|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_64862_[16, 4096, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:09,195|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_60188_[16, 4096, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:10,448|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_14036_[8, 4096, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:10,811|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_50182_[32, 4096, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:11,459|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_28900_[32, 4096, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:11,850|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_23645_[8, 4096, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:12,022|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9628_[32, 4096, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:12,240|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_27546_[8, 4096, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:12,245|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_33398_[16, 4096, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:12,391|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47336_[8, 4096, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:12,671|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_68964_[4, 4096, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:12,900|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85802_[4, 4096, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:12,996|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_78383_[4, 4096, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,213|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_44177_[8, 4096, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,228|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_16245_[4, 4096, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,230|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_61581_[2, 4096, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,251|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65488_[32, 4096, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,415|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_44201_[2, 4096, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,483|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_93510_[1, 4096, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,609|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99535_[1, 4096, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,621|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95249_[2, 4096, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,644|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40397_[2, 4096, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,692|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_91395_[1, 4096, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,726|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93168_[2, 4096, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,751|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_74726_[1, 4096, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,810|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_76647_[4, 4096, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,821|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62139_[16, 4096, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:13,844|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54362_[1, 4096, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:15,703|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_33798_[16, 3072, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:15,710|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_65485_[16, 3072, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:16,090|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_18631_[16, 3072, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:17,148|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_23771_[8, 3072, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:17,295|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_15376_[32, 3072, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:17,713|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_26626_[32, 3072, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:17,995|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_98276_[32, 3072, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,163|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97348_[8, 3072, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,179|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_60585_[16, 3072, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,382|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10859_[8, 3072, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,496|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62400_[8, 3072, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,670|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_60710_[4, 3072, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,699|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22512_[4, 3072, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,951|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9586_[4, 3072, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:18,956|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19261_[32, 3072, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,029|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52341_[2, 3072, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,050|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48744_[8, 3072, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,094|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_92530_[16, 3072, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,221|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95222_[2, 3072, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,237|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_68165_[4, 3072, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,240|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_6550_[1, 3072, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,256|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_13813_[2, 3072, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,391|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_980_[1, 3072, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,394|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3956_[2, 3072, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,421|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_85598_[1, 3072, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,432|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30077_[2, 3072, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,436|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90759_[1, 3072, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,443|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50674_[1, 3072, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:19,456|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15389_[4, 3072, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:21,786|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_43487_[32, 2048, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:21,955|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50883_[32, 2048, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:22,178|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_40043_[32, 2048, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:23,462|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95348_[16, 2048, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:24,068|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_75980_[64, 2048, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:24,517|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_33093_[64, 2048, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:24,960|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39717_[16, 2048, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:24,964|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_82439_[64, 2048, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:25,310|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_62348_[32, 2048, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:25,628|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_10765_[16, 2048, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:25,643|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_30693_[16, 2048, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:25,655|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35688_[8, 2048, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:25,985|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_29459_[8, 2048, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,188|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_57696_[16, 2048, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,336|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_89294_[64, 2048, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,371|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55408_[4, 2048, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,445|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19909_[8, 2048, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,558|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47731_[4, 2048, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,586|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19484_[8, 2048, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,588|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99855_[4, 2048, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,629|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43219_[32, 2048, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,720|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_60940_[4, 2048, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,728|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_20026_[2, 2048, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,774|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_27128_[2, 2048, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,798|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_23670_[2, 2048, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,825|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12008_[4, 2048, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,843|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_87087_[1, 2048, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,868|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_36093_[2, 2048, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,906|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56224_[1, 2048, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,935|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54204_[1, 2048, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,944|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_63650_[8, 2048, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,949|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59233_[1, 2048, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:26,949|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_76383_[2, 2048, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:27,000|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_79966_[1, 2048, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:28,748|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_56224_[32, 1536, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:28,864|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_29656_[32, 1536, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:29,066|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_19135_[32, 1536, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:29,976|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_35215_[16, 1536, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:30,715|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73807_[64, 1536, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:30,857|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_10125_[64, 1536, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:31,068|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62591_[16, 1536, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:31,141|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_63711_[64, 1536, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:31,264|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_5241_[32, 1536, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:31,563|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39441_[16, 1536, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:31,646|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_35436_[8, 1536, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:31,784|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_38285_[8, 1536, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:31,788|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_67318_[16, 1536, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,042|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_39605_[4, 1536, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,068|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_95129_[64, 1536, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,160|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_15836_[8, 1536, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,206|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32920_[16, 1536, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,351|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_14759_[4, 1536, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,358|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_18873_[8, 1536, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,366|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_96210_[4, 1536, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,439|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_90790_[32, 1536, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,510|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71501_[2, 1536, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,516|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25907_[4, 1536, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,517|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82492_[8, 1536, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,522|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12008_[2, 1536, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,523|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_3579_[4, 1536, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,544|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_89655_[2, 1536, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,592|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_76200_[2, 1536, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,610|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19746_[1, 1536, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,608|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_83696_[1, 1536, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,642|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_2208_[1, 1536, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,653|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_21249_[1, 1536, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,654|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_86650_[2, 1536, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:32,733|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71980_[1, 1536, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:35,093|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_70283_[64, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:35,216|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_47401_[64, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:35,457|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_68887_[64, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:36,658|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_26939_[32, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:37,503|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_18378_[128, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:37,957|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_98122_[128, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:38,009|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88044_[32, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:38,541|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24024_[128, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:38,681|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_38910_[64, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:38,904|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_57007_[32, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:38,971|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46684_[32, 1024, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,229|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37867_[16, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,366|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_90647_[128, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,394|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94330_[16, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,731|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_31938_[16, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,757|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_21724_[32, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,803|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_14571_[8, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,831|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_44246_[8, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,933|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23188_[16, 1024, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,944|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_63345_[16, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:39,999|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_22451_[4, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,084|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_4957_[64, 1024, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,120|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_92207_[4, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,133|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_61752_[8, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,151|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_28711_[8, 1024, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,154|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_6982_[4, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,218|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47801_[2, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,249|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_68914_[4, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,250|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_244_[8, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,254|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80030_[2, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,274|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_81786_[2, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,281|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_23572_[2, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,330|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_93636_[1, 1024, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,343|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_25649_[4, 1024, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,351|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55643_[2, 1024, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,365|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_245_[1, 1024, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,366|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_21624_[1, 1024, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,377|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86044_[1, 1024, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:40,394|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_20278_[1, 1024, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:42,790|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_98441_[128, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:42,841|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_62708_[128, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:43,218|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37244_[128, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:44,549|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_50889_[64, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:45,316|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_52624_[256, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:45,479|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_2317_[256, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:45,920|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_4221_[64, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:46,064|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_7869_[256, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:46,163|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_14570_[128, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:46,287|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_74537_[64, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:46,756|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22872_[32, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:46,798|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_81697_[256, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:46,817|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_4842_[64, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:46,857|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22680_[32, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,054|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45484_[32, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,148|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38181_[16, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,196|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_22774_[64, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,196|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_72759_[16, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,393|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_72788_[8, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,457|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3320_[16, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,595|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92869_[8, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,639|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_74136_[8, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,688|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_34720_[16, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,752|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_99315_[32, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,757|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5560_[8, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,780|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_3763_[16, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,792|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_76330_[32, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,799|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_90662_[4, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,857|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_3541_[4, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,858|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_85909_[2, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,884|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_31020_[8, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,883|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5551_[4, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,909|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95668_[4, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,911|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_83046_[4, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,926|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_4698_[128, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,929|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19412_[2, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,960|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_37037_[1, 512, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,978|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_47881_[2, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:47,985|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95112_[2, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:48,007|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_4206_[1, 512, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:48,009|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_65096_[1, 512, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:48,025|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75683_[2, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:48,033|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82500_[1, 512, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:48,039|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54147_[1, 512, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:49,278|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45735_[128, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:49,331|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94921_[128, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:49,459|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63374_[128, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:50,171|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_45465_[64, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:50,436|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_2540_[256, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:50,653|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_5514_[256, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:50,922|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_45809_[64, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:50,930|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41634_[256, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:50,958|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_7059_[128, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,142|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31385_[64, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,159|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_34691_[64, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,287|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_47969_[32, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,339|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_77440_[32, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,400|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_68271_[256, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,507|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_24665_[16, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,521|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_21989_[32, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,591|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_46491_[64, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,611|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_41607_[16, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,653|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_23589_[32, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,708|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_9229_[8, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,731|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34100_[16, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,755|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_41427_[8, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,766|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_57089_[16, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,784|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_43198_[128, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,807|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12500_[8, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,809|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_5016_[16, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,853|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29226_[8, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,870|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_66460_[4, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,889|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78510_[4, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,904|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_89004_[8, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,906|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_76897_[4, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,914|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_46965_[32, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,911|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_71796_[4, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,946|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7089_[2, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,946|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_27766_[2, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,986|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46682_[4, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,988|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_1910_[2, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:51,986|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_20685_[1, 256, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,010|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_10823_[1, 256, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,013|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8983_[2, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,025|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_14978_[1, 256, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,037|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_29259_[1, 256, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,043|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_74391_[2, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,049|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_93742_[1, 256, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,658|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91568_[128, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,701|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2437_[128, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:52,771|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82036_[128, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,186|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_54272_[64, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,265|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_9486_[256, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,397|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59560_[256, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,500|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79709_[256, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,530|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_54083_[128, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,534|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_32728_[64, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,636|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35867_[64, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,669|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_16646_[64, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,715|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72965_[32, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,752|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_55043_[32, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,757|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_42770_[256, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,816|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_17080_[128, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,846|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_873_[32, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,848|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_97733_[16, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,866|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_9659_[16, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,899|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_8928_[64, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,919|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1228_[32, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,944|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_39417_[16, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,969|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_28211_[16, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,972|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66358_[8, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,974|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_52555_[16, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:53,979|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3031_[8, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,001|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8251_[8, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,040|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95112_[4, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,059|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78658_[8, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,068|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_4532_[32, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,070|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29160_[4, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,071|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_8984_[8, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,088|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_21772_[4, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,089|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13044_[4, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,118|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_2909_[4, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,135|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45820_[1, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,159|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_90337_[2, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,159|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_18703_[2, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,173|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65623_[2, 128, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,181|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59399_[2, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,188|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_71826_[1, 128, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,189|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_6103_[1, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,199|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_11663_[2, 128, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,211|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_64816_[1, 128, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,218|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_44136_[1, 128, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,536|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24170_[128, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,565|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_15145_[128, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,609|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59754_[128, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,814|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53992_[256, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,825|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57171_[64, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,871|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_5585_[256, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,952|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95107_[256, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:54,994|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95116_[128, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,008|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_18843_[64, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,051|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_93573_[256, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,054|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_3557_[64, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,064|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12056_[64, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,111|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_73381_[32, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,125|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35980_[64, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,136|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_54254_[32, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,173|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_98786_[32, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,178|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2720_[16, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,180|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_20399_[128, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,187|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72665_[32, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,217|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_30709_[16, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,234|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35045_[8, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,259|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_36269_[16, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,266|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_61556_[16, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,271|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74111_[32, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,303|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_54252_[8, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,316|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_18589_[8, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,317|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52178_[16, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,344|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_26807_[8, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,345|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_52863_[4, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,355|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60346_[4, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,395|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_13859_[2, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,382|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_17172_[4, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,397|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_71774_[4, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,408|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_68743_[8, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,409|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75575_[2, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,409|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_85246_[4, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,441|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_92658_[2, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,445|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_16482_[2, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,445|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45848_[1, 64, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,448|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63467_[1, 64, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,477|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_42346_[2, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,475|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_23350_[1, 64, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,474|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81950_[1, 64, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,489|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75707_[1, 64, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,673|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7553_[128, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,687|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_44212_[128, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,694|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_63698_[128, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,794|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_72220_[256, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,811|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25812_[64, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,845|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_71781_[256, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,857|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_60817_[256, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,899|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47129_[64, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,932|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93356_[256, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,936|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_31687_[128, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,956|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_42218_[64, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,964|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_17541_[64, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:55,992|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_76714_[128, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,018|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82723_[64, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,019|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7527_[32, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,037|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_82648_[32, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,039|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_40777_[32, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,047|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_74181_[16, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,059|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_15597_[32, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,077|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80372_[16, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,124|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41749_[32, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,130|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66325_[16, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,141|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86074_[16, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,152|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_93571_[8, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,157|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34751_[8, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,161|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_32816_[8, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,173|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37940_[8, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,179|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38524_[4, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,185|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_55531_[16, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,196|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_59612_[8, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,222|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71406_[2, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,233|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33993_[4, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,244|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_68178_[4, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,250|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_3108_[2, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,250|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48778_[2, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,251|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56085_[4, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,274|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_23461_[4, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,273|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_91282_[1, 32, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,287|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68352_[2, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,297|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12128_[1, 32, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,298|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_49295_[1, 32, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,299|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_75562_[2, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,314|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93390_[1, 32, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,320|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_46300_[1, 32, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,409|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59335_[128, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,416|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90378_[128, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,443|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_68168_[128, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,480|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22695_[256, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,501|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_25476_[256, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,514|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49479_[256, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,519|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_76460_[64, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,538|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_14131_[128, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,572|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_57517_[256, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,574|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29067_[64, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,579|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_82459_[64, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,622|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_84336_[128, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,632|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39283_[64, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,637|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_93654_[32, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,643|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_35448_[32, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,661|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_74388_[64, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,664|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10100_[32, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,693|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_17605_[32, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,712|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_38357_[32, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,716|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_15097_[16, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,738|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2594_[8, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,750|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_1649_[16, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,756|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46286_[16, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,762|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_86473_[8, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,762|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64327_[16, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,763|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1184_[16, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,786|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33599_[8, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,798|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71689_[4, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,801|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_11370_[4, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,817|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_98934_[8, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,844|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13601_[2, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,849|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_65852_[2, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,851|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_76623_[8, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,863|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_4636_[2, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,873|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45127_[4, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,880|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_49760_[4, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,902|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_87473_[1, 16, 40, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,903|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_79471_[2, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,905|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38776_[4, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,905|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92876_[1, 16, 40, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,915|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8151_[1, 16, 40, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,926|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6788_[1, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,928|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10004_[2, 16, 40, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:56,933|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40130_[1, 16, 40, 40, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:58,985|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69766_[4, 16384, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:59,057|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59404_[4, 16384, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:17:59,257|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58814_[4, 16384, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:00,209|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_10244_[2, 16384, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:01,065|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41387_[8, 16384, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:01,124|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81881_[8, 16384, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:01,365|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_36243_[2, 16384, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:01,830|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_36005_[4, 16384, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:01,909|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_76551_[2, 16384, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,298|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_82819_[2, 16384, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,322|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_39683_[8, 16384, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,365|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_65414_[1, 16384, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,496|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_2971_[1, 16384, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,577|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67757_[4, 16384, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,651|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_52902_[2, 16384, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,805|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_58565_[8, 16384, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,851|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_34063_[1, 16384, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:02,921|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15792_[1, 16384, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:03,073|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95135_[1, 16384, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:04,317|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60643_[4, 12288, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:04,467|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45882_[4, 12288, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:04,847|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27407_[4, 12288, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:05,278|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_24048_[8, 12288, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:05,635|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_81171_[2, 12288, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:05,715|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97939_[8, 12288, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,114|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_83052_[2, 12288, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,343|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_73834_[8, 12288, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,596|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_26590_[4, 12288, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,604|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_19878_[2, 12288, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,618|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43866_[2, 12288, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,749|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34103_[1, 12288, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,867|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79298_[2, 12288, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:06,931|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_2076_[8, 12288, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:07,038|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45151_[4, 12288, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:07,074|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13038_[1, 12288, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:07,149|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_64170_[1, 12288, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:07,201|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_5915_[1, 12288, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:07,223|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_39931_[1, 12288, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:08,381|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61212_[4, 10240, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:08,519|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_4264_[4, 10240, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:08,677|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_40908_[4, 10240, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:09,307|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_84374_[8, 10240, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:09,368|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_33528_[2, 10240, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:09,592|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_11123_[8, 10240, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:09,885|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_39341_[8, 10240, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:09,978|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_77516_[2, 10240, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,100|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_20429_[2, 10240, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,232|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_53242_[4, 10240, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,274|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_74986_[2, 10240, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,313|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1427_[1, 10240, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,509|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_79411_[1, 10240, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,547|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63126_[8, 10240, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,590|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_55751_[2, 10240, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,639|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_31358_[1, 10240, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,685|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58025_[4, 10240, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,740|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40939_[1, 10240, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:10,863|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_28477_[1, 10240, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:12,755|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_6501_[8, 8192, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:12,829|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_11315_[8, 8192, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:13,178|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55993_[8, 8192, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:14,356|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1036_[16, 8192, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:14,369|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81414_[4, 8192, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:14,693|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94677_[16, 8192, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:15,309|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_35969_[16, 8192, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:15,405|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_98402_[4, 8192, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:15,555|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42507_[4, 8192, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:15,655|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_60969_[8, 8192, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:15,788|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_98862_[4, 8192, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:15,942|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_32753_[2, 8192, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,153|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37937_[2, 8192, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,200|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23330_[4, 8192, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,305|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10479_[2, 8192, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,347|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_41167_[16, 8192, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,470|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_99298_[1, 8192, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,508|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_61658_[1, 8192, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,581|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68102_[8, 8192, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,590|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_53233_[2, 8192, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,615|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_49571_[1, 8192, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,746|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_11218_[1, 8192, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,753|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8014_[1, 8192, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:16,800|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72543_[2, 8192, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:18,242|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_61416_[8, 6144, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:18,331|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43171_[8, 6144, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:18,583|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_68399_[8, 6144, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:19,412|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5990_[4, 6144, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:19,649|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94568_[16, 6144, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:19,726|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_44718_[16, 6144, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,112|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_71417_[16, 6144, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,240|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_20796_[4, 6144, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,539|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70260_[4, 6144, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,546|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_93061_[8, 6144, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,553|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41136_[4, 6144, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,684|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48177_[2, 6144, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,819|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_47354_[8, 6144, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,824|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_56969_[4, 6144, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:20,983|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_33792_[2, 6144, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,028|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10627_[1, 6144, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,053|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_43870_[1, 6144, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,060|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_68823_[2, 6144, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,116|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_63744_[2, 6144, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,223|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_35209_[16, 6144, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,237|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54818_[1, 6144, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,244|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_44661_[2, 6144, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,276|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7216_[1, 6144, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:21,323|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52725_[1, 6144, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:23,176|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_3529_[16, 4096, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:23,340|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_82971_[16, 4096, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:23,575|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_77546_[16, 4096, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:24,635|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85106_[8, 4096, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:25,125|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88726_[32, 4096, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:25,347|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_9477_[32, 4096, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:25,715|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_95176_[8, 4096, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:25,754|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9638_[32, 4096, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,099|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46478_[16, 4096, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,308|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56870_[4, 4096, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,333|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22866_[8, 4096, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,354|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5454_[8, 4096, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,707|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15290_[4, 4096, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,885|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79704_[8, 4096, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,937|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50263_[16, 4096, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,962|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_30748_[4, 4096, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,965|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13160_[32, 4096, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:26,985|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_21169_[2, 4096, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,148|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_8424_[1, 4096, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,156|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86412_[2, 4096, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,174|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_46545_[4, 4096, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,204|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72992_[2, 4096, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,216|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_77149_[4, 4096, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,265|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52728_[2, 4096, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,296|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29000_[1, 4096, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,317|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19410_[1, 4096, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,351|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_4648_[2, 4096, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,369|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12167_[1, 4096, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:27,380|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_20962_[1, 4096, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:28,797|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45305_[16, 3072, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:28,929|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5565_[16, 3072, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:29,154|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_38940_[16, 3072, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:30,043|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63227_[8, 3072, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:30,224|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79866_[32, 3072, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:30,442|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_65904_[32, 3072, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:30,791|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45107_[32, 3072, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:30,836|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31584_[8, 3072, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:30,949|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_54550_[16, 3072, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,148|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27956_[8, 3072, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,202|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_59003_[8, 3072, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,299|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50586_[4, 3072, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,382|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24850_[4, 3072, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,509|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_1182_[16, 3072, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,567|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_10079_[32, 3072, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,572|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_44964_[8, 3072, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,605|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_55056_[2, 3072, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,632|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_98732_[4, 3072, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,720|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_61328_[2, 3072, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,747|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_58094_[1, 3072, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,805|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_67066_[2, 3072, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,816|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_55860_[4, 3072, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,840|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91485_[1, 3072, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,877|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_47572_[2, 3072, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,878|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_91549_[2, 3072, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,896|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_68248_[1, 3072, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,903|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_96095_[1, 3072, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,939|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3693_[4, 3072, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:31,947|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_85838_[1, 3072, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:33,835|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34546_[32, 2048, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:33,987|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3278_[32, 2048, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:34,279|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_72340_[32, 2048, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:35,425|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_48554_[16, 2048, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:36,095|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23766_[64, 2048, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:36,179|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45218_[64, 2048, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:36,490|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77763_[16, 2048, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:36,573|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_53854_[64, 2048, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:36,647|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11809_[32, 2048, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:36,889|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_95103_[16, 2048, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,136|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_27775_[8, 2048, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,233|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56692_[8, 2048, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,389|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_81654_[16, 2048, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,425|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_23517_[64, 2048, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,511|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54771_[32, 2048, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,568|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_93747_[8, 2048, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,689|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_8657_[4, 2048, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,708|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31747_[4, 2048, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,728|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_20929_[16, 2048, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,832|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6512_[4, 2048, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,880|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_91478_[2, 2048, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,893|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_66207_[2, 2048, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,950|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_38000_[8, 2048, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,979|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_43076_[8, 2048, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,990|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_52101_[4, 2048, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:37,996|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_24669_[4, 2048, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,031|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59339_[2, 2048, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,040|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_47868_[1, 2048, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,072|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95127_[1, 2048, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,084|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_55885_[2, 2048, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,097|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73046_[1, 2048, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,100|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84004_[2, 2048, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,112|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_25043_[1, 2048, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:38,112|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8816_[1, 2048, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:39,562|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_64097_[32, 1536, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:39,687|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_64603_[32, 1536, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:39,846|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29424_[32, 1536, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:40,674|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_31603_[16, 1536, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,044|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50008_[64, 1536, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,251|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_40922_[64, 1536, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,486|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_63143_[16, 1536, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,598|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_69715_[64, 1536, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,640|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94926_[32, 1536, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,860|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67030_[16, 1536, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,980|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63272_[16, 1536, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:41,991|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20777_[8, 1536, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,061|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_47050_[8, 1536, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,259|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_83441_[4, 1536, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,274|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_49921_[32, 1536, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,361|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35866_[8, 1536, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,412|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_28123_[16, 1536, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,477|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40_[4, 1536, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,505|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_35065_[64, 1536, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,523|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_48828_[4, 1536, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,569|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_94019_[8, 1536, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,585|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_74282_[2, 1536, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,592|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_4517_[4, 1536, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,616|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_73020_[2, 1536, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,653|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_20166_[2, 1536, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,659|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_34047_[1, 1536, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,694|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92653_[4, 1536, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,707|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56976_[1, 1536, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,713|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42942_[8, 1536, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,730|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34557_[2, 1536, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,745|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_70804_[1, 1536, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,746|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_71841_[2, 1536, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,764|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_84309_[1, 1536, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:42,808|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_70703_[1, 1536, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:44,709|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27120_[64, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:44,760|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94618_[64, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:45,075|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_62994_[64, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:46,276|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39041_[32, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:46,882|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75428_[128, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:46,963|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2230_[128, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:47,310|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_40388_[32, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:47,537|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_38949_[128, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:47,613|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_2594_[32, 1024, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:47,752|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57655_[64, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,105|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62907_[32, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,120|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_6811_[16, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,170|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34106_[16, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,230|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21370_[64, 1024, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,429|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9393_[8, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,444|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27048_[16, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,512|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99731_[32, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,525|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_47779_[8, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,644|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_20197_[128, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,656|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52743_[4, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,765|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_25031_[8, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,804|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_70741_[4, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,811|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_47011_[4, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,814|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_8533_[16, 1024, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,857|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_63527_[16, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,861|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_15390_[8, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,908|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29411_[8, 1024, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,914|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49289_[2, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,921|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_73339_[2, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,927|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_52106_[4, 1024, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,962|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_19532_[2, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,984|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99136_[4, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,993|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39909_[1, 1024, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:48,993|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34568_[1, 1024, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:49,002|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_2962_[1, 1024, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:49,022|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_16194_[2, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:49,031|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_74207_[1, 1024, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:49,052|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_14827_[2, 1024, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:49,063|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_51056_[1, 1024, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:51,036|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_35612_[128, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:51,154|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22277_[128, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:51,358|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27823_[128, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:52,464|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_11692_[64, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:52,916|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86603_[256, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:53,126|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35240_[256, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:53,549|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_38470_[64, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:53,765|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_46407_[256, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:53,933|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81402_[128, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,098|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_92196_[64, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,109|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75978_[64, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,304|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90978_[32, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,509|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_51972_[32, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,545|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68461_[64, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,757|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73054_[32, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,797|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_27137_[16, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,831|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_61773_[128, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,832|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54481_[16, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,901|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93468_[32, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,962|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_36938_[256, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:54,971|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63234_[8, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,083|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_25220_[8, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,089|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7821_[16, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,090|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99609_[16, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,096|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34900_[32, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,129|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_36309_[8, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,172|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10218_[4, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,182|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48755_[4, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,185|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42052_[8, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,203|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_6923_[16, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,204|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50189_[4, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,234|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_80962_[8, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,245|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95001_[2, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,279|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_88104_[2, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,313|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_16953_[4, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,325|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_73455_[2, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,333|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_29594_[2, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,334|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74897_[4, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,335|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20629_[1, 512, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,341|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98196_[1, 512, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,347|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92648_[1, 512, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,357|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80239_[2, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,371|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_43641_[1, 512, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:55,399|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_45441_[1, 512, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:56,364|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_13962_[128, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:56,427|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58917_[128, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:56,592|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54052_[128, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,170|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_22786_[64, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,326|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3376_[256, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,468|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62102_[256, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,695|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_71080_[256, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,706|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_11414_[64, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,780|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59328_[128, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,881|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_64956_[64, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,946|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_74041_[64, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:57,996|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_15740_[32, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,063|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80473_[32, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,202|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35425_[32, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,209|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93453_[256, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,246|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13339_[64, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,246|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_33174_[128, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,247|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_83211_[16, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,336|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46719_[8, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,359|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_61377_[16, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,360|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_36454_[32, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,385|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_15820_[16, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,428|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_96558_[8, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,439|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54529_[16, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,459|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_45767_[16, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,480|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_97322_[8, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,486|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_52575_[8, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,501|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_17899_[32, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,507|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_30571_[8, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,520|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59032_[4, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,522|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39278_[4, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,544|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98613_[4, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,563|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_205_[2, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,590|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30506_[4, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,590|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_41370_[2, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,612|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40593_[4, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,638|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12815_[1, 256, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,639|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27414_[2, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,655|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_33431_[1, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,658|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_6731_[1, 256, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,660|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45058_[2, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,668|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_52271_[1, 256, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,674|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78785_[2, 256, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:58,684|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61186_[1, 256, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,178|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_21423_[128, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,224|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88360_[128, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,299|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_62487_[128, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,618|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40020_[64, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,674|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_10523_[256, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,747|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_29899_[256, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,908|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_2105_[64, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,954|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_52464_[128, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,961|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_44662_[256, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:18:59,997|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95096_[64, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,003|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45197_[64, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,114|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_54024_[32, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,120|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72284_[32, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,147|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_71020_[64, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,153|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_40292_[128, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,167|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_16585_[256, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,193|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61204_[32, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,215|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59672_[16, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,244|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_19842_[32, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,245|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_84305_[16, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,279|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_58519_[8, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,277|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85869_[16, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,303|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19570_[32, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,309|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25753_[16, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,322|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_25730_[8, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,341|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37235_[16, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,370|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_90380_[8, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,370|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_22204_[8, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,382|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_33806_[4, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,384|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_97629_[4, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,419|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93551_[8, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,439|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22415_[4, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,441|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_51351_[4, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,459|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_55938_[2, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,460|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31128_[2, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,465|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_76508_[2, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,511|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79716_[2, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,514|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10017_[1, 128, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,498|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_24825_[4, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,520|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_53625_[2, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,525|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38723_[1, 128, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,525|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10531_[1, 128, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,529|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_73812_[1, 128, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,537|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94179_[1, 128, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,805|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_16021_[128, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,812|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_21374_[128, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:00,868|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_98060_[128, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,034|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_47142_[64, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,082|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32893_[256, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,094|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31618_[256, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,170|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39585_[256, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,221|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48203_[64, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,222|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64960_[64, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,224|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_66605_[128, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,261|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_51095_[64, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,279|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_92488_[128, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,308|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93298_[256, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,314|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_27265_[32, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,335|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87571_[32, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,341|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_51063_[64, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,371|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94732_[32, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,371|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_6042_[16, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,389|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_67368_[16, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,426|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_89563_[16, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,426|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_47212_[32, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,430|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20798_[16, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,473|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_32026_[16, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,468|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_34360_[32, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,478|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71966_[8, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,490|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_57016_[8, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,496|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_29413_[8, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,509|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64527_[8, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,532|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77053_[4, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,541|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_96486_[8, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,560|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76428_[4, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,571|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_5605_[2, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,579|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_33085_[4, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,577|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12654_[2, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,589|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_3199_[4, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,593|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_82354_[2, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,606|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92807_[4, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,618|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80040_[1, 64, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,635|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_86021_[2, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,639|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_9555_[1, 64, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,653|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_12682_[2, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,659|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_28309_[1, 64, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,659|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_75201_[1, 64, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,665|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_32381_[1, 64, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,812|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_92679_[128, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,833|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22705_[128, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,856|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5659_[128, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,910|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_24064_[256, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,923|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_38092_[256, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,949|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_41132_[64, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:01,995|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_28484_[256, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,011|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_6193_[64, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,028|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35446_[128, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,087|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96762_[256, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,088|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_51883_[64, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,094|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_8090_[64, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,096|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76100_[128, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,101|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69968_[64, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,101|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_89778_[32, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,117|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_70430_[32, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,131|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_26155_[16, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,168|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_71812_[32, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,179|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_19592_[16, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,187|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56057_[16, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,208|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34779_[16, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,209|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_29402_[32, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,222|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_84452_[16, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,227|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_71021_[32, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,265|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_6379_[8, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,266|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_79199_[8, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,272|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_19265_[4, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,293|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84591_[8, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,305|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_21008_[8, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,315|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_80660_[4, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,324|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59026_[4, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,327|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41848_[2, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,332|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_68234_[2, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,349|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13027_[8, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,362|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36456_[4, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,379|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81786_[2, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,380|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47241_[4, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,388|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_49471_[1, 32, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,395|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_84376_[1, 32, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,413|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_32066_[1, 32, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,419|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_24590_[1, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,422|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_69508_[2, 32, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,425|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_46451_[2, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,432|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99472_[1, 32, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,531|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69389_[128, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,532|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75484_[128, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,564|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_16430_[256, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,570|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_21291_[128, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,577|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_52681_[256, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,617|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_39625_[256, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,633|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21796_[64, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,648|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83962_[256, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,651|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_33295_[64, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,672|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_26847_[64, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,687|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_67810_[128, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,710|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76355_[64, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,727|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20750_[128, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,738|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_72100_[32, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,757|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_62114_[32, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,759|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82696_[32, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,768|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_68560_[32, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,779|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_75803_[16, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,811|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95494_[32, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,829|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77985_[8, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,832|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27045_[16, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,843|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_9750_[64, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,844|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_32487_[16, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,855|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_57908_[16, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,876|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60631_[16, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,887|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53994_[8, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,887|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_8149_[4, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,897|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95316_[4, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,908|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_90168_[8, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,915|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59669_[8, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,940|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42903_[8, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,950|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_89672_[2, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,952|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_32216_[4, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,953|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_52370_[2, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,958|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58617_[4, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,959|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2956_[2, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,969|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_64914_[4, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,979|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15779_[1, 16, 32, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,997|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35294_[2, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:02,998|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_52168_[1, 16, 32, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:03,007|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83260_[1, 16, 32, 32, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:03,009|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_39734_[2, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:03,011|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_44463_[1, 16, 32, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:03,021|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30025_[1, 16, 32, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:04,556|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_41023_[4, 16384, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:04,618|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80512_[4, 16384, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:04,841|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_7895_[4, 16384, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:05,722|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_61460_[2, 16384, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:05,957|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59184_[8, 16384, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:06,267|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33560_[8, 16384, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:06,622|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_80950_[2, 16384, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:06,719|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_23578_[8, 16384, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:06,775|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_58495_[2, 16384, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:06,928|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80502_[2, 16384, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,019|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19793_[4, 16384, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,096|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_79287_[4, 16384, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,156|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_32845_[1, 16384, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,211|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_75040_[1, 16384, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,417|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_16099_[1, 16384, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,547|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_87534_[2, 16384, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,660|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74181_[1, 16384, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,718|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_15171_[1, 16384, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:07,973|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_89370_[8, 16384, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:08,958|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55644_[4, 12288, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:09,101|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59960_[4, 12288, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:09,392|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_51325_[8, 12288, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:09,416|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_41663_[4, 12288, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:09,604|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_30023_[8, 12288, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:09,975|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_26138_[2, 12288, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,050|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80700_[2, 12288, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,139|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47286_[8, 12288, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,343|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_38744_[2, 12288, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,461|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93437_[1, 12288, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,710|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_30433_[1, 12288, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,779|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_71603_[4, 12288, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,787|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95547_[4, 12288, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,801|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64680_[2, 12288, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,884|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_76228_[1, 12288, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,925|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_53057_[1, 12288, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,927|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31841_[2, 12288, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:10,967|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78203_[8, 12288, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:11,210|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_95757_[1, 12288, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:11,875|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_61456_[4, 10240, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:11,973|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_11864_[4, 10240, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:12,409|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_9614_[4, 10240, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:12,757|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74417_[8, 10240, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:12,835|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24779_[8, 10240, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:12,909|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59089_[2, 10240, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,148|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57417_[8, 10240, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,296|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_48528_[2, 10240, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,321|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_34054_[2, 10240, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,355|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47976_[4, 10240, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,479|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2814_[2, 10240, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,599|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30064_[1, 10240, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,621|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_39044_[1, 10240, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,626|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71601_[4, 10240, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,700|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_98713_[1, 10240, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,711|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_82268_[2, 10240, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,858|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6914_[1, 10240, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,875|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5319_[8, 10240, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:13,888|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29955_[1, 10240, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:15,369|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13289_[8, 8192, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:15,519|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98833_[8, 8192, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:15,712|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12971_[8, 8192, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:16,607|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_87697_[4, 8192, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:16,733|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34809_[16, 8192, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:17,013|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_70963_[16, 8192, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:17,437|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_9408_[4, 8192, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:17,582|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42209_[16, 8192, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:17,705|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_2228_[4, 8192, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:17,849|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37709_[4, 8192, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:17,899|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96548_[8, 8192, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,024|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_41183_[8, 8192, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,055|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_28385_[2, 8192, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,192|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_84943_[2, 8192, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,198|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_66358_[16, 8192, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,220|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_14287_[4, 8192, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,282|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_32308_[1, 8192, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,355|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_6196_[2, 8192, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,434|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_26466_[1, 8192, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,442|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86515_[1, 8192, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,553|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82731_[1, 8192, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,559|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28443_[2, 8192, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,613|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_901_[1, 8192, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:18,614|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57551_[2, 8192, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:19,697|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5694_[8, 6144, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:19,826|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54745_[8, 6144, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:20,033|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77798_[8, 6144, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:20,632|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_39865_[16, 6144, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:20,706|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_85071_[4, 6144, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:20,848|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_33491_[16, 6144, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,257|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_33759_[4, 6144, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,290|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82227_[16, 6144, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,442|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15783_[4, 6144, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,466|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_4174_[8, 6144, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,518|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99828_[4, 6144, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,643|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_23560_[2, 6144, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,662|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_86292_[8, 6144, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,807|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46146_[2, 6144, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,813|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86713_[4, 6144, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,847|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_36628_[1, 6144, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,888|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_25256_[16, 6144, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,888|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27156_[2, 6144, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:21,977|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73960_[1, 6144, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:22,012|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_31918_[1, 6144, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:22,027|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80660_[2, 6144, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:22,072|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_36328_[1, 6144, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:22,108|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_84972_[1, 6144, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:22,137|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_57803_[2, 6144, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:23,548|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_95511_[16, 4096, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:23,717|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_94550_[16, 4096, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:24,016|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_84177_[16, 4096, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:24,893|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_70184_[8, 4096, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:24,945|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19859_[32, 4096, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:25,024|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11172_[32, 4096, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:25,736|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46882_[32, 4096, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:25,740|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5611_[8, 4096, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:25,897|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95583_[8, 4096, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:25,903|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_27075_[16, 4096, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:25,947|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66220_[8, 4096, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,169|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_85732_[4, 4096, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,191|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43756_[8, 4096, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,352|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_84138_[4, 4096, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,384|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_77267_[16, 4096, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,402|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41049_[2, 4096, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,410|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_54728_[4, 4096, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,577|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74390_[2, 4096, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,590|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_17681_[4, 4096, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,650|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1373_[2, 4096, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,696|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21889_[1, 4096, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,704|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88199_[1, 4096, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,728|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_31374_[1, 4096, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,731|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_21890_[2, 4096, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,739|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50593_[2, 4096, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,833|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53105_[1, 4096, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,872|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_76161_[1, 4096, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,882|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_55205_[4, 4096, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:26,930|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_36098_[32, 4096, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:27,966|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25584_[16, 3072, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:28,129|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24708_[16, 3072, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:28,345|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_52800_[16, 3072, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:28,995|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80231_[8, 3072, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,055|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_97779_[32, 3072, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,215|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_16223_[32, 3072, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,448|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_46809_[32, 3072, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,604|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_97737_[8, 3072, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,710|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_9878_[16, 3072, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,798|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_92315_[8, 3072, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,853|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_86725_[8, 3072, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,921|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92176_[4, 3072, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:29,968|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_71842_[16, 3072, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,018|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40640_[4, 3072, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,141|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30404_[8, 3072, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,144|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36586_[2, 3072, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,181|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81311_[4, 3072, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,184|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12350_[2, 3072, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,248|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_67287_[4, 3072, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,281|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_48288_[1, 3072, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,351|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_23420_[32, 3072, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,356|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_83870_[2, 3072, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,360|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83881_[1, 3072, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,361|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2621_[4, 3072, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,361|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23303_[2, 3072, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,409|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39876_[2, 3072, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,427|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_89326_[1, 3072, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,435|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_76561_[1, 3072, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:30,472|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_73248_[1, 3072, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:31,941|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_70079_[32, 2048, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:32,055|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_87830_[32, 2048, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:32,316|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12394_[32, 2048, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:33,170|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40360_[16, 2048, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:33,391|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_69321_[64, 2048, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:33,523|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_36735_[64, 2048, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:33,979|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_30172_[16, 2048, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,099|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57971_[64, 2048, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,174|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_2301_[16, 2048, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,340|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86764_[32, 2048, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,459|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_17245_[16, 2048, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,497|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_85102_[8, 2048, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,590|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_97353_[8, 2048, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,698|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47903_[16, 2048, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,812|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59467_[4, 2048, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,898|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75517_[8, 2048, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:34,938|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_98211_[4, 2048, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,006|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2239_[64, 2048, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,043|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99704_[32, 2048, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,055|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_68848_[4, 2048, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,125|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_43688_[4, 2048, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,134|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56198_[2, 2048, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,138|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_26785_[8, 2048, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,179|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48200_[8, 2048, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,194|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_38644_[2, 2048, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,204|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_58962_[1, 2048, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,226|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40131_[2, 2048, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,245|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_39128_[4, 2048, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,249|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_8661_[2, 2048, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,261|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12592_[1, 2048, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,295|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80912_[1, 2048, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,300|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_40548_[2, 2048, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,308|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34685_[1, 2048, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:35,361|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_22403_[1, 2048, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:36,416|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_21520_[32, 1536, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:36,524|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43501_[32, 1536, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:36,744|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_78620_[32, 1536, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:37,423|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_90374_[16, 1536, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:37,466|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_99738_[64, 1536, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:37,722|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10823_[64, 1536, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,020|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88774_[64, 1536, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,041|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_16164_[16, 1536, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,094|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_61026_[16, 1536, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,185|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_43295_[16, 1536, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,212|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1877_[32, 1536, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,373|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77018_[8, 1536, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,450|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_69314_[8, 1536, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,475|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_22169_[32, 1536, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,573|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_26962_[8, 1536, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,624|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_25335_[4, 1536, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,652|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_70862_[4, 1536, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,685|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74282_[16, 1536, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,716|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1389_[8, 1536, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,775|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33288_[4, 1536, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,786|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_84264_[2, 1536, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,805|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_62306_[4, 1536, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,837|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12800_[2, 1536, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,886|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27357_[8, 1536, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,911|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39337_[4, 1536, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,935|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7732_[2, 1536, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,941|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91860_[2, 1536, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,941|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_32567_[1, 1536, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,951|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77994_[1, 1536, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,964|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_77856_[2, 1536, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,975|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11495_[1, 1536, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:38,992|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_6252_[1, 1536, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:39,026|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71767_[64, 1536, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:39,043|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39028_[1, 1536, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:40,480|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53099_[64, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:40,624|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45849_[64, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:40,881|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47802_[64, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:41,778|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_94807_[32, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:42,016|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_24358_[128, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:42,328|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_22773_[128, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:42,629|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_17691_[32, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:42,683|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_18970_[128, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:42,814|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_59153_[32, 1024, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:42,992|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_85655_[32, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,009|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_66712_[64, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,106|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78785_[64, 1024, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,114|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43560_[16, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,278|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50363_[16, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,308|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_90985_[8, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,491|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30480_[16, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,529|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_17740_[8, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,576|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57799_[8, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,614|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90261_[128, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,626|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_18210_[32, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,634|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_65014_[16, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,665|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_97686_[8, 1024, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,713|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20730_[4, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,761|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_22861_[4, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,779|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_9977_[4, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,793|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_80136_[2, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,816|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81030_[4, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,816|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25210_[16, 1024, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,828|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_481_[8, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,829|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11191_[2, 1024, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,850|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_24031_[4, 1024, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,884|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_7609_[2, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,886|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37454_[1, 1024, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,896|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_43349_[1, 1024, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,908|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95273_[1, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,933|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_44843_[2, 1024, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,940|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99878_[1, 1024, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,951|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_57410_[1, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:43,951|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_17565_[2, 1024, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:45,451|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48364_[128, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:45,544|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97777_[128, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:45,796|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_91697_[128, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:46,713|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_78606_[64, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:46,938|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_20802_[256, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:47,201|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80236_[256, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:47,538|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50276_[64, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:47,655|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_4213_[256, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:47,820|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_15961_[128, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:47,872|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_73808_[64, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:47,942|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_78149_[64, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,093|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50279_[32, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,171|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15771_[128, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,286|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_20893_[32, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,401|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_6460_[32, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,419|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35527_[16, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,495|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_83764_[64, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,500|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43324_[256, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,522|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70944_[16, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,619|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50129_[8, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,659|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50415_[32, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,669|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84375_[16, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,673|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22346_[8, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,680|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22121_[16, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,729|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_72830_[32, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,754|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_74730_[16, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,767|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_93066_[4, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,774|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64348_[4, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,774|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_18116_[8, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,806|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_88724_[8, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,853|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_97862_[2, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,860|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72764_[8, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,864|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_89287_[2, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,881|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12025_[4, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,881|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_74650_[4, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,894|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_14313_[2, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,914|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_56754_[4, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,932|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_96149_[1, 512, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,954|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_83293_[2, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,962|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_12318_[1, 512, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,968|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_94874_[1, 512, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,974|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_36231_[1, 512, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,974|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59226_[1, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:48,983|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62662_[2, 512, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:49,766|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_96813_[128, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:49,825|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_67216_[128, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:49,945|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_8381_[128, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:50,432|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63853_[64, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:50,509|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10571_[256, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:50,657|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_46267_[256, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:50,883|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95946_[64, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:50,907|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_74790_[256, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:50,965|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13468_[64, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,015|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93162_[128, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,030|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35762_[64, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,059|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_71041_[128, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,139|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99804_[32, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,210|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_33827_[32, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,283|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_97321_[16, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,291|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38884_[64, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,308|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_55409_[32, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,340|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_69148_[256, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,352|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50524_[16, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,366|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68386_[16, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,367|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78323_[32, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,436|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14797_[8, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,460|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56706_[16, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,461|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33856_[8, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,464|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_14495_[16, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,475|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74516_[32, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,475|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95780_[8, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,478|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_38891_[8, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,524|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_30870_[8, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,547|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69365_[4, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,547|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_70568_[2, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,557|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_10349_[4, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,578|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_17885_[4, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,587|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_88293_[2, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,615|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_88049_[4, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,631|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_73726_[2, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,635|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90931_[4, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,646|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_66139_[1, 256, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,662|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_71303_[2, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,663|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_49934_[1, 256, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,675|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_93960_[2, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,678|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22578_[1, 256, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,687|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_8574_[1, 256, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:51,696|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_90562_[1, 256, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,079|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_60341_[128, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,113|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_81678_[128, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,184|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94440_[128, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,428|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_67384_[64, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,456|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_68786_[256, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,488|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_67096_[256, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,655|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99399_[64, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,670|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72634_[64, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,690|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_89280_[256, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,712|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_4342_[64, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,747|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27561_[128, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,770|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_3103_[32, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,770|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_44223_[128, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,823|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_10883_[64, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,828|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_54725_[32, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,858|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78552_[16, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,875|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_51946_[32, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,911|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_82330_[16, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,926|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_38445_[256, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,936|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_45286_[32, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,946|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_3569_[16, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,948|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5860_[16, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:52,988|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_89797_[32, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,005|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_54231_[8, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,006|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_72548_[16, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,011|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_96164_[8, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,030|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_89654_[8, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,047|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_22123_[4, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,058|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_15734_[4, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,073|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98522_[8, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,081|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82816_[8, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,100|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_37355_[4, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,099|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94796_[4, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,145|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_51540_[4, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,149|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_96590_[2, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,153|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_30962_[1, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,161|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_17144_[2, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,166|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_30873_[2, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,170|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_35201_[2, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,170|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_98369_[2, 128, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,180|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96234_[1, 128, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,200|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_29785_[1, 128, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,213|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_58516_[1, 128, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,217|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45129_[1, 128, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,420|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81305_[128, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,443|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_86496_[128, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,474|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88348_[128, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,595|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_39193_[256, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,600|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_66264_[64, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,639|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_65097_[256, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,715|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_40314_[256, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,734|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_67018_[64, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,736|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_40131_[64, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,768|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_84280_[64, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,780|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_57492_[128, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,781|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_37931_[128, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,839|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_18378_[32, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,845|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_14621_[32, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,854|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30780_[256, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,875|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_18067_[32, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,880|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_27408_[16, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,898|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_29146_[32, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,924|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_78779_[64, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,929|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_19031_[32, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,942|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42306_[16, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,951|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_3728_[16, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,958|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_81793_[16, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,959|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30535_[8, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,971|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_43593_[8, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:53,996|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39605_[16, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,004|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96518_[8, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,046|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53092_[4, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,053|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72162_[4, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,059|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39636_[8, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,066|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_3718_[4, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,066|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_44496_[8, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,085|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95977_[2, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,091|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_98581_[2, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,090|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49806_[4, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,109|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_26602_[4, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,114|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_96226_[1, 64, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,141|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82382_[1, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,151|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_16437_[2, 64, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,153|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_41888_[2, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,155|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_60333_[1, 64, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,159|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_30514_[2, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,159|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_19458_[1, 64, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,174|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_79266_[1, 64, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,275|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34731_[128, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,298|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_7396_[128, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,319|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59049_[128, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,392|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_32225_[256, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,403|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40772_[256, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,421|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_64703_[64, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,439|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1564_[128, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,448|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_62516_[256, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,470|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99304_[128, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,485|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_52525_[64, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,504|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37690_[64, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,515|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_49353_[256, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,517|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45876_[32, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,549|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_34888_[64, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,551|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13230_[32, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,565|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33494_[32, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,583|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_389_[32, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,584|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_53993_[16, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,604|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66800_[16, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,628|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_89578_[64, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,649|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94796_[16, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,657|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_56873_[16, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,658|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82193_[32, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,663|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34255_[8, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,673|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_47975_[16, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,683|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_57204_[8, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,683|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_14997_[8, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,703|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61813_[4, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,706|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_80023_[8, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,758|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_20834_[8, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,761|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59947_[2, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,763|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71101_[2, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,766|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_21937_[4, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,773|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_14554_[2, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,778|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_51229_[4, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,779|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8461_[4, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,804|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87502_[4, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,807|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_89105_[1, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,812|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_91193_[1, 32, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,819|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_42099_[1, 32, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,845|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_12814_[1, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,845|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_97170_[2, 32, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,846|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41086_[2, 32, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,847|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_83141_[1, 32, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,974|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_35386_[256, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,978|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_44602_[128, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,980|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87329_[256, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:54,993|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48662_[128, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,001|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27181_[256, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,005|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_92337_[128, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,032|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34407_[256, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,051|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_40185_[64, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,057|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_58426_[128, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,101|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92668_[64, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,117|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_53358_[64, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,118|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23292_[32, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,123|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_68980_[32, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,126|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2548_[64, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,131|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_21345_[32, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,138|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86999_[128, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,168|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_37740_[64, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,200|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_46687_[16, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,209|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_34728_[16, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,215|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20702_[16, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,221|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36333_[16, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,233|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_7940_[16, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,245|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_28059_[32, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,251|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_49758_[32, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,257|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95560_[8, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,290|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_55016_[4, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,297|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82183_[4, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,299|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38652_[8, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,311|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30601_[8, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,317|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_60608_[8, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,318|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78461_[8, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,320|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91631_[4, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,335|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72203_[4, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,351|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45042_[2, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,361|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2061_[2, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,366|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12664_[4, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,384|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86355_[1, 16, 24, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,389|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13077_[2, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,396|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_65459_[1, 16, 24, 24, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,396|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_30986_[2, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,405|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_76294_[1, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,411|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43717_[1, 16, 24, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,412|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_3286_[1, 16, 24, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:55,413|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_98887_[2, 16, 24, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:56,487|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23486_[4, 16384, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:56,619|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56614_[4, 16384, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:56,837|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_46576_[4, 16384, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:57,464|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_93975_[2, 16384, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:57,498|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_95394_[8, 16384, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:57,743|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_54428_[8, 16384, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,095|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_71114_[2, 16384, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,170|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19576_[2, 16384, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,233|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_260_[4, 16384, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,263|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_44836_[8, 16384, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,263|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_33812_[2, 16384, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,379|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_39978_[4, 16384, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,470|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37951_[1, 16384, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,571|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37235_[1, 16384, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,644|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_17245_[1, 16384, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,739|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42018_[2, 16384, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,766|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8277_[1, 16384, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:58,847|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_26449_[1, 16384, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:59,262|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_50574_[8, 16384, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:59,575|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10692_[4, 12288, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:59,763|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72278_[4, 12288, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:19:59,959|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_70337_[8, 12288, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,295|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_97258_[8, 12288, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,359|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69790_[2, 12288, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,434|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52775_[4, 12288, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,686|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54184_[8, 12288, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,782|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_14183_[2, 12288, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,869|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_69908_[4, 12288, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,949|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86837_[2, 12288, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:00,950|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_36474_[2, 12288, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,015|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3112_[4, 12288, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,025|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_65499_[1, 12288, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,118|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50033_[1, 12288, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,204|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_28206_[2, 12288, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,232|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_58063_[1, 12288, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,261|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75342_[1, 12288, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,342|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_17805_[1, 12288, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,441|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_62686_[8, 12288, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:01,921|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_99933_[4, 10240, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,096|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_90373_[4, 10240, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,364|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93285_[4, 10240, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,435|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_74058_[8, 10240, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,509|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81232_[8, 10240, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,699|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_257_[2, 10240, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,830|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_44486_[2, 10240, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,932|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_99739_[8, 10240, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,968|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_8567_[4, 10240, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:02,978|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_24139_[2, 10240, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,069|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_73406_[2, 10240, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,132|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42193_[1, 10240, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,163|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_44036_[4, 10240, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,184|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23238_[1, 10240, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,227|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_62052_[1, 10240, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,305|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_71246_[2, 10240, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,316|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67587_[1, 10240, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,398|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42645_[1, 10240, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:03,579|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33688_[8, 10240, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:04,350|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53805_[8, 8192, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:04,560|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_8685_[8, 8192, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:05,010|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_76622_[8, 8192, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:05,277|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_80069_[16, 8192, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:05,456|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20510_[16, 8192, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:05,545|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_61338_[4, 8192, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:05,869|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_60140_[4, 8192, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:05,962|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41306_[16, 8192, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,066|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45178_[8, 8192, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,177|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27913_[4, 8192, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,198|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38844_[4, 8192, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,261|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_63763_[2, 8192, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,290|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70452_[8, 8192, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,394|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_70601_[2, 8192, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,455|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_56517_[1, 8192, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,528|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69091_[4, 8192, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,564|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_70255_[1, 8192, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,574|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13630_[2, 8192, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,633|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_5155_[1, 8192, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,647|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75588_[1, 8192, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,689|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_35523_[2, 8192, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,707|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_96004_[2, 8192, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:06,781|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_87021_[1, 8192, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:07,234|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_17885_[16, 8192, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:07,491|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39457_[8, 6144, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:07,659|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_67522_[8, 6144, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,176|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_97582_[16, 6144, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,374|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92392_[8, 6144, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,382|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_81896_[16, 6144, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,569|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_32085_[4, 6144, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,760|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_95112_[4, 6144, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,762|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45258_[16, 6144, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,805|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_69538_[8, 6144, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,884|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_40604_[4, 6144, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,941|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_22281_[8, 6144, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,964|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40063_[4, 6144, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:08,987|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_974_[2, 6144, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,044|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55136_[2, 6144, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,098|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_84322_[1, 6144, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,167|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_8160_[1, 6144, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,190|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19353_[2, 6144, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,240|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_63202_[1, 6144, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,245|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32921_[1, 6144, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,315|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_46726_[2, 6144, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,324|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1042_[2, 6144, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,327|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_77234_[4, 6144, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,364|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10738_[1, 6144, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:09,519|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_60187_[16, 6144, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:10,485|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25147_[16, 4096, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:10,573|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_94179_[16, 4096, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:10,995|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_37572_[16, 4096, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:11,347|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_55636_[32, 4096, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:11,575|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_76638_[8, 4096, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:11,669|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41462_[32, 4096, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:11,996|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_11289_[8, 4096, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,035|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27321_[32, 4096, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,111|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11854_[16, 4096, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,117|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_36994_[8, 4096, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,309|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_93083_[4, 4096, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,371|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_83662_[8, 4096, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,426|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11584_[4, 4096, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,467|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48041_[16, 4096, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,514|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_4319_[4, 4096, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,574|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_79565_[2, 4096, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,630|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_3701_[2, 4096, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,655|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38220_[8, 4096, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,697|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63045_[2, 4096, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,746|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_16909_[1, 4096, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,780|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_41859_[2, 4096, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,836|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14162_[4, 4096, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,865|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87655_[1, 4096, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,867|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_7289_[2, 4096, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,871|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_85408_[4, 4096, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,877|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_57274_[1, 4096, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,888|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_79547_[1, 4096, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,956|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27479_[1, 4096, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:12,963|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_23430_[32, 4096, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:13,681|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25351_[16, 3072, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:13,822|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_72769_[16, 3072, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,022|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94325_[16, 3072, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,435|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54869_[32, 3072, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,441|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55575_[8, 3072, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,660|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_21540_[32, 3072, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,909|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_91912_[16, 3072, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,918|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_25925_[8, 3072, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,928|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_2203_[8, 3072, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:14,990|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78068_[8, 3072, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,001|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_80776_[32, 3072, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,154|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_36910_[4, 3072, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,156|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_8626_[16, 3072, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,190|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_56820_[4, 3072, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,270|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25576_[4, 3072, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,293|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_52472_[2, 3072, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,321|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_29176_[2, 3072, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,408|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_81094_[4, 3072, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,427|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_11874_[2, 3072, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,438|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50522_[8, 3072, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,463|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96845_[2, 3072, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,468|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10763_[4, 3072, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,484|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_92279_[1, 3072, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,519|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_32669_[2, 3072, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,529|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39217_[1, 3072, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,541|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_53721_[1, 3072, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,544|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_21076_[1, 3072, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,611|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5258_[1, 3072, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:15,911|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_18485_[32, 3072, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:16,601|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_98316_[32, 2048, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:16,778|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_46344_[32, 2048, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:17,396|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_55253_[32, 2048, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:17,578|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10565_[64, 2048, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:17,844|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39993_[64, 2048, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:17,937|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_14569_[16, 2048, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,188|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88063_[16, 2048, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,251|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_27550_[16, 2048, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,287|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_42394_[32, 2048, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,398|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_15173_[64, 2048, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,529|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97141_[8, 2048, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,586|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_92980_[16, 2048, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,587|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_44008_[8, 2048, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,627|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13133_[32, 2048, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,727|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58242_[4, 2048, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,790|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_61119_[8, 2048, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,792|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64394_[4, 2048, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,913|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69195_[4, 2048, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,914|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_5101_[8, 2048, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,930|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_75463_[16, 2048, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:18,968|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83058_[4, 2048, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,014|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10850_[2, 2048, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,023|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50246_[2, 2048, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,029|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_97066_[8, 2048, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,046|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_51323_[2, 2048, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,071|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39770_[4, 2048, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,074|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_39024_[2, 2048, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,085|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91186_[1, 2048, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,097|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_88252_[1, 2048, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,153|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61120_[1, 2048, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,157|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45108_[2, 2048, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,160|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95469_[1, 2048, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,175|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_71093_[1, 2048, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,406|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_7047_[64, 2048, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:19,949|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88580_[32, 1536, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:20,082|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_32938_[32, 1536, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:20,516|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36186_[32, 1536, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:20,642|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82621_[64, 1536, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:20,910|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22839_[16, 1536, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:20,930|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_60217_[64, 1536, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,068|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10781_[16, 1536, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,190|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_17689_[16, 1536, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,260|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65027_[32, 1536, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,332|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_86700_[64, 1536, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,408|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_79833_[32, 1536, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,417|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59542_[8, 1536, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,494|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39150_[8, 1536, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,527|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_16777_[16, 1536, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,636|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_31732_[8, 1536, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,642|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_47731_[4, 1536, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,668|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80697_[8, 1536, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,663|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_20475_[4, 1536, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,691|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59301_[16, 1536, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,730|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_13803_[4, 1536, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,754|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_65142_[2, 1536, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,772|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_78878_[2, 1536, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,786|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_55535_[4, 1536, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,813|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27300_[8, 1536, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,820|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_8437_[2, 1536, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,846|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_54684_[2, 1536, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,859|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_79472_[4, 1536, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,870|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19714_[1, 1536, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,878|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_17284_[1, 1536, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,889|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_67690_[1, 1536, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,904|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_68090_[1, 1536, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,920|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3409_[2, 1536, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:21,980|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_94853_[1, 1536, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:22,077|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_91157_[64, 1536, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:22,977|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_68017_[64, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:23,150|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_14891_[64, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:23,621|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_4671_[64, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:23,941|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_53812_[128, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,134|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_9971_[32, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,203|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77366_[128, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,556|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83236_[32, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,610|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_58525_[32, 1024, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,620|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_67828_[128, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,804|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55198_[64, 1024, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,907|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71501_[32, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,937|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5308_[16, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,969|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_69355_[64, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:24,973|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_4470_[16, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,122|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_91490_[8, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,139|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76523_[8, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,176|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99080_[32, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,217|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_71865_[16, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,290|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33959_[4, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,291|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29718_[16, 1024, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,332|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_440_[8, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,333|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_11687_[8, 1024, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,377|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_4090_[4, 1024, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,387|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33850_[4, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,409|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10305_[8, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,436|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_44188_[16, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,438|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_55708_[2, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,464|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22342_[4, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,469|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_1018_[2, 1024, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,479|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11796_[2, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,490|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_96302_[2, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,518|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36033_[4, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,546|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_64836_[1, 1024, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,550|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59658_[1, 1024, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,564|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5968_[2, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,565|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_26600_[1, 1024, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,576|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31358_[1, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,622|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_75265_[1, 1024, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:25,742|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_68147_[128, 1024, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:26,621|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99357_[128, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:26,772|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14583_[128, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:27,155|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_2250_[128, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:27,674|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22547_[256, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:27,718|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10548_[64, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:27,995|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_4057_[256, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,221|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66702_[64, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,285|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_26621_[64, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,312|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45755_[128, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,479|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_83634_[64, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,502|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_70275_[128, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,565|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42987_[256, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,588|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_86970_[32, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,637|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_99953_[32, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,754|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_25112_[16, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,798|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_92771_[16, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,850|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_50993_[32, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,942|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_85320_[16, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,970|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_12458_[16, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,986|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71493_[32, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:28,999|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_70483_[64, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,001|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_38886_[32, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,021|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_72021_[8, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,038|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_41471_[8, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,072|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_88563_[8, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,078|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_17134_[16, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,098|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69443_[4, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,105|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86778_[4, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,102|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_51455_[8, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,149|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_83725_[4, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,171|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_56629_[4, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,177|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_6881_[2, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,182|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_15438_[8, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,182|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63453_[2, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,186|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_98573_[4, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,207|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75362_[2, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,254|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_7106_[1, 512, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,260|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_92708_[1, 512, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,273|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34451_[1, 512, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,271|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_94338_[2, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,292|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_5664_[1, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,304|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_85736_[1, 512, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,316|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_4710_[2, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,433|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99404_[256, 512, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,837|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_50616_[128, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:29,921|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_382_[128, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,185|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_63133_[128, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,446|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_82606_[256, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,486|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_51317_[64, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,577|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_30926_[256, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,691|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_64638_[64, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,699|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_76894_[128, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,781|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90053_[64, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,819|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38153_[256, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,839|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_21679_[128, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,856|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94737_[32, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,906|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_56025_[64, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:30,963|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_41238_[32, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,000|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81866_[16, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,057|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_4333_[16, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,058|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_28139_[32, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,068|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45088_[16, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,112|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_29608_[32, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,131|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_55667_[32, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,133|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_18557_[64, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,159|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_96103_[8, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,199|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53808_[8, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,205|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_15835_[16, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,217|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83447_[8, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,223|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90558_[16, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,228|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65846_[8, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,245|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_65521_[4, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,265|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_79235_[256, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,270|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_9753_[8, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,279|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_2104_[4, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,304|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_68758_[4, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,318|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24989_[4, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,327|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_65111_[2, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,338|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75330_[4, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,357|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_66181_[2, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,363|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_42894_[2, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,363|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_4099_[2, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,395|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_30585_[1, 256, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,401|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66685_[2, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,402|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96122_[1, 256, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,401|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80368_[1, 256, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,418|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_60251_[1, 256, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,425|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_49476_[1, 256, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,687|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_89319_[128, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,725|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30406_[128, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,807|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62078_[128, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,970|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_64303_[256, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:31,986|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_25190_[64, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,094|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_74762_[256, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,109|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50862_[64, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,131|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_53391_[128, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,159|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92098_[64, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,174|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_2389_[256, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,215|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_14714_[64, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,221|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_30209_[32, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,223|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_51237_[128, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,257|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_12433_[32, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,282|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_67168_[16, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,298|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_84050_[32, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,304|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5542_[32, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,337|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_78692_[16, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,379|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_7982_[32, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,398|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55679_[16, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,406|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_50592_[64, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,410|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20685_[8, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,426|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_38954_[16, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,438|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_17934_[16, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,455|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52333_[8, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,458|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_61071_[8, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,478|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31014_[8, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,490|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_47454_[256, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,500|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_44505_[4, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,504|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28191_[4, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,524|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_35624_[4, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,534|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_55875_[8, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,558|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_116_[4, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,563|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_9319_[2, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,565|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63550_[4, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,585|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_37603_[2, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,586|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1366_[1, 128, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,592|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7954_[2, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,599|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29924_[2, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,609|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75785_[1, 128, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,621|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23944_[2, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,639|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_4134_[1, 128, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,644|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_90876_[1, 128, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,655|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_83746_[1, 128, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,813|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81503_[128, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,822|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_65425_[128, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,870|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_90111_[128, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,890|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_89498_[256, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,926|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_87886_[256, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:32,964|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_55362_[64, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,012|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_64878_[256, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,014|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_26351_[128, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,030|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31894_[64, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,072|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30004_[64, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,078|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_87015_[32, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,101|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10340_[128, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,123|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_83231_[32, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,131|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46230_[64, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,135|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_22504_[64, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,181|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_32300_[32, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,179|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_82824_[32, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,191|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39208_[256, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,194|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_76957_[16, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,203|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_28377_[16, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,205|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_90819_[16, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,247|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_4781_[32, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,250|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_86802_[16, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,259|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_10935_[8, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,280|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_38777_[8, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,288|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43882_[8, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,301|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37090_[8, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,305|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40816_[8, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,308|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_39397_[16, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,330|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_21880_[4, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,337|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74454_[4, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,344|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_86554_[2, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,368|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37980_[4, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,383|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24612_[4, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,397|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82435_[2, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,405|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_89780_[2, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,411|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5592_[2, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,418|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_69758_[4, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,424|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_44869_[1, 64, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,432|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25867_[1, 64, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,435|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55595_[1, 64, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,453|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_16594_[2, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,458|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62813_[1, 64, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,459|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81998_[1, 64, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,537|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_80553_[128, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,589|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43798_[256, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,607|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_95816_[128, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,614|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36552_[256, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,627|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81689_[128, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,651|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_16487_[128, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,659|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_4528_[256, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,698|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_75410_[128, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,718|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8273_[64, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,732|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_41892_[64, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,759|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86112_[64, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,772|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_56007_[32, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,773|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60197_[32, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,774|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_56557_[64, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,778|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_74112_[256, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,788|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_90694_[32, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,818|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40679_[64, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,846|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_79792_[16, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,853|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_78414_[16, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,861|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72183_[16, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,862|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46195_[32, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,878|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_41644_[16, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,893|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61251_[16, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,899|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_84149_[32, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,916|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42044_[8, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,936|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_66233_[8, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,941|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_52818_[4, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,948|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_4315_[8, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,948|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10594_[8, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,963|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_4221_[8, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,994|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_85016_[4, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,994|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56653_[2, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:33,998|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_25831_[4, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,003|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_46352_[2, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,007|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_57512_[4, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,028|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93618_[4, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,036|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46923_[2, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,047|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_43503_[1, 32, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,055|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_32183_[1, 32, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,055|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59888_[1, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,061|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_90367_[1, 32, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,063|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85680_[2, 32, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,077|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8330_[2, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,085|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98220_[1, 32, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,172|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75896_[256, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,177|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_9920_[128, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,187|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_11798_[128, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,188|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83129_[256, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,203|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69367_[256, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,209|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63635_[128, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,245|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_79957_[64, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,260|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_81292_[64, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,277|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90385_[64, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,279|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_3977_[128, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,308|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35202_[64, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,313|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11916_[32, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,314|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_29714_[64, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,346|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_34172_[32, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,357|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72866_[32, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,368|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47309_[16, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,378|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7966_[256, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,393|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_54825_[32, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,394|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_15968_[16, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,394|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_26184_[128, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,412|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_51511_[32, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,451|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_9014_[16, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,453|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8962_[16, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,459|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_89137_[16, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,463|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_38513_[8, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,465|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_49988_[8, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,474|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_95743_[8, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,488|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_93708_[8, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,492|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_31547_[8, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,493|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_25822_[4, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,499|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_32069_[4, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,536|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71231_[2, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,541|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54045_[2, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,541|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31554_[4, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,545|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58135_[2, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,548|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_79951_[1, 16, 16, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,549|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_30912_[1, 16, 16, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,551|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59416_[4, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,553|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_75191_[1, 16, 16, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,555|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55906_[1, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,559|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_43109_[4, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,568|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_80649_[1, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,574|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34694_[2, 16, 16, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:34,575|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_11221_[2, 16, 16, 16, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:35,418|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_37844_[4, 16384, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:35,502|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_49132_[4, 16384, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:35,645|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53773_[2, 16384, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:35,754|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_662_[4, 16384, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:35,894|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42842_[2, 16384, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,007|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_22807_[2, 16384, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,126|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_6031_[1, 16384, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,221|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_63803_[8, 16384, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,269|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_63463_[1, 16384, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,340|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_21742_[2, 16384, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,366|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_44958_[1, 16384, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,434|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_37151_[8, 16384, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,460|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_97087_[1, 16384, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,634|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_47798_[4, 16384, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:36,924|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60038_[8, 16384, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,049|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43370_[4, 12288, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,232|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_73287_[4, 12288, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,384|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_33268_[2, 12288, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,462|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_87966_[8, 12288, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,541|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_29485_[4, 12288, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,616|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_61441_[2, 12288, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,726|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52638_[1, 12288, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,781|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31071_[8, 12288, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,803|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99741_[2, 12288, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,819|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_49817_[1, 12288, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,882|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_74697_[1, 12288, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,885|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42100_[2, 12288, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:37,965|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94531_[1, 12288, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,010|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_69533_[4, 12288, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,170|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_37395_[8, 12288, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,437|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63912_[4, 10240, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,556|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55017_[4, 10240, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,750|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66650_[2, 10240, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,814|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_55874_[8, 10240, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,824|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_32667_[4, 10240, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,879|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_24779_[2, 10240, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,892|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62093_[2, 10240, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:38,978|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_11092_[1, 10240, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:39,043|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_50228_[8, 10240, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:39,048|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_68979_[1, 10240, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:39,114|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_29234_[1, 10240, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:39,174|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_75385_[1, 10240, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:39,181|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13493_[2, 10240, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:39,206|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20114_[4, 10240, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:39,386|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22033_[8, 10240, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,004|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_35637_[8, 8192, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,141|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_87887_[8, 8192, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,423|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_82339_[8, 8192, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,437|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_41801_[4, 8192, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,519|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_70261_[4, 8192, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,682|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20085_[4, 8192, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,718|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_41745_[16, 8192, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,745|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_6080_[2, 8192, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,939|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77002_[2, 8192, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:40,990|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_54628_[16, 8192, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,003|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_72766_[2, 8192, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,033|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_79475_[1, 8192, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,061|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_55950_[4, 8192, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,069|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21050_[2, 8192, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,087|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_22211_[1, 8192, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,139|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_35306_[1, 8192, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,187|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_48616_[1, 8192, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,384|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_1661_[16, 8192, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,425|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_61781_[8, 8192, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,771|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_48735_[8, 6144, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:41,902|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45714_[8, 6144, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,142|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_24406_[4, 6144, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,289|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_62869_[4, 6144, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,291|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35209_[8, 6144, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,305|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52670_[4, 6144, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,324|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_65279_[16, 6144, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,481|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96078_[2, 6144, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,485|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_46937_[16, 6144, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,521|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_63433_[2, 6144, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,582|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_27898_[2, 6144, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,584|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1894_[1, 6144, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,636|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42268_[4, 6144, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,682|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_47519_[1, 6144, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,702|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12792_[1, 6144, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,728|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28493_[8, 6144, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,731|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_45283_[2, 6144, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,753|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31889_[1, 6144, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:42,901|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25128_[16, 6144, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:43,571|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_31713_[16, 4096, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:43,657|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_77256_[16, 4096, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:43,922|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_61423_[16, 4096, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,041|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_44840_[8, 4096, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,051|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19279_[8, 4096, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,170|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24526_[8, 4096, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,274|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_51487_[4, 4096, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,424|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_90315_[32, 4096, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,424|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_63864_[4, 4096, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,552|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77741_[2, 4096, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,578|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_3515_[32, 4096, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,607|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_38321_[4, 4096, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,616|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_41624_[4, 4096, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,625|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50297_[8, 4096, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,699|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45176_[2, 4096, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,724|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_53391_[1, 4096, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,733|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_68616_[1, 4096, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,744|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_33479_[2, 4096, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,753|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_86809_[16, 4096, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,778|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_76634_[2, 4096, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,789|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_71538_[1, 4096, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:44,853|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_9594_[1, 4096, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:45,103|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53219_[32, 4096, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:45,398|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37040_[16, 3072, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:45,532|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_66393_[16, 3072, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:45,740|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_54178_[8, 3072, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:45,769|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11268_[16, 3072, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:45,950|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_9254_[8, 3072, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:45,967|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_94798_[8, 3072, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,137|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31987_[32, 3072, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,137|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91276_[4, 3072, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,175|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_22650_[4, 3072, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,180|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_10813_[32, 3072, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,190|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81949_[4, 3072, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,265|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8883_[8, 3072, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,304|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_57176_[2, 3072, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,323|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_47987_[16, 3072, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,330|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_70978_[2, 3072, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,398|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_925_[2, 3072, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,414|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_6899_[2, 3072, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,414|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_83103_[4, 3072, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,417|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_27708_[1, 3072, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,419|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_91231_[1, 3072, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,426|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68504_[1, 3072, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,451|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_44571_[1, 3072, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:46,479|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_13761_[32, 3072, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:47,250|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_33058_[32, 2048, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:47,352|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15008_[32, 2048, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:47,535|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_85674_[16, 2048, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:47,629|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_37604_[32, 2048, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:47,715|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12088_[16, 2048, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:47,874|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_30778_[16, 2048, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:47,958|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_66060_[8, 2048, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,108|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_36939_[8, 2048, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,108|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_95079_[64, 2048, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,171|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_33795_[16, 2048, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,195|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72983_[8, 2048, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,238|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_66974_[4, 2048, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,273|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_2412_[8, 2048, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,292|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94296_[4, 2048, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,345|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5038_[2, 2048, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,349|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_7524_[4, 2048, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,382|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30396_[64, 2048, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,434|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_64083_[2, 2048, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,435|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_91407_[4, 2048, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,440|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5626_[1, 2048, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,466|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53500_[2, 2048, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,479|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_46319_[1, 2048, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,498|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_99682_[2, 2048, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,498|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_57972_[32, 2048, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,508|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83022_[1, 2048, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,510|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2353_[1, 2048, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:48,824|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_72140_[64, 2048, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,118|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45949_[32, 1536, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,231|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_13281_[32, 1536, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,437|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_830_[32, 1536, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,491|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46797_[16, 1536, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,659|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50068_[16, 1536, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,695|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_42103_[64, 1536, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,696|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_1586_[16, 1536, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,812|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_98266_[8, 1536, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,882|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24391_[8, 1536, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,940|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_52115_[8, 1536, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,942|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15928_[16, 1536, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,963|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_14635_[8, 1536, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:49,974|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80665_[64, 1536, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,022|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47396_[4, 1536, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,040|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59907_[4, 1536, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,055|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_77968_[2, 1536, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,091|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_11649_[4, 1536, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,094|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_50476_[4, 1536, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,117|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_45569_[2, 1536, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,142|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_29092_[2, 1536, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,150|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_41531_[1, 1536, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,175|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_11912_[2, 1536, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,177|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_24140_[32, 1536, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,179|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_17409_[1, 1536, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,183|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85512_[1, 1536, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,200|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_38326_[1, 1536, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,299|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_73830_[64, 1536, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:50,986|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_36878_[64, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,190|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99096_[64, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,368|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_67685_[32, 1024, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,401|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_94369_[32, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,454|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_44503_[64, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,735|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_46299_[16, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,770|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_54783_[32, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,792|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_62966_[128, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:51,972|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_68804_[16, 1024, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,002|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63298_[16, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,006|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_41640_[32, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,081|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86954_[8, 1024, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,084|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35730_[8, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,086|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_39243_[128, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,123|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_78000_[16, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,178|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66098_[8, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,192|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32895_[8, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,195|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_23929_[4, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,200|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11437_[4, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,266|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_496_[4, 1024, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,272|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35927_[4, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,277|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_92523_[2, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,285|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_71021_[64, 1024, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,295|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49899_[2, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,294|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_18942_[2, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,319|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_49842_[2, 1024, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,336|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_88558_[1, 1024, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,344|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13183_[1, 1024, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,348|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_41818_[1, 1024, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,349|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_62170_[1, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:52,556|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99783_[128, 1024, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,200|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_29777_[128, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,299|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1401_[128, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,546|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_83577_[128, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,642|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63419_[64, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,694|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_36622_[64, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,869|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87557_[64, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,917|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_89592_[32, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:53,960|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_3043_[256, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,121|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48052_[32, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,174|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_63065_[64, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,239|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_24950_[32, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,239|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_17396_[16, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,247|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_16635_[32, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,264|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_31202_[256, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,314|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_37911_[16, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,323|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30885_[8, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,333|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_92350_[16, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,370|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_69109_[8, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,404|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_62758_[4, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,416|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_76646_[8, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,425|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_51750_[16, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,440|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50490_[128, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,457|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_2085_[8, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,463|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_55650_[4, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,474|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_74506_[4, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,491|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_43648_[2, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,509|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_3489_[2, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,514|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3943_[2, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,528|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48149_[1, 512, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,528|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52088_[4, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,545|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46075_[1, 512, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,565|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43327_[2, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,565|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_38853_[1, 512, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,564|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41109_[1, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:54,782|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74755_[256, 512, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,013|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_90557_[128, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,085|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_90672_[128, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,165|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_92600_[128, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,256|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_32039_[64, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,372|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_9784_[64, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,385|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_68274_[64, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,387|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_92207_[256, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,499|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33714_[64, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,502|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_76769_[32, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,520|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_65953_[32, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,529|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37889_[256, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,557|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_35998_[32, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,584|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92400_[32, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,629|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_85613_[16, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,667|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92054_[16, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,678|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_25223_[8, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,682|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45364_[16, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,684|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11792_[8, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,693|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93298_[8, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,710|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_91901_[128, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,711|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_93652_[16, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,768|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_43073_[4, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,771|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53960_[4, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,775|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_53564_[4, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,783|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_29165_[256, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,790|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40119_[2, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,799|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8738_[2, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,810|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_40800_[4, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,810|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26746_[8, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,859|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_29882_[1, 256, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,860|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_60630_[1, 256, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,865|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65206_[2, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,869|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24349_[2, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,871|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_38138_[1, 256, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:55,874|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96039_[1, 256, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,095|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_23909_[128, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,146|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_98252_[128, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,155|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_75425_[64, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,196|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_6244_[128, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,232|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_88757_[64, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,277|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_51046_[256, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,316|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19433_[64, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,333|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_39439_[32, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,335|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_9992_[64, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,347|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90924_[256, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,367|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_79749_[32, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,420|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_3044_[32, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,424|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_32987_[16, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,429|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26927_[16, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,439|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_18473_[16, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,475|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_50874_[16, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,507|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_1155_[32, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,507|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_49651_[8, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,514|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48823_[8, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,516|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87178_[128, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,529|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_81689_[8, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,537|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_20959_[8, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,582|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_71765_[256, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,583|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_44325_[4, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,597|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_46601_[4, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,598|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14921_[4, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,604|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72015_[4, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,615|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95612_[2, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,633|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10653_[2, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,633|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_80002_[2, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,637|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_67368_[1, 128, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,638|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_95590_[1, 128, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,651|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_24517_[1, 128, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,655|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_74749_[1, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,664|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_53674_[2, 128, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,769|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82235_[128, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,832|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_1017_[128, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_50909_[128, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,860|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38086_[64, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,863|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_73429_[256, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,891|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_96781_[64, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,925|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82029_[256, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,932|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_48951_[32, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,941|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96450_[64, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,983|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_45933_[128, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,993|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45298_[64, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:56,996|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_32107_[32, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,013|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_22236_[32, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,022|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70154_[256, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,022|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_66374_[16, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,041|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_67296_[16, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,058|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80244_[16, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,061|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55396_[32, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,115|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_51479_[8, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,120|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_3148_[8, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,125|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_19823_[8, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,125|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_13703_[16, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,129|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_86253_[4, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,126|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10356_[8, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,137|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6738_[4, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,142|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34028_[4, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,172|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56921_[2, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,179|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_93617_[1, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,180|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_31051_[1, 64, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,189|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_22188_[2, 64, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,202|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35129_[2, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,218|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_36253_[2, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,229|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_24648_[1, 64, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,232|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_59077_[4, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,235|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_20489_[1, 64, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,357|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_16982_[128, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,363|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99086_[128, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,368|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_79903_[256, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,395|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77848_[256, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,401|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_44875_[64, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,425|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_68008_[256, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,434|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19150_[128, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,471|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36100_[64, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,473|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_56460_[64, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,477|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_80800_[128, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,487|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_87213_[32, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,487|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_34531_[64, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,493|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_18354_[32, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,548|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_80929_[16, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,551|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_56502_[16, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,554|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_3353_[8, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,557|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_6938_[16, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,558|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_50402_[8, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,573|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_25283_[32, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,599|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40819_[32, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,605|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71472_[8, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,614|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_63377_[4, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,617|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3820_[16, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,632|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_22977_[4, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,640|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_90489_[2, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,649|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72100_[4, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,661|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13666_[8, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,664|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27626_[2, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,669|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_58185_[2, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,675|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27427_[1, 32, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,699|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_18135_[4, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,706|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56476_[1, 32, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,707|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_10145_[1, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,717|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48738_[2, 32, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,720|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_42526_[1, 32, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,805|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_22650_[256, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,806|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11988_[256, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,819|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59331_[128, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,829|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_27492_[128, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,836|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_57642_[128, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,859|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_5861_[256, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,888|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_23325_[64, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,889|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_97099_[64, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,891|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24795_[64, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,914|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_15889_[32, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,926|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_90990_[32, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,933|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_46256_[64, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,939|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_41535_[32, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,963|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_93220_[32, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,964|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_20100_[128, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:57,993|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56753_[16, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,001|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_83028_[8, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,003|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24031_[16, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,027|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31740_[16, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,033|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21644_[8, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,033|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_16748_[16, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,038|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_51429_[8, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,039|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54374_[4, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,065|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_58198_[4, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,068|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59047_[2, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,074|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_87174_[4, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,078|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_26733_[1, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,084|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_36694_[2, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,089|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_85837_[1, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,092|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_4552_[1, 16, 12, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,095|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_69941_[2, 16, 12, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,099|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88441_[4, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,100|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_84647_[8, 16, 12, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,102|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_94601_[1, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,110|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_6343_[2, 16, 12, 12, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,720|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29409_[4, 16384, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,857|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45639_[4, 16384, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:58,863|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93893_[2, 16384, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,068|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_12572_[4, 16384, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,071|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_61597_[2, 16384, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,254|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_22458_[1, 16384, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,288|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_69593_[2, 16384, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,301|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99033_[8, 16384, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,427|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_97699_[2, 16384, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,468|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_24699_[1, 16384, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,474|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34031_[1, 16384, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,512|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94106_[8, 16384, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,568|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_28842_[1, 16384, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,576|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_9873_[4, 16384, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,946|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_98782_[8, 16384, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:20:59,976|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50413_[4, 12288, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,159|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_27460_[4, 12288, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,228|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_733_[2, 12288, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,234|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_88252_[8, 12288, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,319|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43781_[4, 12288, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,463|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81144_[1, 12288, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,466|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_7354_[2, 12288, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,514|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_73281_[2, 12288, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,531|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64369_[1, 12288, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,604|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86632_[4, 12288, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,615|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_22371_[8, 12288, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,619|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_22461_[2, 12288, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,642|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_56668_[1, 12288, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,703|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_73776_[1, 12288, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:00,906|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27288_[8, 12288, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,014|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_96094_[4, 10240, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,129|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_16199_[4, 10240, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,228|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_19440_[2, 10240, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,269|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80155_[8, 10240, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,353|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_3923_[4, 10240, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,391|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81641_[2, 10240, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,393|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41687_[2, 10240, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,446|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_14545_[8, 10240, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,486|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_77539_[1, 10240, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,536|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84959_[1, 10240, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,537|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_12346_[1, 10240, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,551|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_67794_[2, 10240, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,566|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_34032_[1, 10240, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,601|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80219_[4, 10240, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:01,835|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_26756_[8, 10240, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,146|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_99139_[8, 8192, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,273|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_55797_[8, 8192, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,482|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_19946_[4, 8192, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,579|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_8572_[8, 8192, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,607|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63128_[4, 8192, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,672|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_95264_[16, 8192, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,688|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_37193_[4, 8192, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,772|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34583_[2, 8192, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,863|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_23120_[2, 8192, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,959|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_32508_[2, 8192, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,979|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_83119_[2, 8192, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,991|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60754_[4, 8192, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:02,995|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_4093_[1, 8192, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,010|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_82676_[1, 8192, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,012|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70740_[8, 8192, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,078|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_95600_[1, 8192, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,089|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_12054_[16, 8192, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,137|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_18179_[1, 8192, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,458|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13592_[16, 8192, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,530|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_20618_[8, 6144, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,716|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_70091_[8, 6144, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,781|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_4037_[4, 6144, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,879|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53582_[16, 6144, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:03,889|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_40950_[8, 6144, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,006|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_96593_[4, 6144, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,019|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90360_[4, 6144, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,027|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_73928_[2, 6144, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,122|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_85518_[16, 6144, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,142|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_1658_[8, 6144, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,162|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_80804_[2, 6144, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,178|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_51997_[4, 6144, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,186|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_77661_[2, 6144, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,200|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_57288_[1, 6144, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,222|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75881_[1, 6144, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,222|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_38862_[2, 6144, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,260|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_51519_[1, 6144, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,317|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59973_[1, 6144, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,474|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_75297_[16, 6144, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,826|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40063_[16, 4096, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:04,978|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_88748_[16, 4096, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,159|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_44519_[8, 4096, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,239|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_42266_[8, 4096, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,259|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76790_[16, 4096, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,378|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_35116_[32, 4096, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,396|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_20457_[8, 4096, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,425|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_97702_[4, 4096, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,570|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_43984_[4, 4096, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,634|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28932_[4, 4096, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,655|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24179_[2, 4096, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,670|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3466_[4, 4096, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,677|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94014_[8, 4096, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,687|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_79551_[32, 4096, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,687|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_24257_[16, 4096, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,700|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_38626_[2, 4096, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,741|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_91511_[1, 4096, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,761|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_31747_[2, 4096, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,785|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94756_[1, 4096, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,809|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_2045_[1, 4096, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,819|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_73866_[1, 4096, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:05,835|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34985_[2, 4096, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,127|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_21263_[32, 4096, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,272|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36424_[16, 3072, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,402|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_62178_[16, 3072, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,535|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_44575_[8, 3072, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,561|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53275_[16, 3072, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,608|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_23636_[32, 3072, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,697|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_71517_[8, 3072, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,704|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_70458_[8, 3072, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,726|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77872_[4, 3072, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,792|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84511_[32, 3072, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,851|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_592_[4, 3072, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,865|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_43774_[4, 3072, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,881|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_21017_[2, 3072, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,891|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_17868_[2, 3072, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,900|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_53254_[16, 3072, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,926|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_46379_[4, 3072, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,966|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33691_[1, 3072, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,971|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_84603_[8, 3072, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,972|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53476_[2, 3072, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:06,996|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_69206_[1, 3072, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,004|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82982_[1, 3072, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,037|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_64413_[1, 3072, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,043|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_3105_[2, 3072, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,215|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_1139_[32, 3072, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,582|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_63113_[32, 2048, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,774|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_2708_[32, 2048, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,896|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31406_[16, 2048, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:07,961|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96680_[16, 2048, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,020|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_80574_[32, 2048, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,185|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63429_[8, 2048, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,188|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_58197_[64, 2048, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,195|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_2364_[16, 2048, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,342|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64671_[8, 2048, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,369|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_6990_[8, 2048, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,394|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_39902_[16, 2048, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,398|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_99386_[4, 2048, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,434|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54826_[4, 2048, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,444|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50704_[64, 2048, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,461|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_940_[8, 2048, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,501|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_39974_[32, 2048, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,532|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_75956_[2, 2048, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,534|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_56278_[4, 2048, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,534|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_8974_[2, 2048, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,554|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_92675_[2, 2048, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,594|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_28171_[4, 2048, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,602|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_93578_[1, 2048, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,602|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_40310_[2, 2048, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,615|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_94625_[1, 2048, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,617|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_96051_[1, 2048, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,629|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43727_[1, 2048, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:08,802|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_67394_[64, 2048, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,086|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26338_[32, 1536, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,169|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_82602_[32, 1536, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,336|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30900_[16, 1536, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,382|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10728_[32, 1536, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,385|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23109_[16, 1536, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,473|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_51634_[64, 1536, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,480|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13446_[16, 1536, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,513|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_42339_[8, 1536, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,620|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_24028_[8, 1536, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,670|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_78947_[64, 1536, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,692|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_44069_[8, 1536, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,693|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_2846_[8, 1536, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,698|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_66621_[4, 1536, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,699|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_43437_[32, 1536, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,736|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_15680_[16, 1536, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,744|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_9192_[4, 1536, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,775|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_69409_[2, 1536, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,788|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_97338_[4, 1536, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,790|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27594_[2, 1536, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,815|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_16044_[1, 1536, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,842|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_96423_[2, 1536, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,847|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_14404_[1, 1536, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,851|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_41601_[2, 1536, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,860|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_30380_[1, 1536, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,866|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1551_[1, 1536, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:09,869|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67295_[4, 1536, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:10,111|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_592_[64, 1536, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:10,463|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_92968_[64, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:10,581|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_94838_[64, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:10,785|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33010_[32, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:10,877|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_20195_[64, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:10,881|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_82775_[32, 1024, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:10,967|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_47379_[32, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,026|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_21988_[128, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,050|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6612_[16, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,161|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_4659_[16, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,244|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_85422_[16, 1024, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,278|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_2701_[8, 1024, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,301|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60847_[16, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,312|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_11797_[32, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,317|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_96125_[64, 1024, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,327|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61718_[8, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,361|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45410_[128, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,370|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_44487_[8, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,387|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_20201_[4, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,411|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_7266_[4, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,438|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_55871_[4, 1024, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,440|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10471_[2, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,447|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_34371_[2, 1024, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,473|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69762_[2, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,491|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_88863_[8, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,492|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_36541_[4, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,512|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_78472_[1, 1024, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,525|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_50479_[1, 1024, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,527|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27614_[1, 1024, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,535|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_17892_[2, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,552|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_67511_[1, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:11,776|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91997_[128, 1024, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,127|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_15469_[128, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,278|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_76973_[128, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,440|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_82934_[64, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,496|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_76267_[128, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,570|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95998_[64, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,690|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_72561_[64, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,731|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_91107_[32, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,734|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_6731_[256, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,866|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12503_[32, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,891|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5368_[32, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,938|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_31225_[16, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,949|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_86027_[64, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,974|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_89359_[256, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,977|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72415_[16, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:12,979|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_5092_[128, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,004|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_67846_[32, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,043|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_67662_[8, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,062|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_26775_[16, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,083|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_40668_[8, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,093|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_25410_[8, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,093|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_64368_[8, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,099|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88472_[4, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,109|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_34185_[4, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,174|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46435_[2, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,178|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_80506_[4, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,179|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_91180_[16, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,186|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34860_[4, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,191|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_3980_[2, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,191|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58850_[2, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,204|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_16096_[2, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,231|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_16222_[1, 512, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,235|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52589_[1, 512, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,242|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3517_[1, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,252|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_67498_[1, 512, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,484|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_78611_[256, 512, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,567|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27970_[128, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,632|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_47107_[128, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,777|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_93550_[64, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,786|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_20417_[128, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,825|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_94475_[64, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,899|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_12094_[256, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,916|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_45892_[64, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,941|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_7537_[256, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,995|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_83459_[32, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:13,997|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_10690_[32, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,012|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_68463_[32, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,023|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54332_[128, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,076|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_66851_[16, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,086|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_87248_[16, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,091|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_47063_[64, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,098|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_4232_[16, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,115|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20661_[8, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,138|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_60980_[32, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,171|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_84674_[8, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,177|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_60180_[8, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,179|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_78320_[16, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,191|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48315_[8, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,209|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_60844_[4, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,227|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33348_[256, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,232|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_66377_[4, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,244|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_71104_[4, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,277|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_4454_[4, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,277|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_9733_[2, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,282|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_82323_[2, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,298|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33551_[1, 256, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,301|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3491_[2, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,307|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20077_[2, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,316|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5392_[1, 256, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,322|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_16172_[1, 256, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,328|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_93746_[1, 256, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,480|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_59758_[128, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,513|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_47310_[128, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,552|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_6060_[64, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,599|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_91464_[128, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,612|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_99516_[256, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,626|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_80435_[64, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,697|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_51091_[256, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,702|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5928_[64, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,720|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94558_[32, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,724|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_67964_[128, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,735|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_43640_[64, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,741|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_68498_[32, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,768|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_83715_[32, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,793|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_16109_[16, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,794|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_69054_[16, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,807|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74277_[8, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,834|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_64503_[16, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,841|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42026_[32, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,849|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60303_[8, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,858|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61305_[256, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,877|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82579_[8, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,883|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_95600_[16, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,903|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_34355_[4, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,925|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70909_[8, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,927|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_28545_[4, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,945|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_22055_[2, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,949|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_27156_[4, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,951|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75123_[2, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,962|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_29758_[2, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,979|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90322_[4, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,987|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_11918_[2, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,991|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_5915_[1, 128, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:14,997|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62643_[1, 128, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,009|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_88847_[1, 128, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,017|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_49029_[1, 128, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,110|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_59337_[128, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,144|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_16129_[256, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,176|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33405_[128, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,184|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_49228_[64, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,201|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_52212_[128, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,216|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_74622_[256, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,221|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_9758_[64, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,240|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_11757_[128, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,268|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72516_[64, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,274|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_78514_[32, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,302|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_60996_[256, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,307|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_11414_[32, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,320|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_76847_[32, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,330|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_70687_[16, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,334|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_46645_[16, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,339|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58445_[32, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,367|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_1216_[16, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,373|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_38955_[64, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,394|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_53686_[8, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,428|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_52351_[8, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,444|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_61755_[16, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,448|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_23656_[4, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,452|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_42818_[4, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,452|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_92808_[8, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,458|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_41545_[4, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,451|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_58325_[8, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,467|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_23472_[4, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,496|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_46190_[1, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,501|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_19168_[1, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,518|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_8370_[2, 64, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,527|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_66827_[1, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,532|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_71965_[2, 64, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,539|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_56734_[1, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,525|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_43504_[2, 64, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,546|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_69993_[2, 64, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,637|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_21655_[128, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,654|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_30201_[128, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,657|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33393_[64, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,684|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63546_[256, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,692|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_96330_[128, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,694|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_98568_[128, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,724|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_55973_[64, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,734|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_26940_[256, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,739|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_26130_[64, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,770|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50771_[32, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,784|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_50183_[32, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,784|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_58255_[32, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,789|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_75876_[64, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,793|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_61154_[32, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,794|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_9261_[16, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,832|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_71789_[16, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,835|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_38061_[16, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,864|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_15251_[8, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,864|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70505_[8, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,873|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_197_[16, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,876|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_62803_[8, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,878|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_89693_[4, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,888|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_2505_[4, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,893|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_91096_[8, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,933|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43532_[2, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,938|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_46077_[1, 32, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,952|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55587_[4, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,953|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85987_[2, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,955|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_77877_[1, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,962|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_80872_[1, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,962|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_85566_[2, 32, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,963|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34057_[4, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,963|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39093_[1, 32, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,964|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_59737_[2, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:15,965|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61329_[256, 32, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,034|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48889_[128, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,074|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73168_[128, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,079|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_72645_[128, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,081|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_76684_[64, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,093|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_50798_[128, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,100|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_5794_[64, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,137|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_49174_[256, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,139|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_77560_[256, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,153|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_54627_[64, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,156|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_59175_[256, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,173|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_58409_[32, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,179|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_53561_[32, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,195|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_18031_[32, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,206|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_47420_[64, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,213|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_67395_[16, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,236|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_12225_[16, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,237|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_985_[8, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,251|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61932_[16, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,263|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_13429_[32, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,263|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_48091_[8, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,269|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_27505_[16, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,271|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_23555_[8, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,288|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_86467_[4, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,296|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73378_[2, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,300|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_81807_[1, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,303|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_63886_[2, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,304|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_82975_[1, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,304|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_63463_[4, 16, 8, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,304|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_52280_[8, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,306|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_63063_[2, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,309|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_2940_[1, 16, 8, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,310|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_44364_[1, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,316|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_81429_[4, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,322|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_89482_[2, 16, 8, 8, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,324|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_25568_[4, 16, 8, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,522|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_14448_[2, 16384, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,595|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24510_[2, 16384, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,701|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_87000_[2, 16384, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,702|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72571_[4, 16384, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,727|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_527_[1, 16384, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,738|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_70375_[1, 16384, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,842|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48730_[4, 16384, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:16,872|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_65214_[1, 16384, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,084|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_59363_[8, 16384, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,089|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_77681_[4, 16384, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,132|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81870_[4, 12288, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,254|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19725_[2, 12288, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,263|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_72387_[4, 12288, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,266|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84921_[8, 12288, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,308|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_77181_[8, 16384, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,345|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36302_[2, 12288, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,347|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_7484_[4, 12288, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,372|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_42105_[2, 12288, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,372|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_60707_[1, 12288, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,417|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32460_[1, 12288, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,445|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_81770_[1, 12288, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,473|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7663_[8, 12288, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,597|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_13821_[2, 10240, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,620|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50712_[4, 10240, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,671|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_3556_[2, 10240, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,693|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_65186_[2, 10240, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,705|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_87484_[4, 10240, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,724|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_325_[1, 10240, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,741|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90198_[1, 10240, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,814|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_32437_[8, 10240, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,818|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_13441_[1, 10240, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,846|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19288_[4, 10240, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:17,990|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_88986_[8, 10240, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,048|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45197_[4, 8192, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,135|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_10960_[8, 8192, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,194|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71222_[4, 8192, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,259|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_57111_[2, 8192, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,265|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_75521_[4, 8192, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,307|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60975_[2, 8192, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,330|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_29261_[8, 8192, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,335|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60954_[2, 8192, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,358|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35073_[1, 8192, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,376|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_59029_[1, 8192, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,430|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94250_[1, 8192, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,484|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_6206_[8, 8192, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,497|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_64112_[16, 8192, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,655|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_97114_[8, 6144, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,655|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_18172_[4, 6144, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,730|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_50276_[16, 8192, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,769|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_31977_[4, 6144, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,812|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_25539_[2, 6144, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,825|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_81086_[8, 6144, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,864|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_79131_[2, 6144, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,865|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_90499_[4, 6144, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,902|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_37577_[1, 6144, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,909|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_27844_[16, 6144, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,936|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_76916_[2, 6144, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,938|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_82161_[1, 6144, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,949|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_79872_[8, 6144, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:18,972|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25004_[1, 6144, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,076|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_42474_[16, 6144, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,159|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23603_[8, 4096, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,336|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_16371_[8, 4096, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,337|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_26640_[16, 4096, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,345|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71449_[8, 4096, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,396|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_37488_[4, 4096, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,454|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_13015_[4, 4096, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,465|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_89610_[2, 4096, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,472|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26941_[2, 4096, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,493|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_30121_[16, 4096, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,523|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_61092_[4, 4096, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,538|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_64904_[1, 4096, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,550|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_68656_[1, 4096, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,587|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_70498_[1, 4096, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,620|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_36137_[2, 4096, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,626|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_72197_[32, 4096, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,654|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_49374_[16, 4096, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,802|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_51242_[8, 3072, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,913|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_78574_[16, 3072, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,920|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12716_[8, 3072, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:19,921|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_30786_[32, 4096, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,015|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75962_[8, 3072, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,021|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_66417_[16, 3072, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,024|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_26898_[4, 3072, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,090|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_66743_[4, 3072, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,093|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_77247_[32, 3072, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,098|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_42331_[4, 3072, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,100|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87346_[2, 3072, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,116|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_36608_[2, 3072, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,126|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_61341_[16, 3072, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,142|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_63512_[2, 3072, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,147|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_53498_[1, 3072, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,175|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_60228_[1, 3072, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,184|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_48466_[1, 3072, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,301|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_52767_[32, 3072, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,380|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19100_[16, 2048, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,528|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_23022_[32, 2048, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,546|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_36187_[16, 2048, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,585|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_39033_[16, 2048, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,612|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32005_[8, 2048, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,658|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_37269_[8, 2048, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,660|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_53548_[32, 2048, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,690|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54442_[4, 2048, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,709|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_28600_[4, 2048, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,727|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_66228_[2, 2048, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,741|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_5794_[8, 2048, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,766|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_52277_[2, 2048, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,788|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_55620_[4, 2048, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,788|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_402_[1, 2048, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,791|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_5391_[1, 2048, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,803|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_84404_[2, 2048, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,833|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_26230_[1, 2048, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,883|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_34636_[32, 2048, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:20,902|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_90417_[64, 2048, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,062|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_14132_[16, 1536, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,090|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15029_[64, 2048, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,093|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_70645_[32, 1536, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,185|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_33882_[16, 1536, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,196|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_463_[8, 1536, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,216|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_54260_[32, 1536, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,236|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_75800_[8, 1536, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,288|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99958_[16, 1536, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,297|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_99079_[4, 1536, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,317|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_78063_[4, 1536, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,323|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_33467_[4, 1536, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,366|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_48540_[2, 1536, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,368|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60901_[8, 1536, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,378|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_94272_[64, 1536, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,383|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_40078_[2, 1536, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,411|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_26689_[2, 1536, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,416|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86221_[32, 1536, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,415|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_45011_[1, 1536, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,419|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_22344_[1, 1536, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,427|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_95232_[1, 1536, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,612|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71079_[32, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,630|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13957_[64, 1536, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,802|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_35268_[32, 1024, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,810|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_45906_[16, 1024, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,823|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_90258_[64, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,891|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_57561_[32, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,942|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65302_[64, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,975|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_95004_[8, 1024, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,973|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_18572_[8, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:21,979|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_39044_[16, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,029|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_94559_[16, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,048|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_60038_[4, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,057|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_13582_[8, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,070|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_20955_[4, 1024, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,079|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_62711_[4, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,101|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_49328_[2, 1024, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,131|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_98535_[2, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,131|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_10682_[2, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,133|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_89696_[1, 1024, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,146|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_96623_[1, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,150|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_92544_[128, 1024, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,165|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19931_[1, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,220|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_35565_[64, 1024, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,404|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_2854_[128, 1024, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,418|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_58262_[64, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,543|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_69289_[64, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,565|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_71632_[128, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,673|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_82456_[128, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,685|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_32160_[64, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,686|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_90817_[32, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,687|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_28218_[32, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,746|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_26280_[32, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,760|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_4199_[16, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,797|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_92823_[8, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,800|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40384_[16, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,811|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_47229_[16, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,814|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34385_[8, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,848|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86356_[8, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,865|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_62971_[4, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,876|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_93675_[4, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,886|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_3873_[4, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,892|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3241_[2, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,895|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65529_[256, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,925|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_82442_[2, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,944|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_60165_[2, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,949|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_13241_[1, 512, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,949|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_27681_[1, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,954|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_22875_[1, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:22,971|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_13695_[128, 512, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,102|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_63343_[64, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,137|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_28111_[128, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,141|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_24961_[256, 512, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,160|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_47561_[64, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,233|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31440_[32, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,241|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92771_[128, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,276|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_84280_[32, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,284|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_3021_[16, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,318|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_42075_[256, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,334|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_35491_[16, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,345|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_42932_[128, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,350|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99493_[8, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,366|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_1056_[32, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,391|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_81944_[8, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,393|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33230_[64, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,403|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_43748_[16, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,407|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_7634_[4, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,410|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_71990_[8, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,415|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_83045_[4, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,457|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_88837_[4, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,464|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_43382_[1, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,480|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_37854_[2, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,483|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73366_[2, 256, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,477|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_86387_[1, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,485|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_88014_[2, 256, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,488|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_46871_[1, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,573|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_19109_[256, 256, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,603|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_10743_[64, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,631|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_70784_[128, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,673|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_78081_[64, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,707|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24750_[64, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,712|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_93092_[32, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,714|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_87439_[128, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,708|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_74553_[256, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,719|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_99994_[32, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,758|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_34583_[128, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,767|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_21715_[256, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,790|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_82394_[8, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,810|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_3732_[8, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,812|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_89870_[16, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,813|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_56199_[16, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,832|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_33110_[4, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,833|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_73848_[16, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,834|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_23977_[32, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,848|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_74441_[8, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,884|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_55760_[2, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,889|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_18239_[4, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,892|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_4220_[1, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,895|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87296_[4, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,895|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12419_[2, 128, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,914|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_6674_[1, 128, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,915|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_38483_[2, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,919|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_83509_[1, 128, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:23,975|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_68093_[64, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,009|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_73131_[64, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,015|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_15146_[64, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,024|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92175_[128, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,049|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_59894_[32, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,067|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5182_[16, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,074|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_50609_[32, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,097|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61296_[32, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,098|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_26061_[16, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,117|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61371_[128, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,118|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75799_[128, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,134|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_95703_[256, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,152|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_34893_[256, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,162|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_89056_[16, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,181|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_29902_[8, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,187|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_1138_[8, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,189|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_61503_[4, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,203|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_88083_[1, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,207|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_22661_[1, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,208|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_31573_[1, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,210|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_91474_[4, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,213|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_96533_[8, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,224|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_86758_[4, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,226|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_25711_[2, 64, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,235|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88325_[2, 64, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,242|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_18579_[2, 64, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,302|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_83198_[128, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,310|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_51031_[64, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,311|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_81341_[64, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,327|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_56902_[64, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,350|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_31558_[128, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,360|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_20510_[128, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,390|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_18352_[32, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,395|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_5028_[32, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,402|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_70790_[256, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,411|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_86019_[32, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,413|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40575_[16, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,433|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_69460_[16, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,456|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_31662_[256, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,460|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_271_[16, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,465|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_78895_[2, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,469|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_3871_[4, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,471|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_61299_[8, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,477|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_42174_[1, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,477|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_35589_[1, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,479|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_24809_[2, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,484|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_58969_[4, 32, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,485|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_92774_[8, 32, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,485|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_38068_[2, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,487|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_20264_[8, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,493|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_11206_[1, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,501|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_86434_[4, 32, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,571|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_65592_[64, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,572|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_36671_[64, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,577|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_47502_[64, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,579|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_7117_[128, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,589|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_39088_[128, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,640|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_76213_[16, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,650|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19028_[32, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,654|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_43966_[128, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,656|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_19319_[32, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,658|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_96270_[256, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,664|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_33008_[16, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,666|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_76149_[32, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,671|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_85036_[256, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,679|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_84849_[2, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,682|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_2143_[2, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,684|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_88829_[4, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,685|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_23005_[4, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,686|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_71029_[2, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,689|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_75563_[1, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,690|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_4728_[1, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,693|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_51713_[1, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,703|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_30161_[4, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,703|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_70720_[8, 16, 4, 1, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,707|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_44254_[8, 16, 4, 4, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,709|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_13521_[8, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:24,715|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_81629_[16, 16, 4, 2, 64, 0, False, False, True, 'context_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:21:37,214|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_32468_[8, 16384, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:21:38,046|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_95867_[8, 16384, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:21:38,090|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_52228_[8, 16384, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:21:39,016|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_23085_[8, 16384, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:21:39,110|WARNING|root|parallel_run|Process 2 died (exit code: -6, restarts: 1, errors: 617)
2025-10-04 00:21:39,112|INFO|root|start_process|Started worker process 3754 on device 2
2025-10-04 00:21:39,112|WARNING|root|parallel_run|Process 4 died (exit code: -6, restarts: 1, errors: 622)
2025-10-04 00:21:39,115|INFO|root|start_process|Started worker process 3755 on device 4
2025-10-04 00:21:39,115|WARNING|root|parallel_run|Process 7 died (exit code: -6, restarts: 1, errors: 606)
2025-10-04 00:21:39,116|INFO|root|start_process|Started worker process 3756 on device 7
2025-10-04 00:21:41,117|WARNING|root|parallel_run|Process 5 died (exit code: -6, restarts: 1, errors: 604)
2025-10-04 00:21:41,118|INFO|root|start_process|Started worker process 3949 on device 5
2025-10-04 00:21:50,728|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.attention_context
2025-10-04 00:21:50,871|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.attention_context
2025-10-04 00:21:50,912|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.attention_context
2025-10-04 00:21:52,333|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_context
2025-10-04 00:22:31,652|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_12964_[16, 8192, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:31,718|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_12781_[16, 8192, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:33,030|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_5843_[16, 8192, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:33,142|WARNING|root|parallel_run|Process 2 died (exit code: -6, restarts: 2, errors: 618)
2025-10-04 00:22:33,144|INFO|root|start_process|Started worker process 5372 on device 2
2025-10-04 00:22:33,144|WARNING|root|parallel_run|Process 6 died (exit code: -6, restarts: 1, errors: 650)
2025-10-04 00:22:33,145|INFO|root|start_process|Started worker process 5373 on device 6
2025-10-04 00:22:33,755|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_19414_[16, 8192, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:35,146|WARNING|root|parallel_run|Process 1 died (exit code: -6, restarts: 1, errors: 601)
2025-10-04 00:22:35,148|INFO|root|start_process|Started worker process 5502 on device 1
2025-10-04 00:22:35,148|WARNING|root|parallel_run|Process 5 died (exit code: -6, restarts: 2, errors: 605)
2025-10-04 00:22:35,149|INFO|root|start_process|Started worker process 5503 on device 5
2025-10-04 00:22:44,955|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.attention_context
2025-10-04 00:22:44,962|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.attention_context
2025-10-04 00:22:46,826|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.attention_context
2025-10-04 00:22:46,831|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_context
2025-10-04 00:22:53,880|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_815_[16, 6144, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:54,190|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_26081_[16, 6144, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:55,162|WARNING|root|parallel_run|Process 3 died (exit code: -6, restarts: 1, errors: 594)
2025-10-04 00:22:55,164|INFO|root|start_process|Started worker process 6989 on device 3
2025-10-04 00:22:55,164|WARNING|root|parallel_run|Process 4 died (exit code: -6, restarts: 2, errors: 623)
2025-10-04 00:22:55,165|INFO|root|start_process|Started worker process 6990 on device 4
2025-10-04 00:22:55,259|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_33281_[16, 6144, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:56,328|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_97930_[16, 6144, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:22:57,167|WARNING|root|parallel_run|Process 2 died (exit code: -6, restarts: 3, errors: 619)
2025-10-04 00:22:57,168|INFO|root|start_process|Started worker process 7121 on device 2
2025-10-04 00:22:57,168|WARNING|root|parallel_run|Process 6 died (exit code: -6, restarts: 2, errors: 651)
2025-10-04 00:22:57,169|INFO|root|start_process|Started worker process 7122 on device 6
2025-10-04 00:23:06,693|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.attention_context
2025-10-04 00:23:06,720|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.attention_context
2025-10-04 00:23:08,699|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.attention_context
2025-10-04 00:23:08,699|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.attention_context
2025-10-04 00:23:16,554|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_87913_[32, 4096, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:17,163|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_72923_[32, 4096, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:17,201|WARNING|root|parallel_run|Process 5 died (exit code: -6, restarts: 3, errors: 606)
2025-10-04 00:23:17,203|INFO|root|start_process|Started worker process 8609 on device 5
2025-10-04 00:23:17,782|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_91012_[32, 4096, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:18,846|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_19736_[32, 4096, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:19,204|WARNING|root|parallel_run|Process 0 died (exit code: -6, restarts: 1, errors: 614)
2025-10-04 00:23:19,206|INFO|root|start_process|Started worker process 8675 on device 0
2025-10-04 00:23:19,206|WARNING|root|parallel_run|Process 1 died (exit code: -6, restarts: 2, errors: 602)
2025-10-04 00:23:19,207|INFO|root|start_process|Started worker process 8676 on device 1
2025-10-04 00:23:19,207|WARNING|root|parallel_run|Process 7 died (exit code: -6, restarts: 2, errors: 607)
2025-10-04 00:23:19,208|INFO|root|start_process|Started worker process 8677 on device 7
2025-10-04 00:23:28,519|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_context
2025-10-04 00:23:30,462|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.attention_context
2025-10-04 00:23:30,663|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.attention_context
2025-10-04 00:23:30,687|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.attention_context
2025-10-04 00:23:40,206|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_87541_[32, 3072, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:40,759|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_93676_[32, 3072, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:40,760|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_90950_[32, 3072, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:41,231|WARNING|root|parallel_run|Process 2 died (exit code: -6, restarts: 4, errors: 620)
2025-10-04 00:23:41,232|INFO|root|start_process|Started worker process 10229 on device 2
2025-10-04 00:23:41,232|WARNING|root|parallel_run|Process 3 died (exit code: -6, restarts: 2, errors: 595)
2025-10-04 00:23:41,234|INFO|root|start_process|Started worker process 10230 on device 3
2025-10-04 00:23:41,234|WARNING|root|parallel_run|Process 6 died (exit code: -6, restarts: 3, errors: 652)
2025-10-04 00:23:41,235|INFO|root|start_process|Started worker process 10231 on device 6
2025-10-04 00:23:41,705|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_99615_[32, 3072, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:23:43,246|WARNING|root|parallel_run|Process 5 died (exit code: -6, restarts: 4, errors: 607)
2025-10-04 00:23:43,252|INFO|root|start_process|Started worker process 10425 on device 5
2025-10-04 00:23:52,735|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.attention_context
2025-10-04 00:23:53,017|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.attention_context
2025-10-04 00:23:53,022|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.attention_context
2025-10-04 00:23:54,480|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_context
2025-10-04 00:24:01,675|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_71244_[64, 2048, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:02,272|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_12652_[64, 2048, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:02,272|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_5701_[64, 2048, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:03,271|WARNING|root|parallel_run|Process 0 died (exit code: -6, restarts: 2, errors: 615)
2025-10-04 00:24:03,273|INFO|root|start_process|Started worker process 11849 on device 0
2025-10-04 00:24:03,273|WARNING|root|parallel_run|Process 1 died (exit code: -6, restarts: 3, errors: 603)
2025-10-04 00:24:03,274|INFO|root|start_process|Started worker process 11850 on device 1
2025-10-04 00:24:03,274|WARNING|root|parallel_run|Process 7 died (exit code: -6, restarts: 3, errors: 608)
2025-10-04 00:24:03,275|INFO|root|start_process|Started worker process 11851 on device 7
2025-10-04 00:24:03,646|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_28412_[64, 2048, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:05,276|WARNING|root|parallel_run|Process 4 died (exit code: -6, restarts: 3, errors: 624)
2025-10-04 00:24:05,277|INFO|root|start_process|Started worker process 12045 on device 4
2025-10-04 00:24:14,490|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.attention_context
2025-10-04 00:24:14,772|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.attention_context
2025-10-04 00:24:14,995|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.attention_context
2025-10-04 00:24:16,573|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.attention_context
2025-10-04 00:24:25,393|ERROR|Worker-worker_2|worker|Task trtllm.attention_context_run_attention_torch_40303_[64, 1536, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:26,157|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_96084_[64, 1536, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:26,181|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_47225_[64, 1536, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:27,287|WARNING|root|parallel_run|Process 0 died (exit code: -6, restarts: 3, errors: 616)
2025-10-04 00:24:27,289|INFO|root|start_process|Started worker process 13469 on device 0
2025-10-04 00:24:27,289|WARNING|root|parallel_run|Process 1 died (exit code: -6, restarts: 4, errors: 604)
2025-10-04 00:24:27,290|INFO|root|start_process|Started worker process 13470 on device 1
2025-10-04 00:24:27,290|WARNING|root|parallel_run|Process 2 died (exit code: -6, restarts: 5, errors: 621)
2025-10-04 00:24:27,291|INFO|root|start_process|Started worker process 13471 on device 2
2025-10-04 00:24:27,364|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_49973_[64, 1536, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:29,296|WARNING|root|parallel_run|Process 3 died (exit code: -6, restarts: 3, errors: 596)
2025-10-04 00:24:29,300|INFO|root|start_process|Started worker process 13665 on device 3
2025-10-04 00:24:38,629|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.attention_context
2025-10-04 00:24:38,795|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.attention_context
2025-10-04 00:24:38,822|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.attention_context
2025-10-04 00:24:40,353|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.attention_context
2025-10-04 00:24:47,081|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_24352_[128, 1024, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:47,618|ERROR|Worker-worker_4|worker|Task trtllm.attention_context_run_attention_torch_8254_[128, 1024, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:49,308|WARNING|root|parallel_run|Process 4 died (exit code: -6, restarts: 4, errors: 625)
2025-10-04 00:24:49,310|INFO|root|start_process|Started worker process 15088 on device 4
2025-10-04 00:24:49,310|WARNING|root|parallel_run|Process 5 died (exit code: -6, restarts: 5, errors: 608)
2025-10-04 00:24:49,311|INFO|root|start_process|Started worker process 15089 on device 5
2025-10-04 00:24:50,229|ERROR|Worker-worker_6|worker|Task trtllm.attention_context_run_attention_torch_50818_[128, 1024, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:50,930|ERROR|Worker-worker_7|worker|Task trtllm.attention_context_run_attention_torch_55392_[128, 1024, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:24:51,312|WARNING|root|parallel_run|Process 6 died (exit code: -6, restarts: 4, errors: 653)
2025-10-04 00:24:51,314|INFO|root|start_process|Started worker process 15220 on device 6
2025-10-04 00:24:51,314|WARNING|root|parallel_run|Process 7 died (exit code: -6, restarts: 4, errors: 609)
2025-10-04 00:24:51,315|INFO|root|start_process|Started worker process 15221 on device 7
2025-10-04 00:25:00,834|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.attention_context
2025-10-04 00:25:01,005|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_context
2025-10-04 00:25:03,080|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.attention_context
2025-10-04 00:25:03,090|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.attention_context
2025-10-04 00:25:14,994|ERROR|Worker-worker_5|worker|Task trtllm.attention_context_run_attention_torch_92029_[256, 512, 96, 2, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:25:15,327|WARNING|root|parallel_run|Process 5 died (exit code: -6, restarts: 6, errors: 609)
2025-10-04 00:25:15,328|INFO|root|start_process|Started worker process 16707 on device 5
2025-10-04 00:25:15,703|ERROR|Worker-worker_3|worker|Task trtllm.attention_context_run_attention_torch_95030_[256, 512, 96, 1, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:25:16,473|ERROR|Worker-worker_0|worker|Task trtllm.attention_context_run_attention_torch_87383_[256, 512, 96, 4, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:25:17,172|ERROR|Worker-worker_1|worker|Task trtllm.attention_context_run_attention_torch_3620_[256, 512, 96, 8, 128, 0, False, False, True, 'context_attention_perf.txt'] failed: RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2025-10-04 00:25:17,329|WARNING|root|parallel_run|Process 0 died (exit code: -6, restarts: 4, errors: 617)
2025-10-04 00:25:17,331|INFO|root|start_process|Started worker process 16775 on device 0
2025-10-04 00:25:17,331|WARNING|root|parallel_run|Process 3 died (exit code: -6, restarts: 4, errors: 597)
2025-10-04 00:25:17,332|INFO|root|start_process|Started worker process 16776 on device 3
2025-10-04 00:25:19,333|WARNING|root|parallel_run|Process 1 died (exit code: -6, restarts: 5, errors: 605)
2025-10-04 00:25:19,334|INFO|root|start_process|Started worker process 16915 on device 1
2025-10-04 00:25:26,627|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_context
2025-10-04 00:25:28,370|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.attention_context
2025-10-04 00:25:28,745|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.attention_context
2025-10-04 00:25:31,101|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.attention_context
2025-10-04 00:37:20,929|ERROR|root|parallel_run|trtllm.attention_context: Completed with 4936 errors
2025-10-04 00:37:21,030|ERROR|root|parallel_run|Error details saved to all_20251004_000940/errors_trtllm.attention_context.json
2025-10-04 00:37:21,535|INFO|root|collect_module_safe|Starting collection: trtllm.attention_generation
2025-10-04 00:37:21,554|INFO|root|collect_module_safe|Generated 10052 test cases for trtllm.attention_generation
2025-10-04 00:37:23,256|INFO|root|start_process|Started worker process 18401 on device 0
2025-10-04 00:37:23,257|INFO|root|start_process|Started worker process 18402 on device 1
2025-10-04 00:37:23,258|INFO|root|start_process|Started worker process 18403 on device 2
2025-10-04 00:37:23,259|INFO|root|start_process|Started worker process 18404 on device 3
2025-10-04 00:37:23,260|INFO|root|start_process|Started worker process 18405 on device 4
2025-10-04 00:37:23,261|INFO|root|start_process|Started worker process 18406 on device 5
2025-10-04 00:37:23,262|INFO|root|start_process|Started worker process 18407 on device 6
2025-10-04 00:37:23,263|INFO|root|start_process|Started worker process 18408 on device 7
2025-10-04 00:37:35,424|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.attention_generation
2025-10-04 00:37:35,557|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_88655_[32, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,573|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22054_[32, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,591|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_20236_[32, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,608|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48557_[32, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,626|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_40800_[32, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,643|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_55058_[32, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,660|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_70580_[32, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,677|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_86881_[32, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,694|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2565_[32, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,717|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23384_[32, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,742|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_92514_[32, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,770|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83637_[32, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,778|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81992_[1, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,783|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2975_[1, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,789|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2317_[1, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,794|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62876_[1, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,799|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_89942_[1, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,805|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52916_[1, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,810|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97874_[1, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,821|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_46127_[1, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,863|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_96051_[1, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,868|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28479_[1, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,873|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_16508_[1, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,879|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68605_[1, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,895|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_35644_[1, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,915|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_32809_[1, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,924|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_76427_[2, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,929|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_56630_[2, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,933|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23596_[2, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,937|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59881_[2, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,941|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97879_[2, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,946|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59700_[2, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,949|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62159_[2, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,954|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_13498_[2, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,957|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11007_[2, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,962|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83453_[2, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,966|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.attention_generation
2025-10-04 00:37:35,967|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_3025_[2, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,976|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26996_[2, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:35,993|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_10116_[2, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,019|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60197_[64, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,048|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_8139_[64, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,063|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16238_[2, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,083|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17191_[64, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,113|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99462_[64, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,121|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_44756_[64, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,162|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_68173_[64, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,173|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80318_[64, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,216|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_44350_[64, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,223|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_53755_[64, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,264|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_7435_[64, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,271|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_88807_[64, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,356|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_56129_[4, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,364|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_33950_[4, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,376|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19511_[4, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,390|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.attention_generation
2025-10-04 00:37:36,432|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_65649_[4, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,439|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_64186_[4, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,446|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50304_[4, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,485|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_74579_[4, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,491|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4608_[4, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,502|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_29952_[4, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,513|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_80390_[4, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,523|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34071_[4, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,535|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46157_[4, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,556|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53725_[4, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,594|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_72680_[128, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,624|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28579_[128, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,664|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3464_[128, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,669|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.attention_generation
2025-10-04 00:37:36,684|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11926_[128, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,729|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_54591_[128, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,744|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.attention_generation
2025-10-04 00:37:36,749|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26515_[128, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,792|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_31800_[128, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,820|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.attention_generation
2025-10-04 00:37:36,823|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28984_[128, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,845|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.attention_generation
2025-10-04 00:37:36,861|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.attention_generation
2025-10-04 00:37:36,888|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_22477_[256, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,898|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46609_[128, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,918|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_14365_[256, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,929|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_97907_[128, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:36,983|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_29631_[256, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,005|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28694_[256, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,011|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24591_[256, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,063|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70856_[256, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,067|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27007_[256, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,074|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61240_[4, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,094|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94920_[512, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,097|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_78128_[256, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,103|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_83457_[8, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,135|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52062_[8, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,148|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_88747_[8, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,166|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_55623_[512, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,167|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_88044_[8, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,193|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50320_[8, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,195|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67863_[512, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,215|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99498_[512, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,223|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75665_[8, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,232|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_46632_[8, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,245|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_342_[8, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,245|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_86957_[8, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,251|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_68310_[512, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,282|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51311_[8, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,288|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_25967_[8, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,292|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98205_[512, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,320|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42939_[8, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,321|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_88388_[8, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,325|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93680_[512, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,329|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_82957_[8, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,525|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_19340_[1024, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,550|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_44469_[1024, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,562|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_88307_[1024, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,572|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15742_[1024, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,575|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_59073_[1024, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,581|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_9498_[1024, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,586|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_79508_[16, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,619|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50465_[16, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,626|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22042_[16, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,633|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_61984_[16, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,643|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_15390_[16, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,649|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_4475_[16, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,667|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81641_[16, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,673|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_16604_[16, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,679|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28615_[16, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,691|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62121_[16, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,701|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81837_[16, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,702|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80354_[16, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,717|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81933_[16, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,899|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55743_[2048, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:37,911|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_58823_[2048, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:38,067|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73489_[2048, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:38,088|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87184_[2048, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:38,137|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46747_[2048, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,794|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_61267_[32, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,809|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58934_[32, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,820|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39818_[32, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,835|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_89637_[32, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,843|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33896_[32, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,862|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77656_[32, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,863|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_2460_[32, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,877|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_4083_[32, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,885|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16835_[32, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,905|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_53242_[32, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,911|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32429_[32, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,917|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78044_[1, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,917|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15941_[1, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,920|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_88265_[1, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,921|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80310_[1, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,923|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99977_[1, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,924|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_61081_[1, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,925|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15381_[1, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,927|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46605_[1, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,928|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_61577_[32, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,929|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23380_[1, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,930|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_29991_[1, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,934|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_82627_[1, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,938|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52609_[2, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,938|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_29218_[1, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,941|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40823_[1, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,941|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27694_[2, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,943|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36903_[2, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,944|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_8927_[2, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,948|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22737_[1, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,948|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_8669_[2, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,948|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84854_[2, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,948|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_18794_[2, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,951|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86135_[2, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,954|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_72420_[2, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,955|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_5412_[2, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,955|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45637_[2, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,958|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_22471_[2, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,961|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_31013_[2, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,973|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30691_[2, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,988|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89209_[64, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:42,988|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_65087_[64, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,000|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55772_[64, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,006|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70797_[64, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,045|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43567_[64, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,053|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67933_[64, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,070|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38007_[64, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,079|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13902_[4, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,084|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_53821_[64, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,083|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32870_[64, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,087|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_71721_[4, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,088|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_36640_[64, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,103|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_99608_[4, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,111|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99907_[4, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,112|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4090_[4, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,139|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_67996_[4, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,141|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_90990_[64, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,144|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_69008_[4, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,150|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_83187_[4, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,150|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_58098_[4, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,155|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_73270_[4, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,156|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_3011_[4, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,165|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_57188_[4, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,177|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31154_[4, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,195|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_81597_[4, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,231|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_25901_[128, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,248|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_71242_[128, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,259|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_63888_[128, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,260|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_10432_[128, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,266|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_80741_[128, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,273|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57185_[128, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,274|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_53570_[128, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,275|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_98358_[128, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,336|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_55055_[128, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,357|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_68894_[128, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,365|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_59476_[256, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,384|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_62051_[256, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,397|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_85339_[256, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,397|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_49215_[256, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,407|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_4890_[256, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,408|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_48423_[256, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,452|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_23132_[256, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,458|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_12166_[256, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,473|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_39626_[8, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,478|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_42467_[8, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,495|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_41034_[8, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,531|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_46135_[8, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,532|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_1676_[512, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,546|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84225_[8, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,563|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_48015_[512, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,586|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_71725_[512, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,595|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_9058_[8, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,593|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_87337_[512, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,598|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_82134_[512, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,599|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_10821_[512, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,631|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_6633_[8, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,655|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_70280_[8, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,668|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_91761_[8, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,672|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67278_[8, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,680|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56195_[8, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,680|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_17862_[8, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,679|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_190_[8, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,695|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22534_[512, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,705|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_12584_[8, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,893|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10638_[1024, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,900|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_60615_[1024, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,912|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_32100_[1024, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,912|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64487_[1024, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,915|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_40184_[1024, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,917|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89494_[1024, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,953|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_51023_[16, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,964|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44819_[16, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,965|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99506_[16, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,989|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_22440_[16, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,991|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78374_[16, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:43,998|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26212_[16, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,009|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_92250_[16, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,026|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78919_[16, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,032|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_77774_[16, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,044|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58697_[16, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,057|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16137_[16, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,074|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_44028_[16, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,085|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_69803_[16, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,162|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_55679_[2048, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,205|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_89703_[2048, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,355|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_12663_[2048, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,356|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_93902_[2048, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:44,359|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_95013_[2048, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,248|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16269_[32, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,264|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33615_[32, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,277|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_13255_[32, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,284|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81358_[32, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,308|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23950_[32, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,313|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_75332_[32, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,314|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_42192_[32, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,337|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_60456_[32, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,348|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11090_[32, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,348|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_35520_[32, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,352|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63328_[1, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,355|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99086_[1, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,357|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_10765_[32, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,358|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_15194_[1, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,361|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_58786_[1, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,364|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_35265_[1, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,364|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_75965_[1, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,367|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_146_[1, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,379|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43307_[1, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,384|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_68686_[1, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,385|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_61703_[32, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,386|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_73693_[1, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,387|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8993_[1, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,390|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_27758_[1, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,391|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_21665_[2, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,394|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_31742_[2, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,394|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19748_[1, 8191, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,395|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76857_[2, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,398|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30375_[2, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,399|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_69091_[1, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,400|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_48729_[2, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,400|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85874_[2, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,401|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_64922_[2, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,403|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_29288_[2, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,405|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90635_[2, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,406|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_20203_[2, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,406|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34920_[2, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,408|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57173_[2, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,417|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23513_[2, 8191, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,419|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26134_[2, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,425|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_40850_[64, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,432|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_26608_[64, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,468|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41129_[64, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,470|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8655_[64, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,473|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_39725_[64, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,498|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_5904_[64, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,499|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_72622_[64, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,518|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_8484_[64, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,517|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_63486_[64, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,525|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_71836_[4, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,536|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_18003_[4, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,545|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_10079_[4, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,568|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_30061_[4, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,569|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51593_[64, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,577|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13846_[64, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,579|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82364_[4, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,581|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_86571_[4, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,583|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_61281_[4, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,589|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_4866_[4, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,597|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17037_[4, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,602|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_9461_[4, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,617|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82044_[4, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,619|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_36825_[4, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,634|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_1981_[4, 8191, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,635|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10531_[4, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,653|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71002_[128, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,666|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_33308_[128, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,672|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_28609_[128, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,702|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_2402_[128, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,702|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50656_[128, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,717|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61756_[128, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,723|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_36344_[128, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,727|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_92967_[128, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,734|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_43565_[128, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,756|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_1997_[128, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,810|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30360_[256, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,820|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56256_[256, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,828|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62406_[256, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,834|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_15617_[256, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,836|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_41755_[256, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,847|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63707_[256, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,851|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22221_[256, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,875|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59521_[256, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,901|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_44250_[8, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,929|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_9509_[8, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,958|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_96238_[8, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,973|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_1265_[8, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,976|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_50657_[512, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,979|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74193_[8, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,997|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63313_[8, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:49,999|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_29669_[512, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,025|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50028_[512, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,027|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_25239_[512, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,030|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_27452_[512, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,031|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42190_[8, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,052|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38296_[8, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,052|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_91353_[512, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,057|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_82964_[512, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,062|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_23520_[8, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,075|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42302_[8, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,105|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_30175_[8, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,109|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_4895_[8, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,124|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_71632_[8, 8191, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,127|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_76011_[8, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,302|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49781_[1024, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,314|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_23163_[1024, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,322|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_99589_[1024, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,353|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_98044_[1024, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,359|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_95752_[1024, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,360|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84095_[1024, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,365|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_91160_[16, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,389|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76791_[16, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,390|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32647_[16, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,395|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_17030_[16, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,418|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50686_[16, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,421|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48874_[16, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,424|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22949_[16, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,432|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_4785_[16, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,456|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77090_[16, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,457|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19864_[16, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,466|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_35135_[16, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,476|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_17034_[16, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,500|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_60252_[16, 8191, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,532|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27278_[2048, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,565|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_28300_[2048, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,729|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_90074_[2048, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,737|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_72331_[2048, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:50,738|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_32476_[2048, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,260|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_80600_[32, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,272|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_80099_[32, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,286|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50497_[32, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,300|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_39020_[32, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,313|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96961_[32, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,337|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_95550_[32, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,338|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_73863_[32, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,346|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13978_[32, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,366|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73018_[32, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,373|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_66361_[32, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,381|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_24642_[1, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,384|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75727_[1, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,385|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48625_[32, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,387|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43244_[1, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,389|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74753_[1, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,391|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_44721_[1, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,391|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59706_[32, 4095, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,392|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_93454_[1, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,395|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_12082_[1, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,395|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_47845_[1, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,398|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86600_[1, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,400|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38468_[1, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,401|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11191_[1, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,406|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32892_[1, 4095, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,409|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61019_[1, 8191, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,413|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_89605_[1, 16383, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,414|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13413_[2, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,414|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84305_[32, 8191, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,419|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52491_[2, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,419|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33031_[2, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,422|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64954_[2, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,423|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_51571_[2, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,425|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_35264_[2, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,425|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85284_[2, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,427|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_92675_[2, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,429|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_92135_[2, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,430|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43695_[2, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,432|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24601_[2, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,434|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_90619_[1, 32767, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,437|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_2919_[2, 8191, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,437|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_62398_[2, 4095, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,449|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3391_[2, 16383, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,461|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_70815_[64, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,473|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_4584_[64, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,481|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_3709_[2, 32767, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,484|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_25712_[64, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,502|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84852_[64, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,517|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81924_[64, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,527|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33113_[64, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,540|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85659_[4, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,542|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74610_[64, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,544|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_96761_[4, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,544|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_18051_[4, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,545|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84204_[64, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,546|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70404_[64, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,550|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65690_[4, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,553|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_20111_[4, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,553|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47829_[4, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,554|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_82041_[4, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,557|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_6905_[4, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,559|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_5699_[4, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,562|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_89576_[4, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,564|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_751_[64, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,569|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_76245_[4, 4095, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,569|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99382_[4, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,572|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99748_[4, 8191, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,574|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_38239_[64, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,580|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62357_[4, 16383, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,584|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43484_[64, 4095, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,622|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36800_[128, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,625|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_65300_[4, 32767, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,634|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32285_[128, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,645|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_21164_[128, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,649|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93724_[128, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,652|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13840_[128, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,657|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11727_[128, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,672|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_92130_[128, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,706|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_99313_[128, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,710|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_29880_[128, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,710|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32561_[128, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,735|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_73369_[128, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,752|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67739_[256, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,758|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_36954_[256, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,764|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55406_[256, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,794|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_49876_[256, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,801|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_76089_[256, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,813|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81948_[256, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,820|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30454_[256, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,826|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_14444_[256, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,849|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99229_[256, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,892|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60840_[512, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,903|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_28159_[512, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,918|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_43296_[8, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,936|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_98194_[8, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,937|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_67642_[512, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,943|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89596_[8, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,950|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_50389_[512, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,960|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_29553_[512, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,963|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_6636_[8, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,964|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_24797_[8, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,987|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_5453_[8, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,996|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_22397_[8, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,997|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97742_[8, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:55,998|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_5398_[512, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,003|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13350_[8, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,008|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_83061_[8, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,023|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41322_[512, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,026|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_45793_[512, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,026|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16149_[8, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,038|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16062_[8, 4095, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,052|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_88921_[8, 8191, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,061|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_90950_[8, 16383, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,076|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_70934_[8, 32767, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,249|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42204_[1024, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,255|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_47033_[1024, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,268|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11475_[1024, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,274|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82363_[1024, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,280|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28108_[1024, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,290|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_25952_[1024, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,304|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44271_[1024, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,305|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_92218_[16, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,311|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_88966_[16, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,327|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14046_[16, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,328|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_18913_[16, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,340|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34654_[16, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,346|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79182_[16, 127, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,351|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_13209_[16, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,352|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_53263_[16, 255, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,360|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79677_[16, 1023, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,365|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41358_[16, 511, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,374|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89881_[16, 2047, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,382|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_35185_[16, 4095, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,395|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89073_[16, 8191, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,422|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_46048_[2048, 1, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,425|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_10502_[16, 16383, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,614|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_20659_[2048, 7, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,617|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_94803_[2048, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,620|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_85696_[2048, 15, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,622|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_20233_[2048, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:37:56,652|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_41715_[2048, 63, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,700|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23408_[32, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,708|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33056_[32, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,717|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_12485_[32, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,725|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43501_[32, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,742|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_50903_[32, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,749|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20078_[32, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,761|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_39613_[32, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,763|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76973_[32, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,791|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31010_[32, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,797|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_48224_[1, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,798|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78289_[32, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,803|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_1960_[1, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,804|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42330_[1, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,807|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_48875_[1, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,807|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_14293_[1, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,811|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_48273_[32, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,811|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94038_[1, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,811|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_80673_[1, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,813|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28532_[32, 4095, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,814|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32727_[1, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,818|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_32485_[1, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,819|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_37835_[1, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,821|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23970_[1, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,822|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_4633_[1, 4095, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,824|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_61904_[32, 8191, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,825|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_31999_[2, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,826|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_2494_[2, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,827|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_78356_[1, 8191, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,828|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_91171_[2, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,828|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66983_[2, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,831|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_21960_[2, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,831|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84060_[2, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,831|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_28467_[2, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,832|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77074_[2, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,834|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84299_[1, 16383, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,835|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_3558_[2, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,836|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_8817_[2, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,836|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_4832_[2, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,839|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_64460_[2, 4095, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,845|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_41648_[2, 8191, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,846|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8626_[1, 32767, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,861|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_91182_[2, 16383, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,890|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66790_[64, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,891|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_95543_[64, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,892|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74206_[64, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,899|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_25939_[64, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,900|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49664_[2, 32767, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,909|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3779_[64, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,909|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_71491_[64, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,924|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_3469_[4, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,932|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_92186_[4, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,939|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_41455_[64, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,942|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_22181_[4, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,945|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_95105_[64, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,951|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_86282_[64, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,959|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_18275_[4, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,964|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60121_[4, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,967|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_27292_[4, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,967|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_35796_[4, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,969|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_16451_[64, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,973|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60386_[4, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,975|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_53645_[4, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,978|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_82397_[4, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,978|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_12928_[4, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,978|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_96969_[64, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,981|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_59178_[64, 4095, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,983|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96968_[4, 4095, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:01,988|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65720_[4, 8191, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,002|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75182_[4, 16383, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,013|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30813_[4, 32767, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,035|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_42555_[128, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,043|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45479_[128, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,047|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_29351_[128, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,050|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_88888_[128, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,062|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42898_[128, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,064|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_24371_[128, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,090|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_42153_[128, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,098|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79899_[128, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,119|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24477_[128, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,140|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34598_[128, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,152|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_5977_[256, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,154|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_70551_[128, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,155|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_42870_[256, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,168|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79979_[256, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,176|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59975_[256, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,209|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1054_[256, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,224|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_4070_[256, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,234|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19816_[256, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,245|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_97960_[256, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,282|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_41119_[256, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,291|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_83237_[512, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,296|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39261_[512, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,301|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_10153_[8, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,309|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51594_[512, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,335|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_7719_[512, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,336|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_54432_[8, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,338|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_91699_[8, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,347|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_40998_[8, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,357|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_27332_[8, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,364|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99163_[8, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,376|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81429_[8, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,378|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_12574_[8, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,384|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_91545_[8, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,388|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_44470_[8, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,401|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43734_[512, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,412|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24074_[512, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,413|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_48653_[8, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,428|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_58601_[512, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,428|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30906_[8, 4095, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,436|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_12263_[8, 8191, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,443|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80686_[8, 16383, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,444|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_96700_[512, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,470|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80271_[8, 32767, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,606|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36825_[1024, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,614|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72038_[1024, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,615|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_16073_[1024, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,623|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56424_[1024, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,639|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_85571_[1024, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,646|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27808_[1024, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,662|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_36384_[16, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,667|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_78632_[16, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,685|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_41765_[16, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,685|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_27545_[1024, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,692|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_60676_[16, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,702|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52906_[16, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,708|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_11264_[16, 127, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,713|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_41993_[16, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,714|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_67046_[16, 255, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,722|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_76697_[16, 1023, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,735|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_24494_[16, 2047, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,740|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_49523_[16, 511, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,757|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21280_[2048, 1, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,761|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_11796_[16, 4095, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,773|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20030_[16, 8191, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,790|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_87829_[16, 16383, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,933|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84322_[2048, 3, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,945|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99712_[2048, 15, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,960|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_77530_[2048, 7, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,978|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_59831_[2048, 31, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:02,989|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_48490_[2048, 63, 24, 24, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,737|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48674_[32, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,751|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19840_[32, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,764|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26772_[32, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,770|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_1572_[32, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,777|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_99507_[32, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,796|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49416_[32, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,802|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_84864_[32, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,814|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_10099_[32, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,823|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_55100_[32, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,837|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37320_[1, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,837|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_27752_[1, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,846|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8643_[32, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,850|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58189_[1, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78664_[1, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,854|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23883_[1, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,854|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44655_[1, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,857|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_97339_[1, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,857|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_80458_[32, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,858|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76194_[1, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,859|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33509_[32, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,862|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86499_[1, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,865|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_29956_[1, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,868|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_41310_[1, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,869|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_68411_[1, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,872|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30204_[1, 8191, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,873|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_68531_[2, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,876|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_58119_[2, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,877|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62546_[2, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,878|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_75665_[32, 8191, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,879|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_96289_[2, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,880|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17567_[2, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,881|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_58373_[1, 16383, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,882|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_81752_[2, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,883|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_74936_[2, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,884|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_11982_[32, 16383, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,885|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_78606_[2, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,886|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_76820_[2, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,887|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_25748_[2, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,888|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_58978_[2, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,893|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69201_[2, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,897|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_40788_[2, 8191, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,901|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95650_[2, 16383, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,903|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_15630_[1, 32767, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,904|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84409_[64, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,913|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81768_[2, 32767, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,921|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_84827_[64, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,924|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_6065_[1, 65535, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,931|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_40141_[64, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,949|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52100_[2, 65535, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,963|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_92601_[64, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,969|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89490_[64, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,978|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51174_[64, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,985|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_13652_[64, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,990|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59883_[4, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:07,995|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_55387_[64, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,002|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65821_[4, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,006|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_83292_[4, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,006|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73676_[64, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,006|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60751_[4, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,007|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93912_[64, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,014|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_9818_[4, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,014|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54745_[4, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,017|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_55811_[4, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,018|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_54675_[64, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,019|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_77408_[4, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,019|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30373_[4, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,022|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_35831_[4, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,022|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_98478_[4, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,033|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_58465_[4, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,035|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51007_[4, 8191, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,042|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55212_[64, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,049|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78262_[64, 8191, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,053|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52169_[4, 16383, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,063|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22215_[4, 32767, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,088|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_78146_[128, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,104|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_9727_[4, 65535, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,118|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_17270_[128, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,118|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_33205_[128, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,120|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1894_[128, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,124|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97999_[128, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,130|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_95762_[128, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,142|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_35587_[128, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,158|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_70617_[128, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,158|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_54610_[128, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,225|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14416_[128, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,233|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36370_[256, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,240|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56943_[256, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,241|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59279_[256, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,243|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_54193_[128, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,256|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_18204_[256, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,259|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78955_[256, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,259|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70254_[128, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,307|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11675_[256, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,327|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_7149_[256, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,338|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_99778_[256, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,343|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_5033_[256, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,351|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_34259_[256, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,374|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52483_[512, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,375|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99100_[512, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,382|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81228_[8, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,386|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_87292_[8, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,387|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_13434_[512, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,390|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_49562_[8, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,394|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_60496_[8, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,394|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_4537_[8, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,398|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63763_[8, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,399|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_56404_[8, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,402|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_88922_[8, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,403|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26016_[8, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,407|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_13437_[8, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,409|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59473_[8, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,417|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_10133_[8, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,423|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53006_[512, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,429|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89364_[8, 8191, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,437|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_35174_[512, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,443|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38398_[512, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,449|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_3959_[512, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,449|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46115_[8, 16383, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,453|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_93544_[512, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,469|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67040_[8, 32767, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,488|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_21504_[512, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,497|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_44642_[8, 65535, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,581|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_23015_[1024, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,630|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48601_[1024, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,634|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_68442_[1024, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,640|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59359_[1024, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,641|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33559_[1024, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,653|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_59993_[1024, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,659|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84865_[1024, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,676|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59018_[1024, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,687|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_83266_[16, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,693|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82884_[16, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,698|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_93582_[16, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,704|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_88319_[16, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,709|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74493_[16, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,713|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_44802_[16, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,717|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_33559_[16, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,722|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_33947_[16, 255, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,726|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_77527_[16, 511, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,732|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89107_[16, 1023, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,739|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17707_[16, 2047, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,749|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_92400_[16, 4095, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,765|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34744_[16, 8191, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,796|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_96102_[16, 16383, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,854|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63672_[16, 32767, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,911|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85813_[2048, 31, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,921|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51524_[2048, 1, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,951|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_43925_[2048, 15, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,968|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39785_[2048, 7, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,981|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74063_[2048, 63, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:08,984|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97312_[2048, 3, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:09,018|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1955_[2048, 127, 16, 16, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,081|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_24527_[32, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,088|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_22051_[32, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,104|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_58524_[32, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,110|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_48605_[32, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,117|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_70330_[32, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,127|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_74343_[32, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,133|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_29811_[32, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,146|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_165_[32, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,159|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_6400_[32, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,164|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_19143_[32, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,171|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27263_[32, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,176|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_30883_[1, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,179|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_11455_[1, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,179|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59966_[32, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,182|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_94105_[1, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,185|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89630_[1, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,186|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33388_[1, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,188|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86939_[1, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,189|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_56749_[32, 8191, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,190|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_72971_[1, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,191|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_50765_[1, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,193|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_46542_[1, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,194|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_90959_[1, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,199|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_40558_[1, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,199|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_44384_[1, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,204|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3193_[1, 8191, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,211|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_37012_[1, 16383, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,212|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12156_[32, 16383, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,216|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_18749_[2, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,218|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66158_[2, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,221|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81145_[2, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,223|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_3325_[2, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,224|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_91803_[2, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,224|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15457_[1, 32767, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,227|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_87298_[2, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,228|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_7381_[2, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,230|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_75943_[2, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,230|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_967_[2, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,234|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_54083_[2, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,234|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24913_[2, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,236|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97458_[2, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,245|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22815_[2, 8191, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,248|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30082_[2, 16383, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,251|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38632_[1, 65535, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,258|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83896_[64, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,259|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53783_[2, 32767, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,269|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81243_[64, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,277|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_3036_[64, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,300|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_53915_[2, 65535, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,305|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3250_[64, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,307|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_79230_[64, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,311|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_99443_[64, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,330|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_43258_[64, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,342|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_44894_[64, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,344|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95875_[64, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,353|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_73230_[64, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,358|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_4897_[4, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,362|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_83344_[4, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,362|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79107_[4, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,366|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_4745_[4, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,366|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19628_[4, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,367|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57418_[4, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,369|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15547_[4, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,372|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_78823_[4, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,374|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8604_[4, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,381|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_98108_[64, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,383|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_14123_[64, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,389|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45786_[4, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,390|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93858_[4, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,392|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_77200_[64, 8191, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,393|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87515_[4, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,397|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82118_[4, 8191, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,407|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_73280_[4, 16383, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,409|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31636_[128, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,417|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26022_[4, 32767, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,437|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12125_[128, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,450|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_65486_[128, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,455|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_808_[128, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,459|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_31083_[4, 65535, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,461|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74886_[128, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,467|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11116_[128, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,485|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_86457_[128, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,510|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_90625_[128, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,515|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36365_[128, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,533|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_97067_[128, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,536|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14270_[256, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,537|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_44382_[128, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,553|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96010_[256, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,563|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51754_[256, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,577|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80052_[128, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,604|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19274_[256, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,607|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_30732_[256, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,629|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_64814_[256, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,634|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_70987_[256, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,640|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_763_[256, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,641|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_95307_[256, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,667|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_55076_[256, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,683|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_41454_[512, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,717|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96650_[512, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,722|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70490_[512, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,730|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74198_[8, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,734|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74670_[8, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,735|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_13675_[512, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,735|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8754_[512, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,738|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_94868_[8, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,744|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_68370_[8, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,751|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70965_[8, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,752|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17073_[8, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,752|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_14786_[8, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,752|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57254_[512, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,752|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_30009_[8, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,756|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43836_[8, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,758|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80875_[512, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,760|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84168_[8, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,760|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_90296_[8, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,761|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42262_[8, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,769|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_99908_[8, 8191, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,775|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42109_[8, 16383, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,796|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_58054_[8, 32767, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,799|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34705_[512, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,811|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91694_[512, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,833|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82645_[8, 65535, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,870|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_96729_[1024, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,883|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_55225_[1024, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,890|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_74729_[1024, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,901|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_59426_[1024, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,915|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_37633_[1024, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,936|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_16022_[1024, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:14,957|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37710_[1024, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,017|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_55031_[1024, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,031|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26745_[16, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,038|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_76080_[16, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,044|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_14201_[16, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,049|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_1066_[16, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,054|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45919_[16, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,059|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59302_[16, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,068|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_18516_[16, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,074|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98021_[16, 255, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,079|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89782_[16, 511, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,108|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_55044_[16, 1023, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,121|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_56123_[16, 2047, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,132|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_44924_[16, 4095, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,149|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_20138_[2048, 1, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,160|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52902_[16, 8191, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,164|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20161_[2048, 15, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,171|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74651_[2048, 3, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,190|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_73020_[2048, 31, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,196|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_71554_[16, 16383, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,221|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_83721_[2048, 7, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,246|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_6600_[2048, 63, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,250|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_64977_[16, 32767, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:15,296|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_68010_[2048, 127, 12, 12, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,399|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33721_[32, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,410|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_34058_[32, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,422|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_64748_[32, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,428|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73000_[32, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,433|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28509_[32, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,439|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_29708_[32, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,444|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_86436_[32, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,450|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_26307_[32, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,457|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4293_[32, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,464|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97789_[32, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,482|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73_[32, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,483|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_15136_[32, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,488|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_23053_[1, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,492|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_16431_[1, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,494|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22031_[32, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,495|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_29097_[1, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,498|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51153_[1, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,500|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_78629_[1, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,501|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_60551_[1, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,503|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49224_[1, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,503|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33736_[1, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,506|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79336_[1, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,508|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87946_[32, 16383, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,509|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_34651_[1, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,510|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_99881_[1, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,515|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_58832_[1, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,517|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97291_[1, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,528|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_36626_[1, 16383, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,544|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_96490_[2, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,547|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97472_[1, 32767, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,548|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30350_[2, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,551|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_43279_[2, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,551|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_18066_[2, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,554|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_77449_[2, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,554|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21009_[2, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,556|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2288_[2, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,557|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99268_[2, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,559|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_38080_[2, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,560|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_88139_[2, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,561|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_6698_[32, 32767, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,564|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_42044_[2, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,566|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99043_[2, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,572|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_41509_[1, 65535, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,575|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_84506_[2, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,579|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22360_[2, 16383, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,590|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93895_[64, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,597|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_7049_[64, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,599|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_37635_[2, 32767, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,605|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24996_[64, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,618|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51053_[64, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,619|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_85614_[1, 131071, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,621|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58782_[2, 65535, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,627|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85134_[64, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,654|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_99945_[64, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,672|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_2590_[64, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,672|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_68449_[64, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,677|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_10901_[64, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,682|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_49178_[64, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,683|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_29169_[4, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,688|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_79982_[4, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,689|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_5272_[2, 131071, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,692|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_23187_[4, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,692|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87253_[4, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,694|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_10122_[64, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,695|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45925_[4, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,696|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19063_[4, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,696|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_55296_[4, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,699|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_18920_[4, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,700|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_39398_[4, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,701|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38755_[4, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,703|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31022_[4, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,703|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28071_[64, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,706|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_29257_[4, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,710|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_53177_[4, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,717|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_5476_[64, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,717|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_74520_[4, 16383, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,729|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_64903_[128, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,730|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_79894_[4, 32767, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,751|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_45344_[128, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,751|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40961_[128, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,769|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77569_[4, 65535, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,789|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_36087_[64, 16383, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,791|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_10226_[128, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,796|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79470_[128, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,809|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_93125_[128, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,816|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8345_[128, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,821|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57401_[128, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,824|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_17708_[128, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,833|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48259_[128, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,846|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4794_[4, 131071, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,854|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41980_[256, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,883|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31756_[256, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,883|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73621_[128, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,899|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_51497_[256, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,918|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82805_[128, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,920|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_76548_[256, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,940|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26141_[256, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,957|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20736_[256, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,957|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_74482_[256, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,962|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86589_[128, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,964|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60270_[256, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:20,980|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23412_[256, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,019|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22276_[256, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,025|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8547_[512, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,053|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49443_[256, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,056|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_32020_[512, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,062|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23760_[512, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,068|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_93109_[512, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,068|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85162_[512, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,074|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83580_[512, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,077|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_36444_[8, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,080|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86744_[8, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,083|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_73833_[8, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,083|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_39391_[8, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,084|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_11005_[8, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,085|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78808_[8, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,087|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67528_[8, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,088|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_44224_[8, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,088|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_24010_[8, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,089|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_39932_[8, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,093|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17790_[8, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,095|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_26472_[8, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,107|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_35845_[8, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,107|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43812_[8, 16383, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,123|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63229_[512, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,123|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_70944_[512, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,138|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_93194_[8, 32767, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,163|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14353_[512, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,164|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12134_[8, 65535, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,171|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_97056_[512, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,204|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70457_[1024, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,239|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_95461_[8, 131071, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,241|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15945_[1024, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,246|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_188_[1024, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,252|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52090_[1024, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,281|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_66551_[1024, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,287|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58375_[1024, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,294|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_80646_[1024, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,346|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_97028_[1024, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,443|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_21338_[1024, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,482|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_1582_[2048, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,484|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_55452_[2048, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,494|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34479_[2048, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,499|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38682_[16, 1, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,501|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59250_[16, 3, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,503|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52335_[16, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,505|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_37960_[16, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,507|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31326_[16, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,507|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_40923_[16, 7, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,509|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62096_[16, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,512|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62803_[16, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,515|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_98348_[16, 1023, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,515|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16963_[16, 511, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,518|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_21297_[2048, 31, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,521|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89866_[16, 2047, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,524|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_27939_[2048, 63, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,525|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_84287_[16, 4095, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,529|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81429_[2048, 15, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,537|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_48108_[16, 8191, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,552|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99262_[16, 16383, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,575|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_98810_[16, 32767, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,613|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33238_[16, 65535, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,637|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41835_[2048, 127, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:21,815|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14097_[2048, 255, 8, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,198|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84331_[32, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,203|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_77950_[32, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,205|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_17972_[32, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,208|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_71605_[32, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,210|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78336_[32, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,213|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93017_[32, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,216|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85412_[32, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,218|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97750_[32, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,221|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_13021_[32, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,226|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_85705_[32, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,227|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_46027_[32, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,233|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59076_[32, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,247|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39143_[32, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,257|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_18816_[1, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,260|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37620_[1, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,263|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_83732_[1, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,265|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57624_[1, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,268|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51930_[1, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,270|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_94806_[32, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,271|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4453_[1, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,273|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_85049_[1, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,276|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26709_[1, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,279|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_38199_[1, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,279|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_39029_[1, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,283|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_71120_[1, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,286|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_56649_[1, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,292|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56153_[1, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,298|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_28674_[1, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,298|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90793_[32, 32767, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,310|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_7731_[2, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,314|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_44263_[2, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,317|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_72237_[2, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,320|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_48786_[2, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,320|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_47561_[1, 32767, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,323|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37612_[2, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,324|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_38735_[2, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,326|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46144_[2, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,327|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_27679_[2, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,330|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58869_[2, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,331|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70692_[2, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,335|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68531_[2, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,336|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57129_[2, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,343|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23810_[2, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,343|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_91180_[1, 65535, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,349|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34116_[2, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,369|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51477_[64, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,369|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64420_[2, 32767, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,378|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_31254_[64, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,380|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_12614_[32, 65535, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,384|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_96764_[64, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,390|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84784_[64, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,391|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63348_[2, 65535, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,396|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54800_[64, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,396|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7861_[1, 131071, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,402|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_13013_[64, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,420|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_37956_[64, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,421|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_82630_[64, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,426|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16951_[64, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,430|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_53785_[64, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,434|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_92361_[64, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,439|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57370_[4, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,442|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_70358_[4, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,445|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50701_[4, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,446|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_65703_[2, 131071, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,448|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_71767_[4, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,449|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_555_[64, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,450|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_55863_[4, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,452|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_615_[4, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,453|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4847_[4, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,457|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59027_[4, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,457|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_91822_[4, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,457|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_40700_[4, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,461|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53259_[64, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,463|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_36001_[4, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,463|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52056_[4, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,466|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24054_[4, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,479|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_16366_[4, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,484|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_29470_[64, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,484|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_84902_[128, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,493|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_25144_[128, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,499|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_21333_[4, 32767, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,500|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_93093_[128, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,514|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32797_[128, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,523|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_45748_[4, 65535, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,536|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_85012_[128, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,538|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13968_[128, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,556|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89685_[128, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,579|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33801_[128, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,580|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57235_[128, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,580|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_10089_[128, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,583|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56272_[64, 32767, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,590|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_49917_[4, 131071, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,597|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_92065_[128, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,608|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_88091_[128, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,624|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54146_[256, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,639|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_49170_[256, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,656|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16527_[256, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,662|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66013_[256, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,668|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80643_[256, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,678|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_61176_[256, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,685|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79129_[256, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,708|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_65399_[256, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,725|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40023_[128, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,737|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_58039_[256, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,754|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78349_[256, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,760|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56180_[512, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,769|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_61245_[256, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,780|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_71659_[512, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,790|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_74086_[128, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,816|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_98287_[256, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,825|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_92213_[512, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,831|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_90046_[512, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,837|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94569_[8, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,840|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55071_[8, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,844|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_46152_[8, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,845|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_22746_[512, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,848|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11242_[8, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,850|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84597_[8, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,851|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_92583_[8, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24835_[8, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,854|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79484_[8, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,857|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_1870_[8, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,859|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39875_[8, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,862|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_17613_[512, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,857|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26655_[512, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,863|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51591_[8, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,867|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_44916_[8, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,868|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45644_[512, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,874|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51197_[8, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,884|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84764_[8, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,901|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_15433_[8, 32767, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,911|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42894_[512, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,924|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65686_[8, 65535, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,936|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22138_[512, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,950|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_90037_[1024, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,967|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23967_[1024, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:27,985|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_47869_[512, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,000|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47301_[8, 131071, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,000|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_39337_[1024, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,001|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44371_[1024, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,015|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_49066_[1024, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,038|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_27637_[1024, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,056|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_25823_[1024, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,117|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_30352_[1024, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,150|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_2765_[1024, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,179|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21269_[2048, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,191|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94897_[2048, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,197|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45756_[2048, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,206|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_22318_[16, 1, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,210|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_33780_[16, 3, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,213|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_81594_[16, 7, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,217|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34679_[16, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,221|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_43161_[16, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,226|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_63856_[16, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,230|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56035_[16, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,231|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_11121_[2048, 15, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,234|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_59122_[16, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,239|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43911_[2048, 31, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,240|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73387_[16, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,241|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_96262_[16, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,247|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_38649_[16, 2047, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,251|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61468_[16, 4095, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,260|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_85447_[1024, 1023, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,264|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24435_[16, 8191, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,273|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_5928_[16, 16383, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,301|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72158_[16, 32767, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,314|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59817_[2048, 63, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,347|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63445_[16, 65535, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,389|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_71405_[2048, 127, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,453|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99862_[16, 131071, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,506|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_65281_[2048, 255, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:28,662|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_25549_[2048, 511, 4, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,657|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_29151_[32, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,668|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_46633_[32, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,676|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26291_[32, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,682|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67881_[32, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,689|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31038_[32, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,697|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95067_[32, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,702|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57864_[32, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,708|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_50419_[32, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,715|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_4276_[32, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,723|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_46387_[32, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,737|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30509_[32, 4095, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,739|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73876_[32, 2047, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,743|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_50650_[32, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,743|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77107_[32, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,756|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_84576_[32, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,772|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32846_[32, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,774|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_35034_[32, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,777|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_29060_[32, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,778|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_94601_[32, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,784|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_33333_[32, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,791|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_29011_[32, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,802|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_67790_[32, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,812|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_1867_[32, 4095, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,814|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28856_[32, 2047, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,819|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_34632_[32, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,820|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_85814_[32, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,828|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85560_[32, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,842|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22036_[32, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,851|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_87611_[32, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,853|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8868_[32, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,859|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74514_[32, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,860|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45263_[32, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,865|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_69372_[32, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,881|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_60987_[32, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,902|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54815_[32, 4095, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,905|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_724_[32, 2047, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,943|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_47877_[32, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,945|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14077_[32, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,951|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_16690_[32, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,955|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_32648_[32, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,960|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_54542_[32, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,970|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36794_[32, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,975|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_61030_[32, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,980|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_81360_[1, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,983|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_1959_[1, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,983|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33338_[1, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,986|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_25378_[1, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,987|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_9986_[1, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,989|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77986_[1, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,992|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_51908_[1, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,992|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24703_[1, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:34,999|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_78965_[1, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,003|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_4201_[1, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,008|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12060_[1, 2047, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,013|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_69815_[32, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,016|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_52957_[32, 2047, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,019|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_88246_[1, 4095, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,019|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_66878_[32, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,022|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53841_[32, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,025|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_46959_[1, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,026|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_78007_[1, 8191, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,027|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70763_[1, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,028|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36783_[1, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,029|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_72573_[1, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,030|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67527_[1, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,031|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95971_[1, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,031|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_46511_[1, 16383, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,032|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44435_[1, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,033|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26459_[1, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,033|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93280_[32, 4095, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,034|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_19169_[1, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,034|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_67324_[1, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,035|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_92120_[1, 2047, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,036|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50877_[1, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,037|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_2208_[1, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,038|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62488_[1, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,038|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_803_[1, 4095, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,039|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81889_[1, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,039|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_39147_[1, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,041|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_59708_[1, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,041|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43683_[1, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,042|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_18411_[1, 8191, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,042|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_59626_[1, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,042|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_63545_[1, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,043|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_21415_[1, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,046|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_27631_[1, 2047, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,046|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_28459_[1, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,046|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_1163_[1, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,046|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_80299_[1, 4095, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,049|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93864_[1, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,049|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_60170_[1, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,049|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_20397_[1, 16383, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,049|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_30479_[1, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,049|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67305_[1, 8191, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,050|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_17742_[1, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,052|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50710_[1, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,052|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16760_[1, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,052|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_92411_[1, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,055|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_20534_[1, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,055|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_14741_[2, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,056|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_55141_[1, 4095, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,056|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_27731_[1, 16383, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,056|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_25435_[1, 2047, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,058|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81652_[2, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,058|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_87875_[2, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,059|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_97120_[1, 8191, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,060|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_4274_[2, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,060|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_93294_[2, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,061|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_68312_[2, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,061|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52985_[2, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,061|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99072_[2, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,062|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_83924_[2, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,063|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53112_[1, 16383, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,064|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_71258_[2, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,065|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42477_[2, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,066|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_98273_[2, 4095, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,067|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83194_[2, 2047, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,067|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_95085_[2, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,068|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_69876_[2, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,068|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70521_[2, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,069|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_43027_[2, 8191, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,070|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_20764_[2, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,070|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_62232_[2, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,070|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_3763_[2, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,071|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81770_[2, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,071|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74545_[2, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,073|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_56515_[2, 16383, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,074|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_87527_[2, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,075|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_88062_[2, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,075|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20061_[2, 2047, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,076|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_15163_[2, 4095, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,078|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96056_[2, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,078|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_11787_[2, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,078|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32262_[2, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,078|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_53625_[2, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,079|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30117_[2, 8191, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,079|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_59477_[2, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,080|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_75350_[2, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,081|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_25509_[2, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,081|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37602_[2, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,082|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10656_[2, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,083|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_6833_[2, 16383, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,083|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54272_[2, 2047, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,084|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76213_[2, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,085|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_49434_[2, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,087|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_87313_[2, 4095, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,087|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45229_[2, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,087|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1165_[2, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,088|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57873_[2, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,088|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_50536_[2, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,088|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_2798_[2, 8191, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,090|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_35267_[2, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,090|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85431_[2, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,091|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2829_[2, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,091|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_80672_[2, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,092|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_47478_[2, 2047, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,093|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34287_[2, 16383, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,095|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97176_[2, 4095, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,097|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42490_[2, 8191, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,103|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75027_[2, 16383, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,115|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_90154_[64, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,119|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_68558_[64, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,122|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95582_[64, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,125|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53711_[64, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,134|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81316_[64, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,138|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_71391_[64, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,138|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_26748_[64, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,153|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19070_[64, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,155|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_82668_[64, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,165|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_68353_[64, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,174|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28648_[64, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,179|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_24721_[64, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,190|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_34246_[64, 2047, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,194|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37319_[64, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,195|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31303_[64, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,201|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_57495_[64, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,220|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17997_[64, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,226|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_78410_[64, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,228|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32529_[64, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,240|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_64455_[64, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,240|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22882_[64, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,242|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_18764_[64, 2047, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,252|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_27262_[64, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,304|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33912_[64, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,319|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_41190_[64, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,322|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_94146_[64, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,327|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_46875_[64, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,336|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_50403_[64, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,348|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57033_[64, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,349|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71560_[64, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,351|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_20023_[64, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,404|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_67683_[64, 2047, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,415|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_515_[64, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,420|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13119_[64, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,425|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_31656_[64, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,435|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_72374_[64, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,443|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32673_[64, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,443|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97250_[64, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,450|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_31828_[64, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,479|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_16320_[4, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,489|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28418_[4, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,489|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79391_[64, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,503|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_81617_[4, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,508|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14057_[4, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,522|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45214_[64, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,531|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30005_[64, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,535|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_54545_[64, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,541|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_47056_[4, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,551|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_74829_[4, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,558|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_36040_[64, 2047, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,564|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26087_[4, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,569|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59073_[4, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,583|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_82951_[4, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,585|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67171_[4, 2047, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,588|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_19832_[4, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,590|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_661_[4, 4095, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,590|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62410_[4, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,605|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_14909_[4, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,606|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_27464_[4, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,606|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_45911_[4, 8191, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,618|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44718_[4, 16383, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,621|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_60687_[4, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,627|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_13014_[4, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,632|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60512_[4, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,633|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64404_[4, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,639|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_38108_[4, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,643|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_54112_[4, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,660|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_50780_[4, 8191, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,673|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17188_[4, 4095, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,682|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_52693_[4, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,686|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82035_[4, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,696|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_82888_[4, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,697|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_70502_[4, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,700|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_88775_[4, 16383, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,700|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44858_[4, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,701|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_30015_[4, 2047, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,712|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_9552_[4, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,718|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14806_[4, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,734|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59122_[4, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,734|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73090_[4, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,737|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_19006_[4, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,746|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87340_[4, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,756|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81530_[4, 2047, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,756|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11135_[4, 4095, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,759|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_635_[4, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,780|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37609_[4, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,788|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22019_[4, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,790|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_3188_[4, 16383, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,791|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_82340_[4, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,792|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_89050_[4, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,796|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87243_[4, 8191, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,813|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66255_[4, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,825|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59388_[4, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,835|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_79344_[4, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,835|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11493_[4, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,839|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42553_[4, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,852|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97575_[4, 2047, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_1148_[4, 4095, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,859|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_29548_[4, 8191, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,860|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26618_[4, 16383, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,876|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93790_[128, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,892|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_80205_[128, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,894|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62516_[128, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,895|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_68788_[128, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,899|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_7719_[128, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,900|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11573_[128, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,916|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_3519_[128, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,918|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_61427_[128, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,956|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_57672_[128, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,980|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_26402_[128, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,987|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53712_[128, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,990|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_35817_[128, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,993|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17964_[128, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:35,998|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84091_[128, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,012|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_21794_[128, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,017|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57020_[128, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,045|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_12858_[128, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,097|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_9655_[128, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,103|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68408_[128, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,111|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_46216_[128, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,116|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_52204_[128, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,121|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49557_[128, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,126|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_93222_[128, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,130|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_2912_[128, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,146|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52331_[128, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,215|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_40428_[128, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,216|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_58433_[128, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,229|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_10693_[128, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,244|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_2338_[128, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,253|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49986_[128, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,257|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_54221_[128, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,258|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96135_[128, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,261|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_50541_[128, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,303|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_89211_[128, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,311|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_83199_[128, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,329|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56594_[128, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,342|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32494_[128, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,360|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2193_[128, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,361|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_62492_[256, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,362|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33345_[128, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,366|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_49439_[128, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,425|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63266_[256, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,439|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36411_[256, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,451|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56359_[256, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,455|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_96623_[256, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,466|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62344_[256, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,472|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_55907_[256, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,475|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_41287_[256, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,497|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70978_[256, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,550|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_62426_[256, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,557|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_55234_[256, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,586|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_83578_[256, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,586|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_38266_[256, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,594|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62060_[256, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,595|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_87843_[256, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,611|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99062_[256, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,618|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42424_[256, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,666|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57462_[256, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,668|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_65193_[256, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,721|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_15466_[256, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,723|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_6680_[256, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,723|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_92879_[256, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,735|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_49238_[256, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,742|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66372_[256, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,747|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_65119_[256, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,763|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_92000_[256, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,784|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26228_[256, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,842|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_17200_[256, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,848|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81158_[256, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,877|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43940_[256, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,878|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93908_[256, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,879|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_10348_[256, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,886|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17309_[512, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,892|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_54509_[512, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,934|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16805_[512, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,956|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_91058_[512, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:36,996|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14368_[512, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,014|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49857_[512, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,023|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_78877_[512, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,032|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_25621_[512, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,035|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84473_[512, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,046|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_95567_[512, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,067|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48489_[512, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,127|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52030_[512, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,128|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_7907_[512, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,164|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_99014_[512, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,169|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_92630_[512, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,169|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_40454_[512, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,187|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_97452_[512, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,199|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_18912_[512, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,214|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95739_[512, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,298|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_84820_[512, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,315|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74001_[512, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,334|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_57931_[512, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,339|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_65043_[512, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,358|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_66898_[512, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,361|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85077_[8, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,366|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_41660_[8, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,367|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_82834_[512, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,368|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_24740_[512, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,371|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49424_[8, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,387|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_18947_[8, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,393|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26725_[8, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,403|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_22654_[512, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,409|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_15905_[8, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,415|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_69730_[8, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,415|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81919_[8, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,421|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_2818_[8, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,425|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79195_[8, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,450|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65002_[8, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,457|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95534_[8, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,458|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_18558_[8, 2047, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,468|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_25696_[8, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,471|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_18432_[8, 4095, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,474|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70784_[8, 16383, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,484|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_79969_[8, 8191, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,487|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95418_[8, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,497|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40562_[8, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,510|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_17951_[8, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,510|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13645_[8, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,513|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_75690_[8, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,516|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_44134_[512, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,522|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_47684_[8, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,533|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96364_[8, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,536|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_7143_[8, 2047, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,553|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_13263_[8, 4095, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,554|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16766_[8, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,559|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_34017_[8, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,566|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_39365_[8, 8191, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,574|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_16547_[8, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,577|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30974_[8, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,576|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11131_[8, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,579|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61537_[8, 16383, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,596|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_5484_[8, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,598|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_49526_[8, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,602|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52061_[8, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,613|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_5560_[8, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,616|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_47720_[8, 4095, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,618|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_10201_[8, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,627|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_54847_[8, 2047, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,634|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_89217_[8, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,655|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_59849_[8, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,667|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85195_[8, 8191, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,668|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12183_[8, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,669|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11634_[8, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,669|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_95250_[8, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,669|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17169_[8, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,669|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_72467_[8, 16383, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,673|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87307_[8, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,696|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34864_[8, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,706|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_90280_[8, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,710|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62550_[8, 2047, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,714|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_82776_[8, 8191, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,716|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97873_[8, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,716|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_70376_[8, 4095, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,732|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_53071_[8, 16383, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,920|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57181_[1024, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,937|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_62804_[1024, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,945|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56627_[1024, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,957|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34160_[1024, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,963|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_998_[1024, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,965|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60132_[1024, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,971|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38640_[1024, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:37,983|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_69471_[1024, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,113|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_3254_[1024, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,176|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_25350_[1024, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,185|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26413_[1024, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,207|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80747_[1024, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,208|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_70555_[1024, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,213|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_11511_[1024, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,215|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_48876_[1024, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,227|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_3054_[1024, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,318|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85451_[1024, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,427|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93222_[1024, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,440|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51958_[1024, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,448|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28467_[1024, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,449|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_94025_[1024, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,455|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_2325_[1024, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,461|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_21961_[1024, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,469|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_51030_[1024, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,709|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_39514_[2048, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,856|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_17257_[2048, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,868|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_37045_[2048, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,878|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_43907_[2048, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,880|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_39558_[2048, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,895|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_49175_[2048, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,904|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_94638_[2048, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:38,905|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83507_[2048, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,105|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46178_[2048, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,283|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22472_[2048, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,301|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4891_[2048, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,305|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14440_[2048, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,318|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_63070_[2048, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,325|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_77249_[2048, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,331|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_44519_[16, 1, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,343|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17585_[16, 7, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,344|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_9066_[16, 3, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,344|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_91763_[2048, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,352|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67113_[2048, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,359|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_51258_[16, 15, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,371|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_9973_[16, 63, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,377|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_86340_[16, 31, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,380|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83530_[16, 127, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,390|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50536_[16, 255, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,402|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_91973_[16, 1023, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,402|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_51997_[16, 511, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,404|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83980_[16, 2047, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,427|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81167_[16, 3, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,430|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_33597_[16, 4095, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,430|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_77010_[16, 1, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,435|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_77482_[16, 8191, 128, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,447|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_95136_[16, 7, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,453|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_52075_[16, 31, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,459|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15868_[16, 15, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,462|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81593_[16, 63, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,470|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_86434_[16, 127, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,486|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_85188_[16, 255, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,488|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99457_[16, 1023, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,492|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_71681_[16, 511, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,499|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47645_[16, 2047, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,515|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_63094_[16, 3, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,518|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_19830_[16, 1, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,524|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_53993_[16, 4095, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,525|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_8924_[16, 8191, 128, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,540|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82844_[16, 7, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,544|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_48091_[16, 31, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,544|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_37047_[16, 15, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,552|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_69056_[16, 63, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,574|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52591_[16, 127, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,581|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24820_[16, 1023, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,586|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_36099_[16, 255, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,586|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_77335_[16, 511, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,604|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_31580_[16, 2047, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,616|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3194_[16, 1, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,616|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_40331_[16, 4095, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,617|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_72313_[2048, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,624|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20445_[16, 8191, 128, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,627|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_23676_[16, 3, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,639|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_22292_[16, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,645|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_88036_[16, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,647|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48747_[16, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,652|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_81797_[16, 63, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,657|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33224_[16, 127, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,685|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20285_[16, 2047, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,686|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99253_[16, 255, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,686|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_24158_[16, 511, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,688|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_5486_[16, 1023, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,692|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_7827_[16, 4095, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,730|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_29418_[16, 8191, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,781|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79270_[2048, 7, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,796|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78058_[2048, 15, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:38:39,811|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9873_[2048, 31, 128, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,121|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_69132_[32, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,127|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_88999_[32, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,134|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90530_[32, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,140|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_10488_[32, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,146|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57264_[32, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,152|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70238_[32, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,158|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33768_[32, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,164|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78249_[32, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,170|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_63192_[32, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,185|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_73088_[32, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,193|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13531_[32, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,195|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_48465_[32, 2047, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,204|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36668_[32, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,207|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_14775_[32, 4095, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,218|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_3898_[32, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,219|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26920_[32, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,230|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4617_[32, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,236|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_72173_[32, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,236|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_86610_[32, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,245|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_15809_[32, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,244|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_91699_[32, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,257|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_86589_[32, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,270|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_94302_[32, 2047, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,274|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_89943_[32, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,287|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84353_[32, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,282|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_41885_[32, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,288|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_91627_[32, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,293|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_32923_[32, 4095, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,296|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_89893_[32, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,303|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_53574_[32, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,326|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51228_[32, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,324|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36371_[32, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,340|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83375_[32, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,343|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86445_[32, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,344|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99735_[32, 2047, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,359|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_68153_[32, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,365|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12818_[32, 4095, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,413|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_50381_[32, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,421|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27561_[32, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,431|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_89433_[32, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,420|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48864_[32, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,441|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87248_[32, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,441|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16942_[1, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,449|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_36257_[32, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,450|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_16603_[32, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,452|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_35444_[32, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,461|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_35272_[1, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,463|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_61565_[1, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,462|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56672_[1, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,463|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_29974_[1, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,463|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69172_[1, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,466|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_56733_[1, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,467|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_44269_[1, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,469|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_18462_[1, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,469|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42469_[1, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,471|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79287_[1, 2047, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,477|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_19946_[1, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,477|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_64941_[1, 4095, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,478|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_68736_[1, 8191, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,479|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_16604_[1, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,481|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27387_[1, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,483|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_64463_[1, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,484|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_23373_[1, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,484|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_45334_[1, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,486|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_71595_[1, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,487|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68660_[1, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,487|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_79493_[1, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,487|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_87201_[1, 16383, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,488|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85962_[1, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,488|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_3186_[32, 4095, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,488|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_50008_[32, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,492|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79582_[1, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,492|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8992_[1, 2047, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,495|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_20756_[1, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,495|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_53812_[1, 4095, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,495|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93086_[1, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,495|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_84949_[32, 2047, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,496|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_82264_[1, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,496|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_34427_[1, 8191, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,496|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_91524_[1, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,498|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74024_[1, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,498|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33271_[1, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,499|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_45717_[1, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,499|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_71798_[1, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,501|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_61506_[1, 2047, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,501|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_95343_[1, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,502|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_22008_[1, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,502|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_29222_[1, 16383, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,502|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40081_[1, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,503|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8521_[1, 4095, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,504|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_54625_[1, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,505|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43477_[1, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,505|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97127_[1, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,506|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_83479_[1, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,507|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_44141_[1, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,507|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_94089_[1, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,507|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65591_[1, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,508|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27168_[1, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,509|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_46421_[1, 8191, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,509|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_18677_[1, 2047, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,510|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_92318_[2, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,511|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62523_[2, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,513|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23089_[2, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,513|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_81078_[2, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,513|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_93527_[1, 4095, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,513|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_3047_[2, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,514|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90973_[2, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,514|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_30462_[1, 8191, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,515|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_69993_[1, 16383, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,516|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39904_[2, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,516|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_12394_[2, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,516|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62254_[2, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,518|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_30805_[2, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,519|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59498_[2, 2047, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,519|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42426_[2, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,519|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_74323_[2, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,521|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86154_[2, 4095, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,522|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49549_[2, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,522|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59611_[2, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,522|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54397_[2, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,522|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24892_[2, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,525|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_52598_[2, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,525|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_83538_[2, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,524|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85299_[2, 8191, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,525|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67203_[1, 16383, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,525|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_27296_[2, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,525|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84911_[2, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,527|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_25002_[2, 2047, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,528|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_19015_[2, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,528|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_67088_[2, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,530|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52050_[2, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,530|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_55748_[2, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,531|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_29497_[2, 4095, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,531|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3401_[2, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,531|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_2653_[2, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,533|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42757_[2, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,534|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_91785_[2, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,534|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_12513_[2, 8191, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,534|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52439_[2, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,536|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_50773_[2, 2047, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,536|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19969_[2, 16383, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,536|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_11824_[2, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,539|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_3656_[2, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,539|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70778_[2, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,539|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8117_[2, 4095, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,539|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_56720_[2, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,539|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_67797_[2, 16383, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,540|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_33031_[2, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,542|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_77555_[2, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,541|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_54692_[2, 8191, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,542|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60211_[2, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,543|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_66035_[2, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,543|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_16401_[2, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,544|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_44246_[2, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,544|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_25448_[2, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,546|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36611_[2, 2047, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,547|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76581_[2, 4095, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,549|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52045_[2, 16383, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,550|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_82244_[2, 8191, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,557|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_54279_[2, 16383, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,573|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_3774_[64, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,579|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76694_[64, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,585|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_83311_[64, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,585|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_51240_[64, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,590|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_80697_[64, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,597|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_83683_[64, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,601|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_70627_[64, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,601|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_27499_[64, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,632|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_6888_[64, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,640|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_65291_[64, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,647|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68255_[64, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,653|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65118_[64, 2047, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,657|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81648_[64, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,657|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_56846_[64, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,661|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_16896_[64, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,661|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62062_[64, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,673|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_39455_[64, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,686|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46472_[64, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,701|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_58989_[64, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,702|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_83648_[64, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,703|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_8659_[64, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,712|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_1092_[64, 2047, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,725|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80506_[64, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,731|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_6193_[64, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,756|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61491_[64, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,789|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_68027_[64, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,793|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31677_[64, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,795|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19625_[64, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,804|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58003_[64, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,805|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_51917_[64, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,822|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_10918_[64, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,853|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57720_[64, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,867|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_93990_[64, 2047, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,873|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_50396_[64, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,891|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_25970_[64, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,897|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_85003_[64, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,907|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80928_[64, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,909|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_8344_[64, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,915|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89169_[64, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,939|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93497_[64, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,946|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_63849_[4, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,953|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69606_[4, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,964|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45623_[64, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,974|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60393_[4, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,982|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_85370_[64, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,985|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84923_[4, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:03,998|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77141_[4, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,000|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_88752_[4, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,006|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87182_[64, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,008|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36211_[64, 2047, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,011|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_69923_[4, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,012|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_61510_[4, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,020|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_90348_[4, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,046|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_69826_[4, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,054|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34998_[4, 4095, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,067|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_55643_[4, 16383, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,069|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_6773_[4, 2047, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,071|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56657_[4, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,071|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74075_[4, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,072|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38190_[4, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,076|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75081_[4, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,086|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38596_[4, 8191, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,099|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_58280_[4, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,101|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45191_[4, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,105|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45660_[4, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,117|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_40700_[4, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,121|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33880_[4, 2047, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,122|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34288_[4, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,125|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11870_[4, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,132|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30396_[4, 4095, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,136|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59222_[4, 8191, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,146|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74320_[4, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,155|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99625_[4, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,165|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40225_[4, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,166|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62298_[4, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,170|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26226_[4, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,176|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62590_[4, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,188|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_5521_[4, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,193|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_40239_[4, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,201|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27575_[4, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,205|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_30694_[4, 16383, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,208|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22608_[4, 2047, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,217|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79381_[4, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,227|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85798_[4, 8191, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,237|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28619_[4, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,237|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_45977_[4, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,241|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_57110_[4, 4095, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,251|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_43429_[4, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,259|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_21881_[4, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,260|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_22450_[4, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,268|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14256_[4, 16383, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,269|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97686_[4, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,275|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60845_[4, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,288|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19691_[4, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,288|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61342_[4, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,300|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_14073_[4, 4095, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,309|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_91672_[4, 8191, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,310|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11863_[4, 2047, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,310|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_29318_[4, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,329|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_39571_[4, 16383, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,332|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55548_[128, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,348|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_35906_[128, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,357|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_76075_[128, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,360|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_1114_[128, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,363|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68887_[128, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,363|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71249_[128, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,366|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_20971_[128, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,375|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16664_[128, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,423|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_29095_[128, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,443|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49050_[128, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,448|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_31137_[128, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,460|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_77208_[128, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,467|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_25239_[128, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,471|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_29793_[128, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,473|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17407_[128, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,475|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_64944_[128, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,509|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_50646_[128, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,540|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96338_[128, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,540|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79895_[128, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,557|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_16971_[128, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,571|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91146_[128, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,573|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_39272_[128, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,575|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_63640_[128, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,579|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_43901_[128, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,591|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_72081_[128, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,612|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_85778_[128, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,621|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_83455_[128, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,645|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_30471_[128, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,663|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66599_[128, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,671|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85268_[128, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,677|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39048_[128, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,690|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_35168_[128, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,695|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_21273_[128, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,707|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_21211_[128, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,713|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_47333_[128, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,722|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_64860_[128, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,739|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_48828_[128, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,762|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_92596_[128, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,779|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_52288_[256, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,783|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_51172_[128, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,791|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_34597_[128, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,800|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_90788_[256, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,802|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_53116_[256, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,824|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_95483_[256, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,825|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49447_[256, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,850|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63658_[256, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,874|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_91831_[256, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,889|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_25768_[256, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,897|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_26895_[256, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,906|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_60616_[256, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,912|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_83852_[256, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,929|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_10533_[256, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,932|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_92571_[256, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,951|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63800_[256, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,962|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_64461_[256, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,981|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_67204_[256, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:04,999|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42166_[256, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,006|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99724_[256, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,011|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11250_[256, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,027|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52261_[256, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,033|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_98488_[256, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,049|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_75652_[256, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,066|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_88684_[256, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,085|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_7970_[256, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,103|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78117_[256, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,109|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_63992_[256, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,137|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_7475_[256, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,140|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52350_[256, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,152|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31351_[256, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,159|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82304_[256, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,175|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_37465_[256, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,181|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_20676_[256, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,217|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74363_[512, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,235|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_26027_[512, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,276|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45839_[512, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,304|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17288_[512, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,308|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_37929_[512, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,319|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_92762_[512, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,323|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_53489_[512, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,329|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15231_[512, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,343|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_13023_[512, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,359|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14843_[512, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,424|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_92959_[512, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,465|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51456_[512, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,479|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8686_[512, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,500|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80276_[512, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,506|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_61722_[512, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,508|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72385_[512, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,518|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_91800_[512, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,524|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20184_[512, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,556|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_87792_[512, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,617|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_96541_[512, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,671|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14427_[512, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,675|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46613_[512, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,675|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_47561_[512, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,693|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_51004_[512, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,708|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_73617_[512, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,709|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_19024_[512, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,717|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_15988_[8, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,717|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77940_[512, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,718|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81728_[8, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,733|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_58878_[8, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,748|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_54369_[8, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,748|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_95536_[8, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,753|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_18425_[8, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,754|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64319_[8, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,759|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_72262_[8, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,768|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_29857_[8, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,789|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_98733_[8, 2047, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,789|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_35730_[8, 4095, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,791|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79826_[8, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,797|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42741_[8, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,816|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97928_[8, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,826|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85887_[8, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,826|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71905_[8, 8191, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,827|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94304_[8, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,839|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54607_[512, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,841|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_35129_[8, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,844|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_20140_[8, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,862|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_97227_[8, 16383, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,874|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_47553_[8, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,877|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_12230_[8, 2047, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,877|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_74329_[8, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,883|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_9866_[8, 4095, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,890|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_39245_[8, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,891|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39470_[8, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,896|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86206_[8, 8191, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,920|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46229_[8, 16383, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,926|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_33063_[8, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,930|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_47623_[8, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,939|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_56779_[8, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,940|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14679_[8, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,942|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_71586_[8, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,944|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_35625_[8, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,951|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_88585_[8, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,956|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_58577_[8, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,957|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_27256_[8, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,967|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_56273_[8, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,971|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23937_[8, 4095, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,984|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_64033_[8, 8191, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:05,984|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8239_[8, 2047, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,001|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_71060_[8, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,009|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_47336_[8, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,009|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28229_[8, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,009|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87189_[8, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,019|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_39745_[8, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,021|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86700_[8, 16383, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,024|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50600_[8, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,041|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_90612_[8, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,042|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_72849_[8, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,044|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_25713_[8, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,058|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97962_[8, 2047, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,061|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_87158_[8, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,067|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_64106_[8, 8191, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,070|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_60414_[8, 4095, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,094|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10135_[8, 16383, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,249|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_79432_[1024, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,260|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95113_[1024, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,266|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82648_[1024, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,269|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_9059_[1024, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,278|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_91281_[1024, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,289|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97640_[1024, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,290|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_12522_[1024, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,301|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_43319_[1024, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,437|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_35880_[1024, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,468|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80475_[1024, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,495|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59797_[1024, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,504|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_90256_[1024, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,508|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_56691_[1024, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,508|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39735_[1024, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,508|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82114_[1024, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,519|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54147_[1024, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,648|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27398_[1024, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,671|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_3556_[1024, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,695|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19699_[1024, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,712|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_13744_[1024, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,717|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_27318_[1024, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,721|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_74478_[1024, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,726|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73613_[1024, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,740|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30926_[1024, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:06,995|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70479_[2048, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,043|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17106_[2048, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,076|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_40621_[2048, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,093|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_28184_[2048, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,097|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_63341_[2048, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,099|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3864_[2048, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,102|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42712_[2048, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,107|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_13332_[2048, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,347|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23244_[2048, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,420|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66875_[2048, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,451|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_8552_[2048, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,462|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50655_[2048, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,463|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_3039_[2048, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,466|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62085_[2048, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,478|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4844_[2048, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,479|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_990_[16, 1, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,491|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_6435_[2048, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,493|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34420_[16, 3, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,500|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_7882_[16, 7, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,517|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_33759_[16, 31, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,520|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96190_[16, 15, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,521|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96868_[16, 63, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,521|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_88812_[16, 127, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,539|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_97753_[16, 255, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,540|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41130_[16, 511, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,547|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_15297_[16, 2047, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,556|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_20478_[16, 1023, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,559|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56883_[16, 1, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,568|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52095_[16, 4095, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,574|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64636_[16, 3, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,577|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33672_[16, 8191, 96, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,585|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_38341_[16, 7, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,591|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77411_[16, 31, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,594|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_20218_[16, 15, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,597|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83980_[16, 63, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,604|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_84938_[16, 127, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,617|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_62210_[16, 255, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,618|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_15519_[16, 1023, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,619|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3338_[16, 511, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,629|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_83458_[16, 2047, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,642|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_33892_[16, 1, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,653|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_77397_[16, 3, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,656|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_41484_[16, 4095, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,660|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31767_[16, 7, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,667|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_90976_[16, 15, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,670|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73730_[16, 8191, 96, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,676|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_55788_[16, 63, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,679|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84365_[16, 31, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,691|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56183_[16, 127, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,700|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_61312_[16, 255, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,703|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45375_[16, 511, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,715|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_38476_[16, 2047, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,716|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_90359_[16, 1023, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,729|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_50933_[16, 1, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,741|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80983_[16, 4095, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,743|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_68555_[16, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,750|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_20194_[16, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,755|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3606_[16, 8191, 96, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,759|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_33266_[16, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,767|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57709_[16, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,768|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_34394_[2048, 3, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,780|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_95290_[16, 127, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,780|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_94950_[16, 63, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,781|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96874_[16, 255, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,791|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_39642_[16, 511, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,798|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_92239_[16, 1023, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,805|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_390_[16, 2047, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,836|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52263_[16, 4095, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,842|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44864_[16, 8191, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,885|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30883_[2048, 7, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,899|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_66392_[2048, 15, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:07,925|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_5492_[2048, 31, 96, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,905|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_37388_[32, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,910|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76533_[32, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,919|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_73391_[32, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,925|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_39333_[32, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,925|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30889_[32, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,931|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93973_[32, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,940|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85700_[32, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,940|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_32078_[32, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,946|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_73797_[32, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,953|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_61107_[32, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,961|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16289_[32, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,969|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79709_[32, 4095, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,970|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_21284_[32, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,983|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50813_[32, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,990|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_7850_[32, 8191, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,989|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_66925_[32, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:31,995|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_21439_[32, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,007|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31397_[32, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,014|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_9053_[32, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,025|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60699_[32, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,024|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_87541_[32, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,031|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66549_[32, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,037|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_59995_[32, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,045|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8192_[32, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,052|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_67603_[32, 4095, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,061|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57812_[32, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,067|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66297_[32, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,073|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3029_[32, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,085|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_15459_[32, 8191, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,087|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_37000_[32, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,098|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_25490_[32, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,099|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26785_[32, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,099|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47766_[32, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,111|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62430_[32, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,135|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_91766_[32, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,137|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_68105_[32, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,138|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_61953_[32, 4095, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,144|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_19659_[32, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,158|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_66965_[32, 8191, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,195|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62300_[32, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,196|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_25691_[32, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,212|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_6121_[32, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,231|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_69240_[32, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,245|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51300_[32, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,250|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_62503_[32, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,250|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_25859_[32, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,238|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74351_[32, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,263|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19979_[1, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,264|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_6960_[1, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,264|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_53238_[1, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,261|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52058_[32, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,267|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7572_[1, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,269|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45889_[1, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,270|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61912_[1, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,271|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30623_[1, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,271|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_51757_[1, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,272|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_53928_[1, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,274|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_18020_[1, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,283|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13879_[1, 8191, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,284|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46877_[1, 4095, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,284|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85808_[1, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,287|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84516_[32, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,290|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95373_[1, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,291|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53961_[1, 16383, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,292|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_45961_[1, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,292|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_38337_[1, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,294|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32379_[1, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,295|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_82349_[1, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,295|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48670_[32, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,296|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_64251_[1, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,296|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_67486_[1, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,297|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_16442_[1, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,298|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62553_[1, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,301|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_39390_[32, 4095, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,302|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_29604_[1, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,302|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_94428_[1, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,304|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22462_[1, 4095, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,304|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_80403_[32, 8191, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,306|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_482_[1, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,307|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_28041_[1, 8191, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,307|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53931_[1, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,307|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_73996_[1, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,309|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_82812_[1, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,310|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_46468_[1, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,310|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_73546_[1, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,311|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_16474_[1, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,313|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49600_[1, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,313|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_75315_[1, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,313|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42836_[1, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,314|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99344_[1, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,315|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_97670_[1, 16383, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,316|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89081_[1, 4095, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,317|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_55018_[1, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,319|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90747_[1, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,320|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_29199_[1, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,320|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_13300_[1, 8191, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,320|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_36907_[1, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,322|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32258_[1, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,322|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10922_[1, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,323|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_30293_[1, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,323|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85120_[1, 32767, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,324|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_8502_[1, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,325|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64134_[1, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,326|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19642_[1, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,327|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_9395_[1, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,329|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_6285_[1, 4095, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,330|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_58413_[2, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,332|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86436_[1, 16383, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,332|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67384_[2, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,333|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75396_[2, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,333|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7021_[1, 32767, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,333|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_29620_[1, 8191, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,335|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36536_[2, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,335|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17181_[2, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,336|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_38652_[1, 16383, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,337|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50064_[2, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,338|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_38744_[2, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,338|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_63709_[2, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,338|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_10755_[2, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,339|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49786_[2, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,341|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65713_[2, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,342|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86464_[2, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,343|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_2604_[1, 32767, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,344|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_78867_[2, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,345|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19957_[2, 8191, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,345|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34386_[2, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,345|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42591_[2, 4095, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,347|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52115_[2, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,347|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_72616_[2, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,348|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_2518_[2, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,349|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24143_[2, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,349|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_30023_[2, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,350|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65314_[2, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,352|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63666_[2, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,352|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59504_[2, 16383, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,353|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60951_[2, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,354|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2555_[2, 4095, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,357|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84748_[2, 8191, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,357|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_5299_[2, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,357|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_6805_[2, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,357|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_18903_[1, 32767, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,358|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_14245_[2, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,360|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_4549_[2, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,360|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_88095_[2, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,360|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_75780_[2, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,361|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91483_[2, 32767, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,361|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_69800_[2, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,362|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_16424_[2, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,363|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_83264_[2, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,364|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19862_[2, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,365|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_72588_[2, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,366|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32076_[2, 4095, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,366|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_50194_[2, 16383, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,368|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80207_[2, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,368|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_221_[2, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,370|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_35880_[2, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,370|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_26012_[2, 8191, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,370|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_4691_[2, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,371|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17143_[2, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,371|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_73629_[2, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,372|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_4883_[2, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,373|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48064_[2, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,374|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_12767_[2, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,374|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75762_[2, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,376|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_89277_[2, 16383, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,377|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_32340_[2, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,378|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_9228_[2, 4095, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,381|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_47174_[2, 32767, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,381|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95290_[2, 8191, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,385|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60489_[2, 32767, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,386|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79742_[2, 16383, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,400|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_6980_[64, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,406|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_22356_[64, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,411|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_87209_[64, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,417|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_58894_[64, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,418|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72370_[64, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,419|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_98580_[64, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,423|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_4352_[2, 32767, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,429|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_18975_[64, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,431|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_92496_[64, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,444|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22256_[64, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,468|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_22507_[64, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,469|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42390_[64, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,473|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_94270_[64, 4095, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,474|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_23206_[64, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,478|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_28426_[64, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,482|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_53923_[64, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,489|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99942_[64, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,496|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81805_[64, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,503|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76684_[64, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,508|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_54057_[64, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,512|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19595_[64, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,523|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49777_[64, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,528|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_29850_[64, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,533|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74324_[64, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,576|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_32556_[64, 4095, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,594|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34162_[64, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,610|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28779_[64, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,622|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_55996_[64, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,622|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_4293_[64, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,623|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15092_[64, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,624|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_45267_[64, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,634|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_3076_[64, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,644|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_51217_[64, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,675|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28009_[64, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,691|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_76136_[64, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,716|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84522_[64, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,723|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_18007_[64, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,730|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_71050_[64, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,737|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11603_[64, 4095, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,746|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37657_[64, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,751|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22928_[64, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,766|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33409_[64, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,777|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_35816_[64, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,783|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24919_[4, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,787|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_48772_[64, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,798|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62554_[4, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,799|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31917_[4, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,801|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17335_[64, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,803|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_95456_[4, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,807|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_40115_[4, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,808|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19590_[4, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,810|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_24012_[4, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,814|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4685_[4, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,816|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_93705_[64, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,823|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87330_[64, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,824|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_9949_[4, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,825|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37358_[64, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,825|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_70717_[4, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,830|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81343_[4, 4095, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,832|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73247_[4, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,833|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89714_[4, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,834|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99293_[4, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,834|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_40866_[64, 4095, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,836|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_90408_[4, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,837|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23273_[4, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,837|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_83361_[4, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,839|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51933_[4, 8191, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,840|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_29392_[4, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,841|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_97800_[4, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,841|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_44669_[4, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,842|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86439_[4, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,846|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_95211_[4, 16383, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,847|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24518_[4, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,848|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_28510_[4, 4095, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,848|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41946_[4, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,850|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_70454_[4, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,852|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_90299_[4, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,853|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_86134_[4, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57457_[4, 8191, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,853|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_87167_[4, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,854|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59903_[4, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,856|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58216_[4, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,856|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_79721_[4, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,857|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_2493_[4, 32767, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,857|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_17553_[4, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,860|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_9089_[4, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,860|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_95014_[4, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,861|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_23910_[4, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,862|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_34592_[4, 4095, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,864|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_32033_[4, 16383, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,864|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_64302_[4, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,864|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_76959_[4, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,867|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_88511_[4, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,868|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_78166_[4, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,868|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14995_[4, 8191, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,869|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_13624_[4, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,870|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_11057_[4, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,870|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66119_[4, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,870|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99840_[4, 32767, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,871|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_3813_[4, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,874|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_53907_[4, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,875|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_1171_[4, 16383, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,875|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_58206_[4, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,875|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24088_[4, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,877|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_8119_[4, 4095, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,880|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_31680_[4, 8191, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,887|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_69005_[4, 16383, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,891|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39219_[128, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,893|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95453_[4, 32767, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,901|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_50782_[128, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,910|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_72502_[4, 32767, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,911|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_23205_[128, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,916|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_15380_[128, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,921|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_29472_[128, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,922|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89515_[128, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,938|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75493_[128, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,947|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_20970_[128, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,957|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15818_[128, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,966|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34754_[128, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,983|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_59303_[128, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:32,990|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68262_[128, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,002|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39899_[128, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,009|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_77067_[128, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,017|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_82574_[128, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,049|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_8467_[128, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,060|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93522_[128, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,067|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51566_[128, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,078|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_15337_[128, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,086|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_81774_[128, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,097|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_63052_[128, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,130|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85785_[128, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,133|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_49395_[128, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,152|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_67187_[128, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,153|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_6188_[128, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,157|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_75331_[128, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,171|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_42297_[128, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,201|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_34506_[128, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,214|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_90957_[128, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,216|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66843_[128, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,232|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_45166_[128, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,244|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_92781_[128, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,249|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_64181_[128, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,258|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_68012_[128, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,289|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_7142_[128, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,295|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_70507_[128, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,301|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_47696_[128, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,328|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_96030_[128, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,351|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76231_[128, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,353|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_40056_[128, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,359|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61344_[128, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,380|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59705_[128, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,384|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_28789_[128, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,392|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_67760_[128, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,393|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_64336_[256, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,422|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_9411_[256, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,432|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_10779_[256, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,439|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21236_[256, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,469|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76443_[256, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,487|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_77855_[256, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,499|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_10478_[256, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,508|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_33490_[256, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,515|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85084_[256, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,533|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_74561_[256, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,533|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_92092_[256, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,545|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97437_[256, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,569|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_9861_[256, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,577|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_32043_[256, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,603|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_94193_[256, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,629|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69263_[256, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,638|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43295_[256, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,668|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45535_[256, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,671|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44372_[256, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,671|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_20164_[256, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,675|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_40879_[256, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,687|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33201_[256, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,728|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91405_[256, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,775|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_33969_[256, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,781|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_94852_[256, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,787|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_62868_[256, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,804|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_44289_[256, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,805|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_6170_[256, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,810|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51688_[256, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,810|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_65399_[256, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,837|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21749_[256, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,865|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_18667_[256, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,868|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55771_[256, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,892|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72047_[256, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,898|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_372_[256, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,910|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_83086_[256, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,928|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14687_[512, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,934|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80610_[512, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,971|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_53509_[512, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,971|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_47328_[512, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,983|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19591_[512, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:33,991|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_54274_[512, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,002|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86785_[512, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,018|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99509_[512, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,064|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_45209_[512, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,071|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79967_[512, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,099|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50676_[512, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,108|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79868_[512, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,113|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80658_[512, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,118|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_4069_[512, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,129|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40031_[512, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,144|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99720_[512, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,200|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_41769_[512, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,200|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_31818_[512, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,232|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_37852_[512, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,245|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66763_[512, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,249|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67851_[512, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,253|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_58785_[512, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,272|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54520_[512, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,275|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_7442_[512, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,320|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56214_[512, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,328|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71208_[512, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,348|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_84158_[8, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,355|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_40027_[8, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,373|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_25206_[512, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,398|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79038_[8, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,409|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_54815_[8, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,409|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_31868_[512, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,410|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_19453_[512, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,414|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_25295_[8, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,422|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16116_[512, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,450|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_41988_[8, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,451|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_13097_[8, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,457|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_72654_[8, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,463|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17098_[8, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,467|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30470_[8, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,470|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_9349_[512, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,471|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46902_[8, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,482|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85214_[512, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,501|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4494_[8, 4095, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,509|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_50114_[8, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,518|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43651_[8, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,519|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22375_[8, 8191, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,527|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39206_[8, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,527|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_10898_[8, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,533|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_74529_[8, 16383, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,541|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60463_[8, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,546|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_49764_[8, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,551|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_97236_[8, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,566|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_58357_[8, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,568|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_40267_[8, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,573|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97815_[8, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,577|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74530_[8, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,591|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_5983_[8, 8191, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,603|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_78712_[8, 4095, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,603|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74580_[8, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,613|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_53119_[8, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,614|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62748_[8, 32767, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,621|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84715_[8, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,629|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45103_[8, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,631|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_87078_[8, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,655|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_9724_[8, 32767, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,657|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37333_[8, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,657|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93802_[8, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,667|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31767_[8, 16383, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,668|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_55784_[8, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,671|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_89535_[8, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,674|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_87906_[8, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,676|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_82064_[8, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,687|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1073_[8, 4095, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,690|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16630_[8, 8191, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,717|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34803_[8, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,719|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82545_[8, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,727|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73986_[8, 16383, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,727|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_2978_[8, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,732|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8544_[8, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,739|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80220_[8, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,741|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_21999_[8, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,760|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98184_[8, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,765|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56265_[8, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,775|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_91348_[8, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,778|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_85010_[8, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,780|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77418_[8, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,780|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99632_[8, 32767, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,787|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16677_[8, 4095, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,790|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41003_[8, 8191, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,811|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89522_[8, 16383, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,820|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_19614_[8, 32767, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,937|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46946_[1024, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,947|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_68533_[1024, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,959|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_35153_[1024, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,969|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_42166_[1024, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,981|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_95695_[1024, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,986|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41516_[1024, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:34,992|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_78533_[1024, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,003|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15650_[1024, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,105|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_75267_[1024, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,118|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30316_[1024, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,134|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79110_[1024, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,171|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_24908_[1024, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,180|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_60973_[1024, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,180|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14194_[1024, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,186|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_22449_[1024, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,194|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_108_[1024, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,259|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84040_[1024, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,305|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_54701_[1024, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,317|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_15505_[1024, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,374|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_6671_[1024, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,375|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_77467_[1024, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,378|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26519_[1024, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,387|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_91750_[1024, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,389|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63754_[1024, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,431|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_55170_[1024, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,458|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36895_[1024, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,486|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42365_[1024, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,555|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30327_[1024, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,676|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66390_[2048, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,685|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23247_[2048, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,695|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85594_[2048, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,701|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_54770_[2048, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,730|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_59766_[2048, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,759|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_56108_[2048, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,771|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8296_[2048, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,851|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_10987_[2048, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:35,952|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40352_[2048, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,013|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33257_[2048, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,013|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_93420_[2048, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,019|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_19716_[2048, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,032|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73185_[2048, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,065|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_27070_[2048, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,071|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_59039_[2048, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,160|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42958_[2048, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,246|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_73181_[2048, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,256|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_45808_[16, 1, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,262|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_90369_[16, 3, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,267|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20979_[16, 7, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,272|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_91051_[16, 15, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,291|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_63766_[16, 31, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,309|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_78987_[16, 63, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,324|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62537_[2048, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,330|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_72424_[16, 127, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,335|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65572_[16, 255, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,349|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93793_[16, 511, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,362|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_25054_[2048, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,368|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15592_[16, 1023, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,369|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_55732_[2048, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,385|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_18364_[2048, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,395|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_99037_[16, 2047, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,404|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34147_[16, 8191, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,413|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_5260_[16, 4095, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,416|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_39830_[16, 1, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,427|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_85964_[16, 3, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,435|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_78516_[2048, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,440|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_74173_[16, 15, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,446|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26525_[16, 7, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,448|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_65000_[16, 16383, 64, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,458|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_54482_[16, 63, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,464|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_20722_[16, 127, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,465|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91246_[2048, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,475|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54297_[16, 511, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,476|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_50087_[16, 255, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,482|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_19696_[16, 31, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,500|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14139_[16, 4095, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,512|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_95002_[16, 2047, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,521|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3746_[16, 3, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,542|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71195_[16, 1, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,542|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26785_[16, 1023, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,548|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_74897_[16, 8191, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,548|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61831_[16, 7, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,549|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_26217_[16, 16383, 64, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,557|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45141_[16, 31, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,558|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14160_[16, 15, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,590|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16052_[16, 2047, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,592|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_16150_[16, 127, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,594|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_1504_[16, 511, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,595|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77902_[16, 1023, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,597|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53573_[16, 255, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,601|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_42282_[16, 63, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,618|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_80974_[2048, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,620|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_288_[16, 4095, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,627|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_52010_[16, 3, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,638|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_59041_[16, 7, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,651|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_27955_[16, 1, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,657|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_18720_[16, 15, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,664|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_18756_[16, 31, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,667|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78362_[16, 8191, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,667|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_81265_[16, 63, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,669|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_82283_[16, 127, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,682|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_98547_[16, 255, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,692|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60947_[16, 511, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,703|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_69418_[16, 16383, 64, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,707|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49240_[16, 2047, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,711|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_13427_[16, 4095, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,711|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_6729_[16, 1023, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,718|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_86256_[16, 8191, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:36,778|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95929_[16, 16383, 64, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,900|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15289_[32, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,907|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15988_[32, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,913|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27535_[32, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,920|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34060_[32, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,926|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_21289_[32, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,933|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_10589_[32, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,939|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3395_[32, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,946|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38157_[32, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,953|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_79694_[32, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,962|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63951_[32, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,973|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3372_[32, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:39:59,987|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85352_[32, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,008|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_637_[32, 8191, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,013|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_15221_[32, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,029|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_25310_[32, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,035|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63416_[32, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,048|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22319_[32, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,049|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_92402_[32, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,050|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_98249_[32, 16383, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,055|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_16915_[32, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,067|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_8715_[32, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,088|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_89120_[32, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,093|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_5743_[32, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,091|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33248_[32, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,101|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_51491_[32, 8191, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,100|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_1941_[32, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,108|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80934_[32, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,108|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_9160_[32, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,123|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_59048_[32, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,139|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58452_[32, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,134|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_69953_[32, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,152|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57712_[32, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,152|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3636_[32, 16383, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,154|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15071_[32, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,154|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76252_[32, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,170|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_18010_[32, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,185|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_47843_[32, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,188|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_25707_[32, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,202|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55664_[32, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,211|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47159_[32, 8191, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,216|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_65202_[32, 16383, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,225|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_29004_[32, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,239|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59890_[32, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,275|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63040_[32, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,293|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_44361_[32, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,303|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_68313_[32, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,310|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99937_[32, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,309|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26283_[32, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,317|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_65117_[32, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,328|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_1936_[32, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,329|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71320_[32, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,335|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81599_[1, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,338|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_68678_[1, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,341|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_98153_[1, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,343|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_6088_[1, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,343|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_48715_[1, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,346|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_16033_[1, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,349|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_79163_[1, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,337|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_2946_[1, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,353|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_32110_[1, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,353|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_36694_[1, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,356|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79487_[1, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,363|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33964_[1, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,365|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_61884_[1, 8191, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,369|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_27136_[32, 8191, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,365|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_67234_[32, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,374|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65506_[32, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,375|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_94592_[1, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,377|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_31644_[1, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,378|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62950_[1, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,378|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_81977_[32, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,381|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_15214_[1, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,381|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_37272_[1, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,382|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_80616_[1, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,384|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_13069_[1, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,384|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66932_[1, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,385|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45319_[1, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,386|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96272_[1, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,388|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62803_[1, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,390|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66166_[1, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,391|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93879_[1, 16383, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,391|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_78686_[32, 16383, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,394|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49992_[1, 8191, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,395|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_61901_[1, 32767, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,395|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7369_[1, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,398|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_28634_[1, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,398|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96688_[1, 16383, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,398|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65189_[1, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,400|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_28636_[1, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,400|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_87176_[1, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,400|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79072_[1, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,401|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_23943_[1, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,402|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_66615_[1, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,404|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_94300_[1, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,404|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76654_[1, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,404|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_41533_[1, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,407|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_39590_[1, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,411|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_51145_[1, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,411|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_68290_[1, 8191, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,413|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_45605_[1, 32767, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,415|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_16441_[1, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,415|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_33726_[1, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,417|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98052_[1, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,418|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28155_[1, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,419|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42071_[1, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,420|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83641_[1, 65535, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,420|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74007_[1, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,420|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4665_[1, 16383, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,421|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_25356_[1, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,423|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_92056_[1, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,424|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40291_[1, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,425|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16721_[1, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,425|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67121_[1, 32767, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,428|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_55173_[1, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,430|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36388_[2, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,431|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56454_[2, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,433|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_96141_[1, 8191, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,433|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_9311_[2, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,434|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_23927_[2, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,436|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_9146_[2, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,437|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14163_[2, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,438|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21326_[2, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,439|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_3152_[2, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,439|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_1626_[1, 16383, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,439|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_1199_[2, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,439|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_68298_[1, 65535, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,441|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12574_[2, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,443|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_93364_[2, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,444|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_21075_[2, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,446|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38275_[1, 32767, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,448|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_95047_[2, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,448|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_71439_[2, 8191, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,450|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_39441_[1, 65535, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,451|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_35237_[2, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,451|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_31748_[2, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,452|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34057_[2, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,453|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_30992_[2, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,453|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_8422_[2, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,455|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_74660_[2, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,455|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_97382_[2, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,455|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_30485_[2, 16383, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,456|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_37802_[2, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,457|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_1170_[2, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,459|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_77666_[2, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,461|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_91427_[2, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,464|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_92308_[2, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,466|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_968_[2, 8191, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,466|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57268_[2, 32767, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,467|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_56312_[2, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,468|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_73861_[2, 16383, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,470|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73942_[2, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,471|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89293_[2, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,471|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37404_[2, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,473|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78289_[2, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,473|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_48081_[2, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,473|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_72885_[2, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,474|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_61263_[1, 65535, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,474|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_71883_[2, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,476|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_25732_[2, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,477|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_71521_[2, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,479|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_88492_[2, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,480|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_29573_[2, 32767, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,483|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50394_[2, 8191, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,483|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39953_[2, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,485|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54526_[2, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,486|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_26577_[2, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,487|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13955_[2, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,488|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_86812_[2, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,489|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_99991_[2, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,490|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34616_[2, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,491|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_27262_[2, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,491|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_13018_[2, 16383, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,492|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57482_[2, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,493|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_14609_[2, 65535, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,494|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_12310_[2, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,495|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99083_[2, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,498|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_20678_[2, 32767, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,500|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87322_[2, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,500|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39772_[2, 8191, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,506|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_27030_[2, 16383, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,506|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_98041_[2, 65535, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,514|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_5461_[64, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,522|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_70455_[2, 32767, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,531|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_6661_[2, 65535, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,531|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19622_[64, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,535|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23801_[64, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,535|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_18050_[64, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,538|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93899_[64, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,544|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_77506_[64, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,549|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_48140_[64, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,557|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99675_[64, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,568|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24903_[2, 65535, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,571|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59370_[64, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,581|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_1684_[64, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,586|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_36053_[64, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,590|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_4343_[64, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,593|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_61505_[64, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,612|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_94719_[64, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,614|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76633_[64, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,617|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_65409_[64, 8191, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,621|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39343_[64, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,623|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57849_[64, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,637|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_89104_[64, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,641|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40941_[64, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,644|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_82885_[64, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,651|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9613_[64, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,672|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_21894_[64, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,670|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90123_[64, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,693|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_65861_[64, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,717|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_87470_[64, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,718|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37237_[64, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,731|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7827_[64, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,739|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93110_[64, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,753|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51851_[64, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,755|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_98169_[64, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,769|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_38880_[64, 8191, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,769|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_82548_[64, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,794|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_25031_[64, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,816|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_17255_[64, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,817|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_6255_[64, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,834|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66771_[64, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,835|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_8073_[64, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,846|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76477_[64, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,882|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_98313_[64, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,904|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_42485_[64, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,908|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_78181_[64, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,921|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_43258_[64, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,922|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_69790_[64, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,937|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_2114_[64, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,943|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_27092_[64, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,951|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66306_[4, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,958|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_41424_[4, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,959|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_50831_[64, 8191, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,960|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49522_[4, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,962|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45070_[4, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,963|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_74196_[4, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,965|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_90829_[4, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,966|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_5929_[4, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,968|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_28928_[4, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,969|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_9802_[64, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,972|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_43697_[4, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,979|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_75717_[4, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,981|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_79926_[64, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,988|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_95382_[4, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,988|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_7657_[4, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,992|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_71216_[64, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:00,999|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40075_[4, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,000|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_11310_[64, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,004|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_77866_[4, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,006|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_85771_[4, 8191, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,007|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_54456_[4, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,010|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_16751_[4, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,011|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33042_[4, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,012|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_28075_[4, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,012|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_5153_[4, 16383, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,013|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_12326_[4, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,013|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60097_[4, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,015|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_75628_[64, 8191, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,016|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_52795_[4, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,016|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_61633_[4, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,018|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68390_[4, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,018|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24661_[4, 32767, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,020|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84206_[4, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,024|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_22240_[4, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,024|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66466_[4, 8191, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,024|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32231_[4, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,025|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_55953_[4, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,027|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28248_[4, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,027|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_28572_[4, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,028|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_38067_[4, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,029|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11478_[4, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,030|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_47761_[4, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,031|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87762_[4, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,032|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_37414_[4, 16383, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,033|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_11526_[4, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,034|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97554_[4, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,038|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_83138_[4, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,040|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_30343_[4, 8191, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,040|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_95060_[4, 32767, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,042|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_60955_[4, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,045|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_67047_[4, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,046|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28606_[4, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,046|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_65431_[4, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,048|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_5962_[4, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,049|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91788_[4, 16383, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,049|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8321_[4, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,050|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42402_[4, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,050|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15764_[4, 65535, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,052|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_61745_[4, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,052|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73486_[4, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,054|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_62959_[4, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,056|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_90533_[4, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,058|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_3543_[4, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,060|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_42692_[4, 32767, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,061|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17327_[4, 8191, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,072|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3554_[4, 16383, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,075|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_73463_[128, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,081|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70217_[4, 65535, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,081|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_32677_[4, 32767, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,084|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24489_[128, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,095|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93133_[128, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,095|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_80923_[128, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,104|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_21384_[4, 65535, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,105|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_76154_[128, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,114|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_424_[128, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,120|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34466_[128, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,127|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_35184_[4, 65535, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,131|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11577_[128, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,142|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_76010_[128, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,144|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85938_[128, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,166|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_96797_[128, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,199|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_28617_[128, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,201|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84658_[128, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,224|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_34704_[128, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,227|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_89581_[128, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,232|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60699_[128, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,245|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99225_[128, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,259|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_7233_[128, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,261|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_34119_[128, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,272|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_19905_[128, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,279|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57862_[128, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,331|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_80993_[128, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,334|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67540_[128, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,342|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_8505_[128, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,356|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48061_[128, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,359|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_91485_[128, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,376|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_5736_[128, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,408|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26186_[128, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,409|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_59987_[128, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,426|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57093_[128, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,445|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57948_[128, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,457|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_21541_[128, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,461|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36835_[128, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,465|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_94197_[128, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,476|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_81661_[128, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,478|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_67046_[128, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,511|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37125_[128, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,542|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_96310_[128, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,554|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93194_[128, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,558|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_40970_[128, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,564|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_67089_[128, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,565|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7446_[128, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,577|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_62402_[128, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,584|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81005_[128, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,619|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39433_[128, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,622|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_6068_[128, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,650|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_88364_[128, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,685|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_68382_[256, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,690|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_71675_[256, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,695|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16731_[256, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,718|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80372_[256, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,719|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_66693_[256, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,722|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_43918_[128, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,725|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46748_[256, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,733|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_18528_[256, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,809|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_62306_[256, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,810|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_54590_[256, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,821|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_51606_[256, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,825|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_70550_[256, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,833|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17005_[256, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,833|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60766_[256, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,845|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79209_[256, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,846|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_17603_[256, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,887|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_94548_[256, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,898|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_51899_[256, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,901|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_99466_[256, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,941|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_22103_[256, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,946|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_3071_[256, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,950|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14444_[256, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,951|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_46408_[256, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:01,976|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43200_[256, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,005|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48547_[256, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,011|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_41097_[256, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,015|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_35234_[256, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,017|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79664_[256, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,037|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_38983_[256, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,056|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84118_[256, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,063|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_38963_[256, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,084|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_34131_[256, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,093|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22308_[256, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,119|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_6942_[256, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,123|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_84041_[256, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,136|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26970_[256, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,145|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_56753_[256, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,173|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_15050_[256, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,176|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47128_[256, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,189|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55742_[256, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,195|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_98084_[512, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,197|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_20799_[256, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,231|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_29380_[512, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,242|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_19172_[512, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,258|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57409_[512, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,278|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_33306_[512, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,278|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58076_[512, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,302|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_49503_[512, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,308|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_44219_[512, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,323|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_10865_[512, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,361|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_42372_[512, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,365|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_52189_[512, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,380|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_80947_[512, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,397|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_21052_[512, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,404|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64232_[512, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,413|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_48776_[512, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,425|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_65601_[512, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,446|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60444_[512, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,482|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_19349_[512, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,487|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_32124_[512, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,500|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89315_[512, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,505|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_968_[512, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,531|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37227_[512, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,542|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93151_[512, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,548|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14250_[512, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,557|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66795_[512, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,599|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_6886_[512, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,611|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98445_[512, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,649|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_12336_[512, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,656|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_22451_[512, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,669|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30931_[8, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,671|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_60667_[512, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,671|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_45106_[512, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,675|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_50107_[512, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,677|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_64386_[512, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,683|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_75549_[8, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,686|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_53866_[8, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,686|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_40958_[8, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,687|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68305_[8, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,687|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41132_[8, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,688|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_92748_[8, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,691|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_69879_[8, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,691|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_35856_[8, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,693|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_72464_[8, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,695|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_79405_[8, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,699|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81591_[8, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,704|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8890_[8, 8191, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,704|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_54983_[8, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,708|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_57976_[8, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,711|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_71307_[8, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,712|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_2293_[8, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,714|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_44828_[8, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,714|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_63741_[512, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,715|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_83387_[8, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,717|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9312_[8, 16383, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,717|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_4106_[512, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,720|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76840_[8, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,720|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_75968_[8, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,725|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_68599_[8, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,725|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_34841_[8, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,726|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75035_[8, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,727|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_43578_[8, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,732|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_78593_[8, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,732|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_48374_[8, 32767, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,734|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_51471_[8, 8191, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,735|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_94237_[8, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,739|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_27104_[8, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,739|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_19008_[8, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,740|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_21867_[8, 16383, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,741|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97138_[8, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,742|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_9165_[8, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,742|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58506_[8, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,744|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_60300_[8, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,747|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_31756_[8, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,747|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_95311_[8, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,748|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_3415_[8, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,751|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13119_[8, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,758|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_66599_[8, 8191, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,763|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_62599_[8, 16383, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,763|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95013_[8, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,764|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48306_[8, 65535, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,765|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93655_[8, 32767, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,767|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59150_[8, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,770|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_63696_[8, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,770|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_64396_[8, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,773|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32517_[8, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,773|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52906_[8, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,779|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_77443_[8, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,779|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43172_[8, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,780|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2568_[8, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,780|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66433_[8, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,781|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_58152_[8, 32767, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,785|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_41826_[8, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,787|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_15108_[8, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,787|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_64636_[8, 65535, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,788|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77200_[512, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,795|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_55915_[8, 8191, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,806|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63594_[8, 16383, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,812|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_5658_[8, 65535, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,817|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_13063_[8, 32767, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,849|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_24329_[8, 65535, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,898|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90978_[1024, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,908|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52508_[1024, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,937|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_69288_[1024, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,945|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37814_[1024, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,947|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38143_[1024, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,952|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_88549_[1024, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,974|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76354_[1024, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:02,990|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40177_[1024, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,080|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_45734_[1024, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,102|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_92864_[1024, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,103|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_96184_[1024, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,115|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_8772_[1024, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,135|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61545_[1024, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,135|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_68427_[1024, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,167|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14363_[1024, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,173|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_75459_[1024, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,244|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70591_[1024, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,276|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_20316_[1024, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,302|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_75322_[1024, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,308|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_63090_[1024, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,312|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_66323_[1024, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,325|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_83110_[1024, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,337|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60547_[1024, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,368|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57689_[1024, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,423|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_14659_[1024, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,471|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89704_[1024, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,493|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_910_[1024, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,498|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_6890_[1024, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,508|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_44540_[1024, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,510|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77161_[1024, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,522|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87954_[1024, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,602|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_65832_[1024, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,678|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_25064_[2048, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,713|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_19514_[2048, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,743|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_38677_[2048, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,750|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_96883_[2048, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,757|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57284_[2048, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,774|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_12443_[2048, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,814|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_47256_[2048, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,853|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_68787_[2048, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,913|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42635_[2048, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,953|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_42552_[2048, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,986|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_61217_[2048, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,992|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9922_[2048, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:03,999|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_67266_[2048, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,039|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_41672_[2048, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,070|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17002_[2048, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,095|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_23463_[2048, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,144|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58174_[2048, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,193|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_94107_[2048, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,235|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_46625_[2048, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,258|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_11390_[2048, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,280|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_988_[2048, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,305|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_61771_[16, 1, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,310|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19611_[16, 3, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,315|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23006_[16, 7, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,326|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56412_[16, 15, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,332|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_74567_[2048, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,338|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_4072_[16, 31, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,351|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_90480_[2048, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,356|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_20607_[16, 63, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,358|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_70635_[16, 127, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,385|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_38458_[16, 255, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,388|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_31325_[16, 511, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,389|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_1235_[2048, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,394|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_321_[16, 1023, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,424|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_61509_[2048, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,425|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_84796_[16, 2047, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,429|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_47347_[16, 4095, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,432|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42591_[16, 8191, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,455|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_46664_[16, 16383, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,461|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_914_[16, 3, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,462|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_9320_[16, 7, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,463|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30609_[16, 1, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,485|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_34049_[16, 15, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,498|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77944_[16, 63, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,498|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_10615_[16, 127, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,498|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_7641_[16, 31, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,503|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56214_[16, 255, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,519|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73304_[2048, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,532|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_94596_[16, 32767, 32, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,534|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_12862_[2048, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,538|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_80256_[16, 1023, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,541|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50047_[16, 511, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,554|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_49408_[16, 2047, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,561|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63353_[16, 8191, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,564|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_55799_[16, 4095, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,569|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_4254_[16, 1, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,584|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85390_[16, 3, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,597|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24934_[16, 7, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,597|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28981_[16, 15, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,600|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_51442_[16, 31, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,610|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77508_[16, 16383, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,618|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_26389_[16, 63, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,627|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74582_[16, 127, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,629|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63721_[16, 255, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,637|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_69801_[16, 511, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,645|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_27996_[16, 2047, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,656|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50673_[16, 1023, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,657|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_42736_[16, 32767, 32, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,669|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_59356_[16, 4095, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,672|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57476_[16, 1, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,674|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_9212_[16, 8191, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,685|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56566_[16, 3, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,688|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84938_[16, 7, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,692|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_612_[16, 16383, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,709|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_85775_[2048, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,719|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8058_[16, 15, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,720|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_49786_[16, 127, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,721|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_95994_[16, 63, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,727|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_81667_[16, 255, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,727|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_7295_[16, 31, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,736|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_88648_[16, 511, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,761|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_21520_[16, 1023, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,764|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31532_[16, 4095, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,767|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14021_[16, 2047, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,779|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_86305_[16, 8191, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,786|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_18493_[16, 32767, 32, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,798|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_49209_[16, 16383, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:04,850|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11032_[16, 32767, 32, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,355|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_25302_[32, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,366|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_6594_[32, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,378|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_52753_[32, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,389|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_43474_[32, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,391|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_50294_[32, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,407|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_39071_[32, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,406|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73359_[32, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,414|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_51738_[32, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,418|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38514_[32, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,445|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_67297_[32, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,443|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_59084_[32, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,453|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84961_[32, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,454|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_15939_[32, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,467|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_67191_[32, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,473|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26926_[32, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,485|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_71877_[32, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,493|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_19021_[32, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,501|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_29639_[32, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,502|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93239_[32, 16383, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,514|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_28453_[32, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,521|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57869_[32, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,530|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41796_[32, 32767, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,526|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_42288_[32, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,533|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_68756_[32, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,545|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_50092_[32, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,552|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_88583_[32, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,555|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3421_[32, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,574|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41959_[32, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,579|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_39882_[32, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,584|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62987_[32, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,595|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61691_[32, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,595|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91757_[32, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,606|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_57545_[32, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,607|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33362_[32, 16383, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,628|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_6284_[32, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,643|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_47173_[32, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,645|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_55695_[32, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,650|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_55977_[32, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,651|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_35508_[32, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,656|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49039_[32, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,658|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61634_[32, 32767, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,690|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_48751_[32, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,701|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73020_[32, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,706|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17349_[32, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,717|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_43138_[32, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,714|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26277_[32, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,759|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_18630_[32, 16383, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,767|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_79015_[32, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,768|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_70979_[32, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,778|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_52629_[32, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,781|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66323_[32, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,793|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_40545_[32, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,809|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_19516_[32, 32767, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,837|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_7174_[32, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,842|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_58223_[32, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,843|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62863_[1, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,844|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_34333_[32, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,847|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96256_[1, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,850|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17537_[32, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,853|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_54228_[1, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,856|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32269_[1, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,856|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99706_[1, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,856|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56232_[32, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,860|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51995_[1, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,860|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_54580_[1, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,859|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_1038_[1, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,862|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98860_[1, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,865|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_78864_[1, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,865|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_36850_[1, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,867|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14530_[1, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,870|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_32406_[1, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,872|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80774_[32, 16383, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,875|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_38381_[1, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,875|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_88827_[1, 16383, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,877|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12189_[1, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,880|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_25070_[1, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,880|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81627_[1, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,881|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81315_[1, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,883|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38541_[1, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,883|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97906_[1, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,885|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59692_[1, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,887|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52485_[1, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,887|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99125_[1, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,889|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_62211_[1, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,889|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_39682_[1, 32767, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,893|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99548_[1, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,894|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_10883_[1, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,905|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72404_[1, 16383, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,910|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_1722_[1, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,912|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_653_[1, 65535, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,913|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19820_[1, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,913|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37823_[1, 32767, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,914|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_39381_[1, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,916|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_41220_[1, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,917|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_52463_[1, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,917|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26687_[1, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,919|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_52176_[1, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,919|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26591_[1, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,919|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57237_[1, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,922|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_90123_[1, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,923|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70111_[1, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,924|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_18692_[1, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,928|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8552_[1, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,935|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_10235_[32, 32767, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,936|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_94114_[1, 16383, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,941|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49343_[1, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,943|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54087_[1, 32767, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,944|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_291_[1, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,944|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_23370_[1, 65535, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,946|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2658_[1, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,948|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_93912_[1, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,948|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36091_[1, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,949|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81888_[1, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,949|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_7943_[1, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,950|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_38158_[1, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,952|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_22341_[1, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,952|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_10438_[1, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,953|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_78116_[1, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,953|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_37009_[1, 131071, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,955|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60677_[1, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,962|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33583_[1, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,964|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53830_[1, 16383, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,967|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70578_[2, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,969|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73635_[2, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,969|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_19705_[1, 65535, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,970|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_709_[2, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,972|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_90880_[2, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,974|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_22997_[2, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,974|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_49492_[2, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,974|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_72320_[2, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,977|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37953_[2, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,977|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_73456_[2, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,978|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71167_[2, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,979|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_45712_[1, 32767, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,982|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54961_[2, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,983|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_6393_[2, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,986|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36650_[2, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,988|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_71647_[1, 131071, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,993|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_5150_[2, 16383, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,994|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62222_[2, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,997|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_66590_[2, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,997|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_3750_[1, 65535, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,998|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_91386_[2, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:29,999|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_11963_[2, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,001|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_66559_[2, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,002|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_27942_[2, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,003|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_25219_[2, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,004|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_8844_[2, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,005|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_63122_[2, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,006|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_10604_[2, 32767, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,006|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_12547_[2, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,008|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_18070_[2, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,011|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_69189_[2, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,015|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_53508_[2, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,017|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_10695_[1, 131071, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,021|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1728_[2, 16383, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,022|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_20162_[2, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,025|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45135_[2, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,026|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_77261_[2, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,027|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_85336_[2, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,029|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_40501_[2, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,029|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72257_[2, 65535, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,030|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_97625_[2, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,031|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_65060_[2, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,032|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_29494_[2, 32767, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,033|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_88964_[2, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,034|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_50191_[2, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,035|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_14481_[2, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,037|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_23166_[2, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,041|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_68100_[2, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,042|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_12345_[1, 131071, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,042|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_94343_[2, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,047|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_7640_[2, 16383, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,048|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_75590_[2, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,051|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_94493_[2, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,052|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_45188_[2, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,054|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_91651_[2, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,054|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11263_[2, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,055|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45416_[2, 65535, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,057|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58831_[2, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,057|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_77064_[2, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,059|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34630_[2, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,060|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_29071_[2, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,061|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11340_[2, 32767, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,062|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_2506_[2, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,064|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_24813_[2, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,065|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68197_[2, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,070|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_72187_[2, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,076|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_20011_[2, 16383, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,085|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_80687_[2, 32767, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,087|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_58688_[64, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,091|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_49363_[2, 131071, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,092|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63147_[2, 65535, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,101|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_47146_[64, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,108|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_64243_[2, 131071, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,113|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37444_[64, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,118|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79303_[2, 65535, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,127|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_96370_[64, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,127|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_70750_[64, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,127|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_72233_[64, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,130|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_63922_[64, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,147|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_60163_[64, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,150|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37459_[64, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,164|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_8196_[64, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,168|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27416_[64, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,169|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60470_[64, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,171|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_40187_[2, 131071, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,172|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_49322_[2, 131071, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,172|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_94187_[64, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,178|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14506_[64, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,199|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40691_[64, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,208|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_33526_[64, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,211|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_49600_[64, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,214|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80638_[64, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,216|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_36028_[64, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,217|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22900_[64, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,223|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_35386_[64, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,246|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_12807_[64, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,249|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_66313_[64, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,250|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64610_[64, 16383, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,253|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84552_[64, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,287|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_51428_[64, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,301|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14407_[64, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,307|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_95163_[64, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,310|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_44286_[64, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,313|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_43307_[64, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,319|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_97244_[64, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,347|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_47383_[64, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,359|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97235_[64, 16383, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,371|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63000_[64, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,386|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52012_[64, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,390|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_92724_[64, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,391|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_34764_[64, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,404|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_79599_[64, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,412|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99130_[64, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,430|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_17469_[64, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,453|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31898_[64, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,467|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_80970_[64, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,481|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_63246_[64, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,481|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50004_[64, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,519|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_23852_[64, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,527|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66160_[64, 16383, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,535|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_77816_[64, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,542|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95436_[64, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,549|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_61192_[64, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,550|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17306_[64, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,554|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_21449_[64, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,566|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61399_[64, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,568|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_24670_[4, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,571|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_66099_[4, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,571|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_95219_[4, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,572|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_92865_[4, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,572|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_17213_[4, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,574|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79094_[4, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,575|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8499_[4, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,578|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_35704_[4, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,579|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_82005_[4, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,580|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27207_[64, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,588|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26111_[4, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,590|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_62166_[4, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,596|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_38405_[4, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,597|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45288_[4, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,597|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_1497_[64, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,603|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_31817_[4, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,604|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_41235_[4, 16383, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,606|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_89523_[4, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,606|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4558_[4, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,609|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_23838_[4, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,611|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32124_[4, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,611|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_57531_[4, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,615|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86603_[4, 32767, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,615|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85682_[4, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,619|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_83070_[4, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,620|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_830_[4, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,622|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_19766_[4, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,626|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_55668_[4, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,628|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_89121_[4, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,631|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_840_[4, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,632|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_47972_[64, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,634|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46702_[4, 16383, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,639|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_98581_[4, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,642|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_56835_[4, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,644|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_44822_[4, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,645|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26369_[4, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,647|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77556_[4, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,648|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_37114_[4, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,648|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_15599_[64, 16383, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,650|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17102_[4, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,652|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_70679_[4, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,653|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_22782_[4, 65535, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,653|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26936_[4, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,658|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_26613_[4, 32767, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,658|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52776_[4, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,659|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_65291_[4, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,664|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84712_[4, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,670|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47293_[4, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,676|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_98918_[4, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,681|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_44183_[4, 16383, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,681|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_28185_[4, 65535, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,681|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67597_[4, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,682|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_53615_[4, 32767, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,686|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_62916_[4, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,687|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_45838_[4, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,688|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_21456_[4, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,689|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_90008_[4, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,690|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68130_[4, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,690|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_54343_[4, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,691|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24446_[4, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,695|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_84834_[4, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,696|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22525_[4, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,698|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83620_[4, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,699|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_49040_[4, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,710|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17829_[4, 16383, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,713|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_89078_[4, 131071, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,715|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_11416_[4, 65535, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,725|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_71370_[128, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,727|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_23760_[4, 32767, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,737|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37960_[128, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,737|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_18579_[128, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,739|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40060_[4, 131071, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,753|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99027_[4, 65535, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,755|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24798_[128, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,756|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33587_[128, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,765|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4868_[128, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,767|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58619_[128, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,773|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_92992_[4, 131071, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,774|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32568_[128, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,781|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_68645_[128, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,797|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_89135_[128, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,806|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_35619_[4, 131071, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,826|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_36559_[128, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,846|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_35178_[128, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,847|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4179_[128, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,856|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_92066_[128, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,862|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56100_[128, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,876|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_55143_[128, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,881|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_90347_[128, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,887|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_52716_[128, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,921|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_17008_[128, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,928|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_67846_[128, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,942|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_19956_[128, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,948|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_47816_[128, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,959|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_49830_[128, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,967|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62665_[128, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:30,979|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_43051_[128, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,001|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_46056_[128, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,024|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58838_[128, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,045|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_98242_[128, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,045|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_30199_[128, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,047|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_9422_[128, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,056|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86148_[128, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,057|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65136_[128, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,084|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_57943_[128, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,096|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_13425_[128, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,124|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_88785_[128, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,124|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17687_[128, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,127|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_24693_[128, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,160|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_40347_[128, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,175|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_5376_[128, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,180|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_15678_[128, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,192|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38112_[128, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,198|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_47534_[128, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,219|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_47955_[128, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,221|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_51802_[128, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,241|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1815_[128, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,258|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_71271_[128, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,260|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_36952_[128, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,267|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4586_[128, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,295|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_20119_[128, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,297|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77815_[128, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,300|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_49546_[256, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,324|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87248_[256, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,345|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_72728_[128, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,363|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_5549_[256, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,385|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42409_[256, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,393|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83273_[128, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,397|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38087_[256, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,397|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8293_[256, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,403|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46890_[256, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,408|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42973_[256, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,433|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3910_[256, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,476|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_82003_[256, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,488|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_49038_[256, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,494|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76992_[256, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,515|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_47032_[256, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,520|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_16061_[256, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,521|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22566_[256, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,531|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_60319_[256, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,535|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_21733_[256, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,542|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66512_[256, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,552|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14094_[256, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,597|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_15982_[256, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,618|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66400_[256, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,628|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_8192_[256, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,633|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_43838_[256, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,638|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_20356_[256, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,644|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_30865_[256, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,661|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97018_[256, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,663|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_95956_[256, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,680|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95992_[256, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,710|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_9265_[256, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,712|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45391_[256, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,723|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_96685_[256, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,749|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_70548_[256, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,762|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73234_[256, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,773|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_46965_[256, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,783|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_38196_[256, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,786|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_76530_[256, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,791|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_48579_[256, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,812|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56259_[256, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,838|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_15725_[256, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,855|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_2898_[256, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,860|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_91325_[256, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,868|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_70523_[256, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,886|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_42714_[512, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,889|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84534_[256, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,901|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_18961_[512, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,911|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_55244_[256, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,948|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_18075_[512, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,960|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34197_[512, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,960|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16759_[512, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,972|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28242_[512, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,977|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_99290_[512, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,983|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_75634_[512, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:31,993|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_80206_[512, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,047|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93691_[512, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,062|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31576_[512, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,075|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75525_[512, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,083|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_24853_[512, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,095|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_27138_[512, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,098|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33574_[512, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,098|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_42261_[512, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,106|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_86964_[512, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,153|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_36340_[512, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,158|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_16819_[512, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,171|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_38437_[512, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,184|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_66462_[512, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,201|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87219_[512, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,204|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_3850_[512, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,213|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_35956_[512, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,231|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_43517_[512, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,244|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_66571_[512, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,259|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49285_[512, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,268|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77172_[512, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,298|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_13543_[512, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,317|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_13227_[512, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,323|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79195_[512, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,336|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_27455_[512, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,352|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_56644_[512, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,359|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30388_[512, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,359|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52845_[8, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,363|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_16222_[8, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,366|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_74691_[8, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,369|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_18034_[8, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,372|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_92467_[8, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,372|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24733_[8, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,375|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_2971_[8, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,375|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77017_[512, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,376|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42521_[8, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,378|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26083_[8, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,380|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_75791_[8, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,388|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_23117_[8, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,388|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_15394_[8, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,390|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75828_[512, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,395|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_34750_[8, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,414|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_60049_[512, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,414|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_31169_[8, 16383, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,421|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54801_[8, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,423|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97034_[8, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,425|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79355_[8, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,426|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60782_[512, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,427|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87233_[8, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,429|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_66949_[8, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,430|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_6657_[8, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,432|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58844_[8, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,434|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_33801_[8, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,436|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_72027_[8, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,436|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70938_[8, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,438|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_97329_[8, 32767, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,440|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_85308_[8, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,445|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57778_[512, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,448|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30181_[8, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,450|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_44756_[8, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,457|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_66212_[8, 65535, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,458|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_8683_[8, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,458|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97911_[8, 16383, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,461|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89788_[8, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,462|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_26978_[512, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,465|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49560_[8, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,466|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_57396_[8, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,466|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_94728_[8, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,469|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45218_[8, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,469|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_21716_[8, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,470|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_67744_[8, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,473|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_10927_[8, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,474|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_71864_[8, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,475|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_72921_[8, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,477|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34551_[8, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,483|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_54851_[8, 32767, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,486|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56747_[8, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,491|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_34270_[8, 16383, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,492|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_83539_[8, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,495|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76568_[8, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,498|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89020_[8, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,499|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_96535_[8, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,501|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_84240_[8, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,502|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87392_[8, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,505|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_52513_[8, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,506|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_1547_[8, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,508|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_79963_[8, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,510|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_29196_[8, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,510|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40806_[8, 32767, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,514|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_92874_[8, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,514|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73103_[8, 65535, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,517|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24742_[8, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,527|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_7771_[8, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,532|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42119_[8, 16383, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,536|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_49271_[8, 65535, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,547|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8454_[8, 131071, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,547|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15936_[8, 32767, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,576|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87995_[8, 131071, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,581|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_35269_[8, 65535, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,612|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27166_[8, 131071, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,630|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_15491_[1024, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,641|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_93033_[1024, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,648|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_65233_[1024, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,651|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_90284_[8, 131071, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,663|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82570_[1024, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,674|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99859_[1024, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,682|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_12980_[1024, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,725|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_79892_[1024, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,751|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10300_[1024, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,780|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_41427_[1024, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,784|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42370_[1024, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,790|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36641_[1024, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,801|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56032_[1024, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,808|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_56831_[1024, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,828|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_22743_[1024, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,848|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_36988_[1024, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,872|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_86419_[1024, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,915|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_44000_[1024, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,938|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_61299_[1024, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,949|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70073_[1024, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,956|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_16789_[1024, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,963|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_42282_[1024, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,982|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_77090_[1024, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:32,997|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_82752_[1024, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,008|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_94060_[1024, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,072|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53851_[1024, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,102|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_55974_[1024, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,119|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31247_[1024, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,131|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99296_[1024, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,131|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_59518_[1024, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,152|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_67204_[1024, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,174|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_99299_[1024, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,178|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66226_[1024, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,236|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_82620_[1024, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,264|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_94003_[1024, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,306|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_66528_[1024, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,356|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_67920_[2048, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,362|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34525_[2048, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,372|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_65161_[1024, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,383|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57606_[2048, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,429|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9349_[2048, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,448|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_21135_[2048, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,468|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64837_[2048, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,591|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34233_[2048, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,607|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64930_[2048, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,612|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_37284_[2048, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,624|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_65589_[2048, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,689|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_94814_[2048, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,699|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81940_[2048, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,703|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64651_[2048, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,709|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_74534_[2048, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,872|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41093_[2048, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,886|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_5957_[2048, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,891|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26628_[2048, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,942|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68544_[2048, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,949|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_32077_[2048, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,959|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_13738_[2048, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,973|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_95407_[2048, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:33,993|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50747_[2048, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,171|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62318_[2048, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,182|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_40434_[2048, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,208|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87363_[2048, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,217|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74053_[16, 1, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,221|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_44047_[16, 3, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,225|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57433_[16, 7, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,228|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13088_[2048, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,229|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68516_[16, 15, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,233|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99307_[16, 31, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,233|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93889_[2048, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,237|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59889_[16, 63, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,240|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_38615_[16, 127, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,241|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_87470_[16, 255, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,244|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_54379_[16, 511, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,245|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93009_[16, 1023, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,247|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76710_[16, 2047, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,252|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_67720_[16, 4095, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,259|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_94189_[16, 8191, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,278|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41870_[16, 16383, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,285|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75379_[16, 1, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,291|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_22703_[2048, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,291|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49437_[2048, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,293|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36574_[16, 3, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,297|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78146_[16, 7, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,299|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_83650_[16, 15, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,301|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_77130_[16, 63, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,301|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_86168_[16, 31, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,303|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_40379_[16, 127, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,304|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32788_[16, 32767, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,305|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_31715_[16, 255, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,306|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9379_[16, 511, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,309|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45958_[16, 1023, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,311|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_25828_[16, 2047, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,313|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_77665_[2048, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,314|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_20017_[16, 4095, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,323|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_13614_[16, 8191, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,328|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11602_[16, 1, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,330|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17694_[16, 3, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,333|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_11033_[16, 7, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,333|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50381_[16, 15, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,337|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_3837_[16, 31, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,337|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_4587_[16, 63, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,337|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64639_[16, 16383, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,342|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73391_[16, 127, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,342|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69277_[16, 255, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,343|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_27559_[16, 65535, 16, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,345|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_94668_[16, 511, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,347|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_4438_[16, 1023, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,348|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_25948_[16, 2047, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,352|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_39631_[16, 32767, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,353|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_57275_[16, 4095, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,362|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_359_[16, 1, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,363|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_70401_[16, 8191, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,366|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_93737_[16, 3, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,369|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94847_[16, 16383, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,370|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_97605_[16, 15, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,371|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68019_[16, 7, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,375|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_24127_[16, 31, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,376|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_57901_[16, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,377|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23695_[16, 63, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,379|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_2607_[16, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,381|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30903_[16, 511, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,382|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_11199_[16, 1023, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,385|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52448_[16, 2047, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,390|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80838_[16, 4095, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,395|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_9895_[16, 32767, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,395|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_30661_[16, 8191, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,402|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_52875_[16, 65535, 16, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,407|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_65312_[16, 16383, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,435|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64447_[16, 65535, 16, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,446|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2020_[16, 32767, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,478|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_98630_[16, 65535, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,508|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_894_[2048, 127, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:40:34,600|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_19465_[2048, 255, 16, 8, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,002|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_45209_[32, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,004|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_10678_[32, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,007|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_92884_[32, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,009|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_38218_[32, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,012|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_76428_[32, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,013|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_631_[32, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,016|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80907_[32, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,018|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27882_[32, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,022|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_79171_[32, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,025|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70461_[32, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,031|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_74257_[32, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,037|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_62790_[32, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,049|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_91871_[32, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,070|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58674_[32, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,080|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_96487_[32, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,082|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53978_[32, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,084|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_80539_[32, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,088|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_98830_[32, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,089|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43333_[32, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,093|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_31499_[32, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,093|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95896_[32, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,098|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36312_[32, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,099|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64752_[32, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,103|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_21951_[32, 32767, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,104|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_17021_[32, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,107|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_38738_[32, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,116|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_51144_[32, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,125|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52000_[32, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,141|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61616_[32, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,152|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_36227_[32, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,157|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86692_[32, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,162|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_31407_[32, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,167|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24246_[32, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,172|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_33304_[32, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,173|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68900_[32, 65535, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,177|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_33828_[32, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,179|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_3851_[32, 32767, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,183|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64086_[32, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,188|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_34367_[32, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,193|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_2468_[32, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,197|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63483_[32, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,198|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_82335_[32, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,207|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_9672_[32, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,216|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_82223_[32, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,222|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_30520_[1, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,225|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_75277_[1, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,227|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_15389_[1, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,229|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_70939_[32, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,230|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_85681_[1, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,233|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_74928_[1, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,235|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_71441_[1, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,238|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_18580_[1, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,238|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_13485_[1, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,240|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_89088_[1, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,243|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_25121_[1, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,244|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_54614_[1, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,249|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_39772_[1, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,251|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_31778_[1, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,253|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43058_[32, 65535, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,255|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53579_[32, 32767, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,263|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_59973_[1, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,267|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_71973_[1, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,270|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_76807_[1, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,270|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94744_[1, 32767, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,272|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_30332_[1, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,273|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_61994_[1, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,275|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_5147_[1, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,275|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27122_[1, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,277|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_56464_[1, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,277|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_45136_[1, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,279|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_47253_[1, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,281|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_8375_[1, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,282|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_5841_[1, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,285|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_77004_[1, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,292|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_28050_[1, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,294|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_48549_[1, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,295|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_94284_[1, 65535, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,299|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_27093_[1, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,304|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_44689_[1, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,306|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_79975_[1, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,308|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16602_[1, 32767, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,309|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4763_[1, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,311|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81051_[1, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,313|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_97139_[1, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,313|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_36085_[1, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,314|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_56924_[1, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,316|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74683_[1, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,318|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_101_[1, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,319|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_75253_[1, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,321|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11301_[1, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,326|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_58763_[1, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,335|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_2654_[1, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,335|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_45323_[32, 65535, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,338|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75587_[1, 65535, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,341|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_7568_[1, 32767, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,342|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_32136_[2, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,345|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31093_[2, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,346|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_55212_[2, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,348|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_88662_[2, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,348|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60706_[1, 131071, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,349|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33995_[2, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,350|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3955_[2, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,351|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86172_[2, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,353|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74373_[2, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,354|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_54269_[2, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,355|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_56508_[2, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,358|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_12393_[2, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,360|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_72447_[2, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,361|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60156_[2, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,366|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_58805_[2, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,370|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63093_[1, 65535, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,371|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52791_[2, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,373|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_52132_[2, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,375|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_22219_[2, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,376|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86137_[2, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,377|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_8335_[2, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,378|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_35060_[2, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,379|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_13473_[1, 131071, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,380|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_53587_[2, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,381|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_81048_[2, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,383|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81739_[2, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,384|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_87828_[2, 32767, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,385|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89887_[2, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,385|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_9994_[2, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,388|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_39015_[2, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,393|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_10361_[2, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,397|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_78679_[2, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,401|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_40243_[2, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,404|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_60130_[2, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,407|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_57002_[2, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,408|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_97250_[2, 65535, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,408|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78461_[2, 32767, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,409|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_44596_[2, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,412|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_9663_[2, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,413|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27083_[2, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,413|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_59339_[2, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,414|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23288_[2, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,416|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11021_[2, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,417|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_25737_[2, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,419|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_6431_[2, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,421|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_95332_[2, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,424|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14224_[1, 131071, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,425|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_2970_[2, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,431|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10782_[2, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,434|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50507_[2, 65535, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,440|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_30826_[64, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,443|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_67052_[2, 32767, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,446|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_59739_[64, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,449|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19094_[2, 131071, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,452|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_33449_[64, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,459|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_93393_[64, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,464|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_50625_[64, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,472|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48133_[2, 65535, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,479|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69478_[64, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,480|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34724_[64, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,488|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46022_[64, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,491|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_74752_[2, 131071, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,485|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_17232_[64, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,504|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_52195_[64, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,504|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_59238_[64, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,510|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_36375_[64, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,528|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45200_[2, 131071, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,529|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_3038_[64, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,532|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_4722_[64, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,536|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99546_[64, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,540|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23040_[64, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,548|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64520_[64, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,554|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_84783_[64, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,566|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_96605_[64, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,570|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_32904_[64, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,575|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_20013_[64, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,587|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_62915_[64, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,588|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_63378_[64, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,597|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_93192_[64, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,601|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_97382_[64, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,624|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_77827_[64, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,633|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_67643_[64, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,634|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97960_[64, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,644|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_19312_[64, 32767, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,664|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76508_[64, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,666|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_81997_[64, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,677|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17750_[64, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,681|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_68975_[64, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,710|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_42918_[64, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,712|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82178_[64, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,739|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31027_[64, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,746|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86254_[64, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,757|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_74568_[64, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,758|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_24701_[64, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,763|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_46399_[4, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,764|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_55074_[4, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,766|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_43655_[4, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,767|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_16902_[64, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,768|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_28372_[4, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,769|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_91443_[4, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,772|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36049_[4, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,773|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_10030_[4, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,773|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_80158_[64, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,776|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_77373_[4, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,777|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37228_[4, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,777|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17693_[4, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,786|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_35663_[4, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,792|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_60916_[4, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,794|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_80488_[4, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,795|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_2482_[4, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,799|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98353_[64, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,800|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_6240_[4, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,803|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_75253_[4, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,806|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_65514_[4, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,811|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_78789_[4, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,812|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34056_[4, 32767, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,812|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_87783_[4, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,813|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_54759_[64, 32767, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,815|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_22757_[4, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,815|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_9472_[4, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,817|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97451_[4, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,818|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_2778_[4, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,819|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_28255_[4, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,822|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_86191_[4, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,822|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_94805_[64, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,824|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_72798_[4, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,827|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_44703_[4, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,835|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_43640_[4, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,837|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76889_[4, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,840|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_56670_[4, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,841|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_72362_[4, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,843|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_30733_[4, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,846|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21421_[4, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,846|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52775_[4, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,850|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_18035_[4, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,850|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42822_[4, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,850|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_6014_[4, 65535, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,851|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_8621_[4, 32767, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,853|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_10585_[4, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,856|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_69335_[4, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,858|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_39286_[4, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,859|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63367_[4, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,864|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_11347_[4, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,873|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73221_[4, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,878|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_30258_[4, 65535, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,883|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_80861_[4, 32767, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,887|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_81553_[64, 32767, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,895|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50289_[128, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,899|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_12045_[128, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,901|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_64726_[4, 131071, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,905|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_68331_[4, 65535, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,911|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_71586_[128, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,915|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64958_[128, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,929|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_12430_[128, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,938|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8243_[4, 131071, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,944|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_65068_[128, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,947|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_53553_[128, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,950|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98596_[128, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,950|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_89764_[128, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,958|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45333_[128, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,963|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26715_[128, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,973|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86807_[128, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:00,980|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_62018_[4, 131071, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,001|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_81394_[128, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,016|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_44255_[128, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,027|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11658_[128, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,033|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_42774_[128, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,035|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_45971_[128, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,045|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_51742_[128, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,055|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_84220_[128, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,071|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_16741_[128, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,077|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_95930_[128, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,087|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26006_[128, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,103|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23890_[128, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,116|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_82729_[128, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,128|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36276_[128, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,137|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_626_[128, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,161|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_68342_[128, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,165|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_69149_[128, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,175|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_23145_[128, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,175|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73286_[128, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,199|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_16985_[128, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,202|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_79467_[128, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,219|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_83597_[128, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,238|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_85274_[128, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,242|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_66925_[128, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,247|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_15293_[128, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,273|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_52891_[128, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,273|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82198_[128, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,308|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_41195_[128, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,310|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_9328_[128, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,314|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_3251_[256, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,326|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_67138_[256, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,326|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74030_[256, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,383|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24936_[256, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,389|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48806_[256, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,395|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59467_[128, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,407|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_42621_[256, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,411|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30908_[256, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,413|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99214_[256, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,413|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_35834_[256, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,475|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_23626_[256, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,485|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75482_[256, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,492|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_19412_[128, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,496|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93840_[256, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,506|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_21901_[256, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,506|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_72363_[256, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,512|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_22475_[256, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,546|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_88072_[256, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,552|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65595_[256, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,572|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28208_[256, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,574|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_44391_[256, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,587|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_86258_[256, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,592|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_55239_[256, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,604|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_44568_[256, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,629|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_21005_[256, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,662|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_13454_[256, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,667|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_60239_[256, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,668|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57091_[256, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,668|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_12988_[256, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,668|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_75834_[256, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,707|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_35409_[256, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,713|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_95827_[256, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,714|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_82430_[256, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,736|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31702_[256, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,750|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_72615_[256, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,759|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_54573_[256, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,762|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_11131_[256, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,773|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_23165_[512, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,810|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_88276_[512, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,816|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_94264_[512, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,819|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53418_[512, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,855|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1261_[512, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,858|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_81582_[512, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,868|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_25147_[512, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,871|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_93627_[512, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,884|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16873_[256, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,922|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46929_[512, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,934|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31938_[512, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,947|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_55573_[512, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,955|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50128_[512, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,961|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_28643_[512, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,971|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_44562_[512, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:01,999|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_68164_[512, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,007|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_43913_[512, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,016|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_76139_[512, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,026|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_82786_[512, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,032|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_19603_[512, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,089|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75556_[512, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,096|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_56810_[512, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,113|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17002_[512, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,121|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_37678_[512, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,125|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_63383_[512, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,127|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_25543_[512, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,130|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_78043_[512, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,137|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97552_[8, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,141|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_74361_[8, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,144|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89881_[8, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,148|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_4935_[8, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,151|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_44981_[8, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,154|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_23024_[8, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,157|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58455_[8, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,161|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30860_[8, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,161|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_54628_[512, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,162|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_37796_[512, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,165|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_39026_[8, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,170|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_86795_[8, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,175|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_49745_[8, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,178|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57917_[8, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,185|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73196_[512, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,191|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_73355_[512, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,191|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13847_[8, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,196|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11503_[8, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,198|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_52356_[8, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,201|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_53837_[8, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,201|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_74130_[8, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,204|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_91569_[8, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,205|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64016_[8, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,207|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_99679_[8, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,208|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_96794_[8, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,210|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_26910_[8, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,215|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_12587_[8, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,219|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_74478_[8, 32767, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,220|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_58316_[8, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,223|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_1851_[8, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,225|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_2400_[512, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,227|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66846_[8, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,238|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_73054_[8, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,242|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_57447_[512, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,245|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_57186_[8, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,252|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_5108_[8, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,253|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82418_[8, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,254|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_82837_[8, 65535, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,257|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_29400_[8, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,257|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_93373_[8, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,260|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_77395_[8, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,260|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32985_[8, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,260|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_66398_[8, 32767, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,263|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_87194_[8, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,263|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_50295_[8, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,264|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_73568_[8, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,269|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_39747_[8, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,269|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_89062_[8, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,271|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97246_[8, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,274|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_24898_[8, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,277|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_86669_[512, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,285|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_58170_[8, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,294|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_65379_[8, 65535, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,298|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_65981_[8, 32767, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,321|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_92039_[8, 131071, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,331|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67087_[8, 65535, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,359|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_28561_[1024, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,367|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85113_[1024, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,370|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51780_[8, 131071, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,377|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_88611_[1024, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,389|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_2904_[1024, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,406|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_33414_[8, 131071, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,408|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_7985_[1024, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,435|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81897_[1024, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,463|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_27003_[1024, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,487|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_16940_[1024, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,520|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28793_[1024, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,520|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_11467_[1024, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,523|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_26119_[1024, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,534|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_58205_[1024, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,548|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_71466_[1024, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,559|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63595_[1024, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,593|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24420_[1024, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,619|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28788_[1024, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,655|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_10369_[1024, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,660|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73141_[1024, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,666|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_22960_[1024, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,678|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_88670_[1024, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,715|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87463_[1024, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,715|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17887_[1024, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,737|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_54149_[1024, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,762|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_17630_[1024, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,777|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_7151_[1024, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,784|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_19544_[1024, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,801|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30548_[1024, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,838|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_40506_[1024, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,901|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_99070_[2048, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,908|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_30186_[1024, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,938|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_88613_[2048, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,954|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_9250_[2048, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,964|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_22756_[2048, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:02,995|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97729_[2048, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,003|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_78883_[1024, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,031|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64598_[2048, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,141|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64839_[2048, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,147|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_52606_[2048, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,166|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97935_[2048, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,196|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77523_[2048, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,202|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_92805_[2048, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,237|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_9935_[2048, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,255|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_9156_[2048, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,337|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_66680_[2048, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,402|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_33800_[2048, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,417|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_93964_[2048, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,432|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_44397_[2048, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,466|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_87264_[2048, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,477|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_98970_[2048, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,548|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97422_[2048, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,554|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79456_[2048, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,565|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_55908_[16, 1, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,566|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_38865_[16, 3, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,568|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59974_[16, 7, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,570|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_35156_[16, 15, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,572|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_70922_[16, 31, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,574|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_97440_[16, 63, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,575|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16396_[16, 127, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,578|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_14787_[16, 255, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,579|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_59347_[16, 511, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,583|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_64428_[16, 1023, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,586|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_92163_[16, 2047, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,602|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23699_[16, 8191, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,603|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9893_[16, 4095, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,633|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_18769_[2048, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,639|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_9616_[2048, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,643|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_99877_[16, 16383, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,649|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_15639_[16, 32767, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,652|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73191_[16, 1, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,656|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_30337_[16, 3, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,660|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_22809_[16, 7, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,660|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_90883_[16, 15, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,663|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_76061_[16, 31, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,664|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_94801_[16, 63, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,667|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_78902_[16, 127, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,668|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37733_[16, 255, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,671|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75026_[16, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,673|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_86213_[16, 1023, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,677|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_6702_[16, 2047, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,682|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_73300_[16, 4095, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,691|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36652_[16, 8191, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,706|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_94898_[16, 16383, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,715|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_67251_[16, 65535, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,720|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_7394_[2048, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,731|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_26691_[16, 32767, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,731|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27794_[16, 1, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,736|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_48182_[16, 3, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,740|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_85811_[16, 7, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,742|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_75020_[16, 15, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,743|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_79170_[16, 31, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,746|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_40972_[16, 63, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,747|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_92612_[16, 127, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,751|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_98778_[16, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,751|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_920_[16, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,756|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_88414_[16, 1023, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,758|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_90251_[16, 2047, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,762|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_2195_[2048, 511, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,766|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46237_[16, 4095, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,771|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_3909_[16, 8191, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,789|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79008_[16, 16383, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,799|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_28704_[16, 65535, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,813|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67031_[16, 131071, 8, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,817|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_18897_[2048, 255, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,821|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_35580_[16, 32767, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,860|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67396_[16, 65535, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,905|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_37435_[16, 131071, 8, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:03,971|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_90684_[16, 131071, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:04,050|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_40953_[2048, 511, 8, 4, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,689|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57761_[32, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,693|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93397_[32, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,697|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24759_[32, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,701|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_54963_[32, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,706|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_44659_[32, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,708|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_78143_[32, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,710|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_60847_[32, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,713|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_82268_[32, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,716|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_25230_[32, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,719|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_56470_[32, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,724|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_57071_[32, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,731|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7926_[32, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,745|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73529_[32, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,764|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_37455_[32, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,795|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_47700_[32, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,799|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_16785_[32, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,800|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_36296_[32, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,804|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_58002_[32, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,809|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_29499_[32, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,810|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48874_[32, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,813|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62302_[32, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,814|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_36331_[32, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,817|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53317_[32, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,819|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_33096_[32, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,821|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_70724_[32, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,825|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_65685_[32, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,830|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_31870_[32, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,842|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_86743_[32, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,855|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_53142_[32, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,870|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_45068_[32, 65535, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,889|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_14676_[32, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,892|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_41470_[1, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,894|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45998_[1, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,895|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_43831_[1, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,897|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_86494_[1, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,898|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_97015_[1, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,900|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_67660_[1, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,900|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_78033_[1, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,901|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63915_[1, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,904|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_93824_[1, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,904|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93610_[1, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,907|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_50718_[1, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,910|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_63485_[1, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,911|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_56787_[1, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,919|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_27640_[1, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,932|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_71128_[1, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,932|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_18308_[1, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,935|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_32259_[1, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,936|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_42518_[1, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,938|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_3689_[1, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,939|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_81549_[1, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,941|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_64367_[1, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,942|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_9157_[1, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,944|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_79814_[1, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,945|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_60246_[1, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,948|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_53284_[1, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,950|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_36406_[1, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,953|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_94706_[1, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,954|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_53111_[1, 65535, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,960|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_27470_[1, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,966|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_4224_[1, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,968|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_42717_[32, 65535, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,978|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39470_[1, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,983|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30838_[2, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,985|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_1801_[2, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,988|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93032_[2, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,989|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_33757_[2, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,991|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_60267_[2, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,992|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_55868_[2, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,993|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_30060_[2, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,995|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_62722_[2, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:22,996|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52179_[2, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,000|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_77116_[2, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,001|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_76417_[2, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,006|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28766_[2, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,007|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28742_[1, 65535, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,009|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_22102_[1, 131071, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,010|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_19650_[2, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,019|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_42199_[2, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,024|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76723_[2, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,027|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_64988_[2, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,030|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_23937_[2, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,032|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_59775_[2, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,035|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_94838_[2, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,035|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_20262_[2, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,037|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_39986_[2, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,040|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14161_[2, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,040|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_73238_[2, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,043|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_20746_[2, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,045|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11648_[2, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,045|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_99479_[2, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,049|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80654_[2, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,052|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_96589_[1, 131071, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,053|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_79892_[2, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,056|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_8551_[2, 65535, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,063|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_9546_[2, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,065|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_97355_[64, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,071|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28795_[2, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,071|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_64806_[64, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,072|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69015_[64, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,078|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_47456_[64, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,080|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_64469_[64, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,080|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14931_[64, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,084|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_89465_[64, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,087|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_70180_[64, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,089|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_23888_[64, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,094|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63104_[64, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,098|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_79982_[32, 131071, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,100|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_46755_[2, 65535, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,103|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9117_[2, 131071, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,104|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_31943_[64, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,109|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83726_[64, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,120|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_48375_[64, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,125|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_63031_[64, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,127|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21913_[64, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,133|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_31206_[64, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,137|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17096_[64, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,138|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_68785_[64, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,139|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_22800_[64, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,143|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11909_[2, 131071, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,144|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_11358_[64, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,147|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_95373_[64, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,147|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_79103_[64, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,154|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_25108_[64, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,157|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_51146_[64, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,160|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_26852_[64, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,166|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24374_[64, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,175|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81611_[4, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,177|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_17724_[64, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,178|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_74905_[4, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,181|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_12184_[4, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,184|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_29544_[4, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,184|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_17176_[32, 131071, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,186|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81289_[4, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,187|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_8343_[4, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,189|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_13444_[4, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,190|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_72720_[4, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,192|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_17377_[4, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,194|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76122_[4, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,197|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26005_[4, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,200|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_98771_[4, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,205|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48941_[4, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,209|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_43386_[64, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,210|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_84688_[64, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,216|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24126_[4, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,222|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_6818_[4, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,226|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62163_[4, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,229|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_42902_[4, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,230|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_15807_[4, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,231|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_69712_[4, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,232|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_97742_[4, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,235|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_30140_[4, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,235|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_61464_[4, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,235|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_77566_[4, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,238|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_90346_[4, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,239|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_43666_[4, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,239|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_78465_[4, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,244|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_5853_[4, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,247|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_98616_[4, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,253|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_34781_[4, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,263|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95696_[4, 65535, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,268|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_38469_[4, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,268|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_51142_[64, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,279|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34486_[128, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,285|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_27996_[128, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,291|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_75045_[128, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,294|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_37192_[4, 65535, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,297|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_74159_[128, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,304|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11438_[128, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,309|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_99116_[128, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,321|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_47313_[128, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,321|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_49239_[4, 131071, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,326|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_32413_[128, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,326|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78599_[128, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,333|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_95709_[128, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,357|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_4827_[128, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,361|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_82089_[4, 131071, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,372|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_71719_[128, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,374|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_51254_[64, 65535, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,375|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_54646_[128, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,384|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_80784_[128, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,408|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_60314_[128, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,418|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_87584_[128, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,424|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_75186_[128, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,441|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_26633_[128, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,452|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11167_[64, 65535, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,469|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_98759_[128, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,476|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_50450_[128, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,491|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_21657_[128, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,502|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98867_[128, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,502|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_36286_[128, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,514|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7308_[128, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,520|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_64718_[128, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,529|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_8887_[128, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,563|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_52998_[256, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,582|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_53197_[256, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,591|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_13363_[256, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,595|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_84947_[256, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,608|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_55174_[128, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,612|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_76591_[256, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,632|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_73609_[128, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,644|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_95670_[256, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,651|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_1284_[256, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,660|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_73625_[128, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,674|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_57886_[256, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,686|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_93668_[256, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,723|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_71962_[256, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,736|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_43985_[256, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,748|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_48292_[256, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,750|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_37014_[256, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,772|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_34467_[256, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,781|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_84752_[256, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,781|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_64466_[256, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,799|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_18129_[256, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,810|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_13834_[256, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,815|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_76899_[256, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,870|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_85100_[256, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,885|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_8488_[256, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,889|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_2686_[256, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,892|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_19317_[256, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,899|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_51113_[256, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,910|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_99877_[128, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,944|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_83866_[512, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,971|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_20070_[512, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,973|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_9536_[256, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,983|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_24084_[512, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,985|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_30374_[512, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:23,996|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_11063_[512, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,001|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_33570_[512, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,020|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_94480_[512, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,028|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_81283_[512, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,044|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_38911_[512, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,065|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_28523_[256, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,074|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_49814_[512, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,084|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_80527_[512, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,091|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_15615_[512, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,103|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_61440_[512, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,118|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_59240_[512, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,126|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_65185_[512, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,171|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_14744_[512, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,171|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_48223_[512, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,179|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_36883_[512, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,182|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_41212_[8, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,183|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_67396_[512, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,186|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_46623_[8, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,188|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_85628_[8, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,189|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_98532_[8, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,192|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_16215_[512, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,192|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_43277_[8, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,193|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63412_[8, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,196|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37211_[8, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,196|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_70877_[8, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,200|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_75338_[8, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,201|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_5215_[8, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,201|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17053_[8, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,203|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62967_[8, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,212|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_68204_[8, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,219|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_59514_[8, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,225|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_86052_[8, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,229|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_14992_[8, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,230|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_59419_[8, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,232|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_46526_[8, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,235|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52692_[8, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,237|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_13292_[8, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,238|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_52763_[8, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,241|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_16011_[512, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,245|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_67979_[8, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,250|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_93263_[8, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,250|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_37478_[8, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,251|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_48662_[512, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,255|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_24264_[8, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,256|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_11676_[8, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,260|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31683_[8, 65535, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,262|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_19375_[8, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,267|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_76467_[8, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,277|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_23556_[8, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,288|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_62466_[512, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,302|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_89510_[8, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,321|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_75102_[8, 65535, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,348|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_7399_[8, 131071, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,355|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_49617_[1024, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,361|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_17906_[1024, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,373|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_28054_[1024, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,376|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_66928_[8, 131071, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,384|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_87780_[1024, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,428|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_42089_[512, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,433|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_81547_[1024, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,443|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_84798_[1024, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,457|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_55342_[1024, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,491|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_45016_[1024, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,529|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_65159_[1024, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,529|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_38550_[1024, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,555|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_17275_[1024, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,557|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_52709_[1024, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,569|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_81514_[1024, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,587|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_98452_[1024, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,640|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_80428_[1024, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,648|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63461_[1024, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,655|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_94558_[1024, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,683|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_85746_[1024, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,726|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_36485_[1024, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,812|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_83560_[2048, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,841|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_34289_[1024, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,847|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_27406_[2048, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,848|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_28052_[2048, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,852|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_22557_[1024, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,870|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_56420_[2048, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:24,909|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_39875_[2048, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,013|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_37682_[2048, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,025|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_99295_[1024, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,091|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_48498_[2048, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,098|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_26884_[2048, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,105|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_12761_[2048, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,127|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_69015_[2048, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,204|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_98211_[2048, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,241|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_78091_[2048, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,293|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_73976_[2048, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,300|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_93585_[2048, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,301|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_97977_[16, 1, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,305|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_84520_[16, 3, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,309|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_21497_[16, 15, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,309|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_6863_[16, 7, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,313|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_69118_[16, 31, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,313|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_71231_[16, 63, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,317|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_84058_[16, 127, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,318|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_77905_[16, 255, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,321|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_64534_[16, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,323|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_83491_[16, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,327|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_83439_[16, 2047, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,332|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_31188_[16, 4095, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,342|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_13223_[16, 8191, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,356|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_18510_[2048, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,360|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_35510_[16, 16383, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,375|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_39653_[2048, 511, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,383|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_63772_[16, 32767, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,390|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_92233_[16, 1, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,393|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_85103_[16, 3, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,395|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_73439_[16, 7, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,397|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_67452_[16, 15, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,399|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_83095_[16, 31, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,401|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_31091_[16, 63, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,403|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_35610_[16, 127, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,405|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_86484_[16, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,405|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_41279_[2048, 255, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,410|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_41454_[16, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,411|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_18069_[16, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,416|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_14764_[16, 2047, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,420|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_82551_[16, 4095, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,423|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_62698_[16, 8191, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,438|ERROR|Worker-worker_3|worker|Task trtllm.attention_generation_run_attention_torch_98381_[16, 65535, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,439|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_48172_[16, 16383, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,458|ERROR|Worker-worker_4|worker|Task trtllm.attention_generation_run_attention_torch_83941_[16, 32767, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,497|ERROR|Worker-worker_7|worker|Task trtllm.attention_generation_run_attention_torch_82670_[16, 65535, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,551|ERROR|Worker-worker_6|worker|Task trtllm.attention_generation_run_attention_torch_5771_[16, 131071, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,610|ERROR|Worker-worker_0|worker|Task trtllm.attention_generation_run_attention_torch_63489_[16, 131071, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,665|ERROR|Worker-worker_1|worker|Task trtllm.attention_generation_run_attention_torch_77010_[2048, 1023, 4, 1, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:25,744|ERROR|Worker-worker_2|worker|Task trtllm.attention_generation_run_attention_torch_89054_[2048, 511, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:26,064|ERROR|Worker-worker_5|worker|Task trtllm.attention_generation_run_attention_torch_55098_[2048, 1023, 4, 2, 64, 0, False, False, False, 'generation_attention_perf.txt'] failed: AssertionError: 
2025-10-04 00:41:42,585|ERROR|root|parallel_run|trtllm.attention_generation: Completed with 5026 errors
2025-10-04 00:41:42,687|ERROR|root|parallel_run|Error details saved to all_20251004_000940/errors_trtllm.attention_generation.json
2025-10-04 00:41:43,110|INFO|root|collect_module_safe|Starting collection: trtllm.mla_bmm_gen_pre
2025-10-04 00:41:43,110|INFO|root|collect_module_safe|Generated 200 test cases for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:44,830|INFO|root|start_process|Started worker process 21718 on device 0
2025-10-04 00:41:44,831|INFO|root|start_process|Started worker process 21719 on device 1
2025-10-04 00:41:44,832|INFO|root|start_process|Started worker process 21720 on device 2
2025-10-04 00:41:44,833|INFO|root|start_process|Started worker process 21721 on device 3
2025-10-04 00:41:44,834|INFO|root|start_process|Started worker process 21722 on device 4
2025-10-04 00:41:44,835|INFO|root|start_process|Started worker process 21723 on device 5
2025-10-04 00:41:44,836|INFO|root|start_process|Started worker process 21724 on device 6
2025-10-04 00:41:44,837|INFO|root|start_process|Started worker process 21725 on device 7
2025-10-04 00:41:57,573|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:57,690|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:58,063|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:58,196|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:58,273|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:58,305|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:58,332|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:41:58,356|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.mla_bmm_gen_pre
2025-10-04 00:42:07,049|INFO|root|parallel_run|trtllm.mla_bmm_gen_pre: Completed successfully with no errors
2025-10-04 00:42:07,375|INFO|root|collect_module_safe|Starting collection: trtllm.mla_bmm_gen_post
2025-10-04 00:42:07,375|INFO|root|collect_module_safe|Generated 448 test cases for trtllm.mla_bmm_gen_post
2025-10-04 00:42:09,034|INFO|root|start_process|Started worker process 24011 on device 0
2025-10-04 00:42:09,035|INFO|root|start_process|Started worker process 24012 on device 1
2025-10-04 00:42:09,036|INFO|root|start_process|Started worker process 24013 on device 2
2025-10-04 00:42:09,037|INFO|root|start_process|Started worker process 24014 on device 3
2025-10-04 00:42:09,038|INFO|root|start_process|Started worker process 24015 on device 4
2025-10-04 00:42:09,039|INFO|root|start_process|Started worker process 24016 on device 5
2025-10-04 00:42:09,040|INFO|root|start_process|Started worker process 24017 on device 6
2025-10-04 00:42:09,041|INFO|root|start_process|Started worker process 24018 on device 7
2025-10-04 00:42:21,379|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:21,712|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:22,335|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_61785_[1, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,475|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:22,544|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:22,548|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:22,553|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:22,556|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_16205_[1, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,562|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_72716_[1, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,568|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_671_[1, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,575|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_91737_[1, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,587|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_22663_[1, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,603|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:22,612|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.mla_bmm_gen_post
2025-10-04 00:42:22,625|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_14408_[1, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,639|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_22625_[2, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,662|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_78664_[1, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,676|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_41382_[2, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,861|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_62253_[2, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,956|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_63314_[2, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,959|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_40256_[2, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,971|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_48076_[2, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:22,985|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_75970_[2, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,031|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_72698_[2, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,052|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_51442_[4, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,065|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_15034_[4, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,130|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_72358_[4, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,178|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_77934_[4, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,190|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_11140_[4, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,210|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_27708_[4, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,223|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_14918_[4, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,283|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_30353_[4, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,296|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_19884_[8, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,390|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_98738_[8, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,397|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_47291_[8, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,411|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_25470_[8, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,430|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_35615_[8, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,442|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_9166_[8, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,467|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_33479_[8, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,502|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_94987_[8, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,544|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_78316_[16, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,614|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_31882_[16, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,643|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_17689_[16, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,682|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_50359_[16, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,694|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_69367_[16, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,706|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_34964_[16, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,758|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_92505_[16, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,772|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_98305_[16, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,792|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_38228_[32, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,836|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_79642_[32, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,865|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_78668_[32, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,931|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_70192_[32, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,944|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_44805_[32, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,946|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_32474_[32, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:23,959|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_83585_[32, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,043|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_57814_[32, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,061|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_16415_[48, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,092|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_61036_[48, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,113|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_31398_[48, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,158|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_23915_[48, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,182|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_67640_[48, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,194|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_20429_[48, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,206|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_45976_[48, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,294|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_56925_[48, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,324|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_84456_[64, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,381|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_16218_[64, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,410|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_84803_[64, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,425|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_36921_[64, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,439|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_2823_[64, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,452|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_88227_[64, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,556|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_12097_[64, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,568|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_36713_[64, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,604|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_83020_[80, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,617|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_17520_[80, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,672|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_39165_[80, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,684|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_43422_[80, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,706|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_21093_[80, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,720|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_43929_[80, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,804|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_76492_[80, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,817|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_38929_[80, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,831|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_21214_[96, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,910|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_91073_[96, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,931|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_16338_[96, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,960|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_49794_[96, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:24,996|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_86515_[96, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,022|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_4665_[96, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,034|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_37247_[96, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,082|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_10626_[96, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,095|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_74415_[128, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,151|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_63128_[128, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,186|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_63549_[128, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,218|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_61212_[128, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,247|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_38139_[128, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,268|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_16370_[128, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,281|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_43499_[128, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,338|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_91288_[128, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,393|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_45171_[160, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,431|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_12469_[160, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,451|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_18946_[160, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,471|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_8401_[160, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,484|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_45243_[160, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,512|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_35301_[160, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,541|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_63962_[160, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,592|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_90115_[160, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,634|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_70228_[192, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,677|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_10033_[192, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,708|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_92916_[192, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,721|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_21865_[192, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,736|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_66790_[192, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,819|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_28664_[192, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,832|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_70233_[192, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,846|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_29139_[192, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,876|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_66820_[256, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,933|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_34547_[256, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,945|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_81561_[256, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,959|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_21136_[256, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:25,971|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_5439_[256, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,081|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_7396_[256, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,106|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_84437_[256, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,119|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_82181_[256, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,156|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_55816_[320, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,185|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_26886_[320, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,195|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_34057_[320, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,208|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_15440_[320, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,220|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_84832_[320, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,345|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_88445_[320, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,358|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_83972_[320, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,380|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_7895_[320, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,394|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_7824_[384, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,426|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_90871_[384, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,443|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_60851_[384, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,455|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_77323_[384, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,600|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_35012_[384, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,616|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_37138_[384, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,625|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_65110_[384, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,638|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_31718_[384, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,652|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_89559_[512, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,669|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_17289_[512, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,681|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_58842_[512, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,698|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_88755_[512, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,830|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_34503_[512, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,844|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_94704_[512, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,892|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_8765_[512, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,905|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_15183_[512, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,920|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_23933_[768, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,933|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_26392_[768, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:26,957|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_55118_[768, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,026|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_41679_[768, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,068|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_59049_[768, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,081|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_89657_[768, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,107|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_56580_[768, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,151|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_3983_[768, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,164|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_34374_[1024, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,217|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_31879_[1024, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,231|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_66165_[1024, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,299|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_22756_[1024, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,311|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_22455_[1024, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,332|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_77465_[1024, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,390|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_81724_[1024, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,406|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_56535_[1024, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,420|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_10169_[1536, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,486|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_44609_[1536, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,500|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_8421_[1536, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,519|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_87680_[1536, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,554|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_62673_[1536, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,566|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_36510_[1536, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,632|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_44916_[1536, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,661|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_10864_[1536, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,739|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_16143_[2048, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,752|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_45633_[2048, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,774|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_52861_[2048, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,788|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_45744_[2048, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,805|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_20501_[2048, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,852|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_3674_[2048, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,875|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_51130_[2048, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,918|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_49706_[2048, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,961|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_5942_[3072, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:27,989|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_94570_[3072, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,015|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_4027_[3072, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,047|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_1502_[3072, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,065|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_77661_[3072, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,118|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_2494_[3072, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,178|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_72059_[3072, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,203|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_93938_[3072, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,218|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_78405_[4096, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,277|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_3866_[4096, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,290|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_80819_[4096, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,302|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_73805_[4096, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,342|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_42948_[4096, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,359|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_83704_[4096, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,430|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_82088_[4096, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,443|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_91092_[4096, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,458|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_77849_[6144, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,538|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_87574_[6144, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,552|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_27423_[6144, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,601|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_2153_[6144, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,619|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_81032_[6144, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,651|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_5490_[6144, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,674|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_41839_[6144, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,693|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_78269_[6144, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,715|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_31654_[8192, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,775|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_46523_[8192, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,816|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_36885_[8192, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,843|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_10552_[8192, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,877|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_94167_[8192, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,899|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_37026_[8192, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,912|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_17520_[8192, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:28,975|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_63074_[8192, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,021|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_24743_[12288, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,073|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_7507_[12288, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,097|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_93430_[12288, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,109|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_94860_[12288, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,122|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_95750_[12288, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,151|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_73214_[12288, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,184|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_39795_[12288, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,255|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_77976_[12288, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,273|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_42856_[16384, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,326|ERROR|Worker-worker_3|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_36551_[16384, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7ff5d2f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7ff5d2f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7ff5d2f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7ff20b3b8cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7ff20b3bd918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7ff76dcbb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7ff76dcbb7d0]
7       0x7ff76e4a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7ff76e4a9d51]
8       0x7ff776724a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7ff776724d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
11      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7ff77694f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7ff77671e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7ff776724c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7ff776636901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7ff776636901]
25      0x7ff77616b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7ff77616b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7ff782b101ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7ff782b101ca]
39      0x7ff782b1028b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,339|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_22845_[16384, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,352|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_87460_[16384, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,369|ERROR|Worker-worker_4|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_68654_[16384, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f7d1089256a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f7d10881b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f7d108a6299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f7acab81cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f7acab86918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f802d4bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f802d4bb7d0]
7       0x7f802dca9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f802dca9d51]
8       0x7f8035f24a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8035f24d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
11      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f803614f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8035f1e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8035f24c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8035e36901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8035e36901]
25      0x7f803596b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f803596b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f80422f61ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f80422f61ca]
39      0x7f80422f628b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,462|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_62635_[16384, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,534|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_70626_[16384, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,546|ERROR|Worker-worker_0|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_97011_[16384, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fd858fb456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fd858fa3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fd858fc8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fd6132cecb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fd6132d3918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fdb75ba07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fdb75ba07d0]
7       0x7fdb7638ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fdb7638ed51]
8       0x7fdb7e609a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fdb7e609d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
11      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fdb7e8344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fdb7e6037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fdb7e609c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fdb7e51b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fdb7e51b901]
25      0x7fdb7e05037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fdb7e05037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fdb8aa371ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fdb8aa371ca]
39      0x7fdb8aa3728b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,568|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_42385_[20480, 128, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,576|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_19377_[20480, 64, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,589|ERROR|Worker-worker_7|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_57334_[20480, 32, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7fa371c6856a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7fa371c57b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7fa371c7c299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7fa12bf18cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7fa12bf1d918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7fa68e8bb7d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7fa68e8bb7d0]
7       0x7fa68f0a9d51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7fa68f0a9d51]
8       0x7fa697324a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7fa697324d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
11      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7fa69754f4bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7fa69731e7c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7fa697324c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7fa697236901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7fa697236901]
25      0x7fa696d6b37d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7fa696d6b37d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7fa6a36841ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7fa6a36841ca]
39      0x7fa6a368428b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,612|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_28955_[20480, 16, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,626|ERROR|Worker-worker_5|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_71167_[20480, 8, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7eff4af5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7eff4af46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7eff4af6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7efbe78cacb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7efbe78cf918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f014a1a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f014a1a07d0]
7       0x7f014a98ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f014a98ed51]
8       0x7f0152c09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f0152c09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
11      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f0152e344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f0152c037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f0152c09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f0152b1b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f0152b1b901]
25      0x7f015265037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f015265037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f015f02c1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f015f02c1ca]
39      0x7f015f02c28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,752|ERROR|Worker-worker_6|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_82464_[20480, 4, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f304e1b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f304e1a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f304e1c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f2e084c0cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f2e084c5918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f336ada07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f336ada07d0]
7       0x7f336b58ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f336b58ed51]
8       0x7f3373809a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f3373809d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
11      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f3373a344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f33738037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f3373809c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f337371b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f337371b901]
25      0x7f337325037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f337325037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f337fc4e1ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f337fc4e1ca]
39      0x7f337fc4e28b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,792|ERROR|Worker-worker_1|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_65811_[20480, 2, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f33b23b456a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f33b23a3b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f33b23c8299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f316c597cb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f316c59c918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f36cefa07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f36cefa07d0]
7       0x7f36cf78ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f36cf78ed51]
8       0x7f36d7a09a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f36d7a09d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
11      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f36d7c344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f36d7a037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f36d7a09c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f36d791b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f36d791b901]
25      0x7f36d745037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f36d745037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f36e3e151ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f36e3e151ca]
39      0x7f36e3e1528b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:29,809|ERROR|Worker-worker_2|worker|Task trtllm.mla_bmm_gen_post_run_mla_gen_post_78543_[20480, 1, 'fp8', 2, 10, 'mla_bmm_perf.txt'] failed: RuntimeError: DeepGEMM only supports Hopper (SM90) architectures, but current device compute capability is 80. (../include/tensorrt_llm/deep_gemm/compiler.cuh:330)
1       0x7f8982f5756a deep_gemm::jit::Compiler::build(unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, unsigned int, deep_gemm::GemmType, bool) + 11770
2       0x7f8982f46b95 tensorrt_llm::kernels::fp8_blockscale_gemm::strided_batch_gemm_dispatch(__nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, __nv_bfloat16*, int, int, float*, float*, unsigned int, unsigned int, unsigned int, unsigned int, CUstream_st*, int) + 229
3       0x7f8982f6b299 tensorrt_llm::kernels::fp8_blockscale_gemm::CutlassFp8BlockScaleGemmRunner<__nv_fp8_e4m3, __nv_fp8_e4m3, __nv_bfloat16>::strideBatchGemm(__nv_bfloat16*, int, int, __nv_fp8_e4m3*, int, int, __nv_fp8_e4m3*, int, int, int, int, int, int, CUstream_st*, float*, int, float*) + 121
4       0x7f875030ccb5 torch_ext::fp8_block_scaling_bmm_out(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&) + 1157
5       0x7f8750311918 c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoRuntimeFunctor_<at::Tensor (*)(at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&), at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor const&, at::Tensor&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) + 120
6       0x7f8cb37a07d0 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x4ffc7d0) [0x7f8cb37a07d0]
7       0x7f8cb3f8ed51 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so(+0x57ead51) [0x7f8cb3f8ed51]
8       0x7f8cbc209a5f torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args const&, pybind11::kwargs const&, std::optional<c10::DispatchKey>) + 239
9       0x7f8cbc209d09 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 553
10      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
11      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
12            0x58208f /usr/bin/python() [0x58208f]
13            0x54b30c PyObject_Call + 108
14            0x5db55b _PyEval_EvalFrameDefault + 19483
15            0x54a9d2 _PyObject_Call_Prepend + 194
16            0x5a3628 /usr/bin/python() [0x5a3628]
17            0x54b30c PyObject_Call + 108
18            0x5db55b _PyEval_EvalFrameDefault + 19483
19            0x54cccd /usr/bin/python() [0x54cccd]
20            0x54a4ca PyObject_CallMethod + 330
21      0x7f8cbc4344bf torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef<_object*>, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) + 1071
22      0x7f8cbc2037c2 torch::jit::_maybe_handle_torch_function(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, pybind11::args const&, pybind11::kwargs const&) + 994
23      0x7f8cbc209c40 torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 352
24      0x7f8cbc11b901 /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x84f901) [0x7f8cbc11b901]
25      0x7f8cbbc5037d /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_python.so(+0x38437d) [0x7f8cbbc5037d]
26            0x58208f /usr/bin/python() [0x58208f]
27            0x54b30c PyObject_Call + 108
28            0x5db55b _PyEval_EvalFrameDefault + 19483
29            0x54a9d2 _PyObject_Call_Prepend + 194
30            0x5a3628 /usr/bin/python() [0x5a3628]
31            0x549185 _PyObject_MakeTpCall + 117
32            0x5d73c9 _PyEval_EvalFrameDefault + 2697
33            0x5d58eb PyEval_EvalCode + 347
34            0x608a23 PyRun_StringFlags + 211
35            0x6b3e9e PyRun_SimpleStringFlags + 62
36            0x6bcb61 Py_RunMain + 1153
37            0x6bc57d Py_BytesMain + 45
38      0x7f8cc86491ca /usr/lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7f8cc86491ca]
39      0x7f8cc864928b __libc_start_main + 139
40            0x657ce5 _start + 37
2025-10-04 00:42:41,064|WARNING|root|parallel_run|Process 24011 did not terminate, forcing...
2025-10-04 00:42:41,065|ERROR|Worker-worker_0|signal_handler|Worker 0 received signal 15
2025-10-04 00:42:51,074|WARNING|root|parallel_run|Process 24012 did not terminate, forcing...
2025-10-04 00:42:51,076|ERROR|Worker-worker_1|signal_handler|Worker 1 received signal 15
2025-10-04 00:43:01,085|WARNING|root|parallel_run|Process 24013 did not terminate, forcing...
2025-10-04 00:43:01,086|ERROR|Worker-worker_2|signal_handler|Worker 2 received signal 15
2025-10-04 00:43:11,095|WARNING|root|parallel_run|Process 24014 did not terminate, forcing...
2025-10-04 00:43:11,096|ERROR|Worker-worker_3|signal_handler|Worker 3 received signal 15
2025-10-04 00:43:21,105|WARNING|root|parallel_run|Process 24015 did not terminate, forcing...
2025-10-04 00:43:21,106|ERROR|Worker-worker_4|signal_handler|Worker 4 received signal 15
2025-10-04 00:43:31,115|WARNING|root|parallel_run|Process 24016 did not terminate, forcing...
2025-10-04 00:43:31,116|ERROR|Worker-worker_5|signal_handler|Worker 5 received signal 15
2025-10-04 00:43:41,125|WARNING|root|parallel_run|Process 24017 did not terminate, forcing...
2025-10-04 00:43:41,126|ERROR|Worker-worker_6|signal_handler|Worker 6 received signal 15
2025-10-04 00:43:51,135|WARNING|root|parallel_run|Process 24018 did not terminate, forcing...
2025-10-04 00:43:51,135|ERROR|root|parallel_run|trtllm.mla_bmm_gen_post: Completed with 31 errors
2025-10-04 00:43:51,136|ERROR|Worker-worker_7|signal_handler|Worker 7 received signal 15
2025-10-04 00:43:51,143|ERROR|root|parallel_run|Error details saved to all_20251004_000940/errors_trtllm.mla_bmm_gen_post.json
2025-10-04 00:43:51,643|INFO|root|collect_module_safe|Starting collection: trtllm.moe
2025-10-04 00:43:51,643|INFO|root|collect_module_safe|Generated 392 test cases for trtllm.moe
2025-10-04 00:43:53,344|INFO|root|start_process|Started worker process 26312 on device 0
2025-10-04 00:43:53,346|INFO|root|start_process|Started worker process 26313 on device 1
2025-10-04 00:43:53,347|INFO|root|start_process|Started worker process 26314 on device 2
2025-10-04 00:43:53,347|INFO|root|start_process|Started worker process 26315 on device 3
2025-10-04 00:43:53,348|INFO|root|start_process|Started worker process 26316 on device 4
2025-10-04 00:43:53,349|INFO|root|start_process|Started worker process 26317 on device 5
2025-10-04 00:43:53,350|INFO|root|start_process|Started worker process 26318 on device 6
2025-10-04 00:43:53,351|INFO|root|start_process|Started worker process 26319 on device 7
2025-10-04 00:44:06,263|INFO|Worker-worker_0|worker|Worker 0 initialized for trtllm.moe
2025-10-04 00:44:06,265|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_51744_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,266|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_2149_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,267|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_94290_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,267|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_73593_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,268|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47991_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,269|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_51886_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,269|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_99115_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,270|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_19569_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,271|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_59398_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,271|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_11197_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,272|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_60469_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,273|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_89294_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,273|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_87168_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,274|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_16962_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,275|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_71271_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,275|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_29437_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,276|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_69802_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,277|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_29726_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,277|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_62043_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,278|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_45918_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,279|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_36920_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,279|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_70794_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,280|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_69166_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,280|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_69086_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,281|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_21850_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,282|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_32272_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,282|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_87252_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,283|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_50811_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,284|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_19212_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,284|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_20057_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,285|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_67879_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,286|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_77965_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,286|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_78763_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,287|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_27421_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,288|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_17031_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,288|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_6822_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,289|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_59030_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,289|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_4646_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,290|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_90016_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,291|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_52714_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,292|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_25833_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,292|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_58790_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,293|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_90541_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,293|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_17062_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,294|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_39911_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,295|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_15847_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,295|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_22183_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,296|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_33893_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,297|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_97240_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,297|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_29924_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,298|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_24480_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,298|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_68590_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,299|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_15281_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,300|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_92995_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,300|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_87851_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,301|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_70557_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,301|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_94427_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,302|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_65920_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,303|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_91676_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,303|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_87369_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,304|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_36020_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,304|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_69573_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,305|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37156_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,305|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_8444_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,306|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_5351_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,307|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_7255_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,307|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_46554_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,308|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_5219_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,308|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_58907_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,309|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_97055_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,310|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_56744_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,310|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_28795_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,311|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_11712_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,311|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_48102_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 1, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,312|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_28947_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,312|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_44303_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,313|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_48699_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,314|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_17682_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,314|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_64074_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,315|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47563_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,315|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_26149_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,316|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_38194_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 1, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,317|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_48692_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,317|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_540_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,318|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_95178_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,318|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_49343_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,319|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_67196_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,320|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_64026_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,320|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_28538_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,321|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_18959_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,321|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_26089_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,322|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_53982_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,322|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_48943_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,323|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_54612_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,324|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_70101_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,324|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_52551_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,325|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_46265_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,325|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_33419_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,326|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_74211_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,326|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_95063_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,327|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_23657_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,328|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37108_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,328|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_86011_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,329|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_64210_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,329|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_62340_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,330|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_43682_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,331|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_22356_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,331|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47933_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,332|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_89584_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,332|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_44546_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,333|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_80907_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,334|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_68286_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,334|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_90421_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,335|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_6485_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,335|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_60334_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,336|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_35180_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,336|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_17468_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,337|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_35379_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,338|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_22085_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,338|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_59555_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,339|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_33801_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,339|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_59134_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 2, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,340|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_45292_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,341|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_81411_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,341|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_34540_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,342|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_13316_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,342|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_32498_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,343|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_56449_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,345|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_64087_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,347|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_66174_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 2, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,347|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_32068_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,348|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_9084_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,349|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_69181_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,350|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_9170_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,350|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_21278_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,351|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_98253_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,352|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47685_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,352|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_38003_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,353|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_11616_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,353|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_67564_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,354|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_79487_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,354|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_79709_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,355|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_10596_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,356|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_85886_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,356|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_68125_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,357|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_4966_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,357|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_49901_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,358|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_13722_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,359|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_42911_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,359|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37701_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,360|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_974_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,360|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37771_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,361|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_38351_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,361|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_83850_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,362|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_96667_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,362|INFO|Worker-worker_4|worker|Worker 4 initialized for trtllm.moe
2025-10-04 00:44:06,363|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_58190_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,363|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_41326_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,364|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_89870_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,365|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47098_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,365|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_34782_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,365|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_55985_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,366|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_50871_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,366|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_99709_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,367|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_5015_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,367|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_83607_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,367|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_88459_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,368|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_49856_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,368|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_23352_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,368|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_20_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,368|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_94527_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,369|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_6349_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,369|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_36579_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,369|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_80948_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,370|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_50712_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,370|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_75643_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,370|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_16653_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,371|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_43043_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,371|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_44721_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 4, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,371|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_72087_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,371|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_9463_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,372|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_73240_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,372|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_16479_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,372|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_11580_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,373|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_38098_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 1, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,373|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_28664_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,373|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_39053_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 4, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,374|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_40501_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,374|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_54432_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,374|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_12461_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,375|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_67885_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,375|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_80886_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,375|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47219_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 1, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,375|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_17151_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,376|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_54133_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,376|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_58842_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,376|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_88810_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,377|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_77596_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,377|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_52932_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,377|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_9275_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,378|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_97857_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,378|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_12309_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,378|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_40532_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,378|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_94989_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,379|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_59210_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 1, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,379|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_20741_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,379|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_93251_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,379|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_63156_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,380|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_5662_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,380|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_22618_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,381|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_92675_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,381|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_8140_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,381|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_30086_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,381|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_37030_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,382|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_48368_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,382|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_91873_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,382|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_88966_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 1, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,383|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_76059_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,383|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_61335_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 1, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,383|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_86257_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,384|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_67937_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,384|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_24942_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,384|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_5827_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,384|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_18820_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,385|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_59787_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,385|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_93262_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,386|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_23667_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,386|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_59733_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,386|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_4890_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 1, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,386|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_96057_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,387|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_67506_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,387|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_28099_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,387|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_96118_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,388|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_10955_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,388|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_79221_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,388|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_65771_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,389|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_13061_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,389|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_13773_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,389|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47184_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,389|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_67468_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,390|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_26503_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 1, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,390|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_10256_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,391|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_88038_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 8, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,391|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_81365_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,391|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_30485_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,391|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_9188_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,392|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_8344_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 2, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,392|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_96388_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,393|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_78691_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 8, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,393|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_63908_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,393|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37099_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,393|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_30391_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,394|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_32873_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 2, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,394|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_45956_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 64, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,394|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_71342_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 64, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,395|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_92819_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,395|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_621_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,395|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_9628_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,396|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_22948_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,396|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_65019_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,396|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_84068_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,396|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_19343_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,397|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_80996_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,397|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_80525_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,397|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_47701_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 2, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,398|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_47248_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 64, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,398|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_32789_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 64, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,398|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_36652_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,399|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_82718_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,399|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_91812_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,399|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_15328_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,399|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_93669_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,400|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_1105_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,400|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_14490_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,401|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_5978_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,401|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_48042_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,401|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_18057_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 2, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,401|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_2731_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,402|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_89726_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 2, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,402|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_63246_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,402|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_89361_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,403|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_54231_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,403|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_18512_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,403|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_55566_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,404|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_31587_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,404|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_62798_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,404|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_90674_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 2, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,404|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_54815_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 64, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,405|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_35386_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 64, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,405|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_78539_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,406|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_58288_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,406|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_45446_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,406|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_3859_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,406|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_76086_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,407|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_8275_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,407|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_23073_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,407|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_93186_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,407|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_45737_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,408|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_1389_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 2, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,408|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_51910_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,409|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_39965_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 16, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,409|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_74539_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,409|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_68330_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 4, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,409|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_16221_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,410|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_94353_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 16, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,410|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_97727_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,410|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_52395_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 4, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,411|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_46322_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 128, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,411|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_71751_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 128, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,411|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_21435_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 64, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,412|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_60291_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 64, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,412|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_781_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,412|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_54263_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,412|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_58761_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,413|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_53879_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,413|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_75090_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,414|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_22819_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,414|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_83066_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,414|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_39746_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 4, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,414|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_86500_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 128, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,415|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37035_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 1, 128, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,415|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_10089_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 64, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,415|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_79237_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 64, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,415|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_80719_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,416|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_45287_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,416|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_47585_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,417|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_4009_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,417|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_51073_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,417|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37268_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,417|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_30427_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,418|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_65332_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 4, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,418|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_24620_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,418|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_38900_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 4, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,419|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_34806_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,419|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_90723_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,419|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_6955_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,420|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_39132_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,420|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_25714_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,420|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_86108_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 4, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,420|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_31_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 128, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,421|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_38922_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 1, 128, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,421|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_21147_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 64, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,422|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_49723_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 64, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,422|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_32363_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,422|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_31892_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,422|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_32319_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,423|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_62632_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,423|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_58616_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,423|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_37316_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,423|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_35810_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,424|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_14235_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 4, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,424|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_89037_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,425|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_58915_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 14336, 2, 8, 32, 8, False, 'MOE_Mixtral8x7B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,425|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_558_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,425|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_99235_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 16384, 2, 8, 32, 8, False, 'MOE_Mixtral8x22B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,425|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_30457_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 256, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,426|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_10640_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 1, 256, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,426|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_56483_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 128, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,426|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_68521_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 2, 128, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,426|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_4425_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 64, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,427|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_49830_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 4, 64, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,427|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_11804_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,428|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_9700_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 8, 32, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,428|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_5066_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,428|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_60008_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 16, 16, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,428|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_49729_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,429|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_78_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 256, 32, 8, False, 'DEEPSEEK_V3', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,429|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_99188_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 128, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,430|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_56697_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 2, 128, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,430|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_88860_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 64, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,430|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_19892_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 4, 64, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,430|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_22351_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,431|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_92336_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 8, 32, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,431|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_59167_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,431|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_22873_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 16, 16, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,432|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_65600_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,432|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_95700_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 4096, 1536, 8, 128, 32, 8, False, 'QWEN3_235B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,432|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_50071_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,433|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_88171_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 8, 32, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,433|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_34198_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,433|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_50946_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 16, 16, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,433|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_9966_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,434|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_4263_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 6144, 2560, 8, 160, 32, 8, False, 'QWEN3_480B', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,434|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_62943_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 128, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,434|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_41117_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 2, 128, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,435|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_34317_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 64, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,435|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_89735_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 4, 64, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,435|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_40631_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,436|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_99892_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 8, 32, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,436|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_66076_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,436|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_20526_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 16, 16, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,436|ERROR|Worker-worker_4|worker|Task trtllm.moe_run_moe_torch_74327_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.01] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,437|ERROR|Worker-worker_0|worker|Task trtllm.moe_run_moe_torch_72118_['float16', [1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 128, 160, 192, 256, 320, 384, 512, 768, 1024, 1536, 2048, 3072, 4096, 6144, 8192, 12288, 16384, 20480, 32768, 65536], 7168, 2048, 8, 384, 32, 8, False, 'KIMI_K2', 'moe_perf.txt', 'power_law', 1.2] failed: TypeError: create_moe() got an unexpected keyword argument 'swiglu_alpha'
2025-10-04 00:44:06,501|INFO|Worker-worker_6|worker|Worker 6 initialized for trtllm.moe
2025-10-04 00:44:06,653|INFO|Worker-worker_2|worker|Worker 2 initialized for trtllm.moe
2025-10-04 00:44:06,704|INFO|Worker-worker_1|worker|Worker 1 initialized for trtllm.moe
2025-10-04 00:44:06,709|INFO|Worker-worker_7|worker|Worker 7 initialized for trtllm.moe
2025-10-04 00:44:06,748|INFO|Worker-worker_5|worker|Worker 5 initialized for trtllm.moe
2025-10-04 00:44:06,935|INFO|Worker-worker_3|worker|Worker 3 initialized for trtllm.moe
2025-10-04 00:44:10,284|ERROR|root|parallel_run|trtllm.moe: Completed with 392 errors
2025-10-04 00:44:10,294|ERROR|root|parallel_run|Error details saved to all_20251004_000940/errors_trtllm.moe.json
2025-10-04 00:44:10,851|INFO|root|generate_collection_summary|============================================================
2025-10-04 00:44:10,851|INFO|root|generate_collection_summary|COLLECTION SUMMARY - trtllm v1.0.0
2025-10-04 00:44:10,851|INFO|root|generate_collection_summary|============================================================
2025-10-04 00:44:10,851|INFO|root|generate_collection_summary|Total errors: 10385
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|
Errors by module:
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|  trtllm.attention_context: 4936
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|  trtllm.attention_generation: 5026
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|  trtllm.mla_bmm_gen_post: 31
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|  trtllm.moe: 392
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|
Errors by type:
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|  AssertionError: 9926
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|  RuntimeError: 67
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|  TypeError: 392
2025-10-04 00:44:10,852|INFO|root|generate_collection_summary|
Detailed error report saved to: all_20251004_000940/collection_summary_trtllm.json
