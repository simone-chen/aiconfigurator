{
  "summary": {
    "backend": "trtllm",
    "version": "1.0.0",
    "timestamp": "2025-10-07T23:34:38.372646",
    "total_errors": 514,
    "errors_by_module": {
      "trtllm.attention_generation": 514
    },
    "errors_by_type": {
      "RuntimeError": 514
    }
  },
  "errors": [
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_76636_[32, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.339455"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_73173_[32, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.347524"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_15583_[32, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.352240"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_23189_[32, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.362664"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_34400_[32, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.367998"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_36448_[32, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.375588"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_80289_[32, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.380327"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_42119_[32, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.388357"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_66309_[32, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.395297"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_81343_[32, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.402925"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_38963_[32, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.412509"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_69048_[32, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.424357"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_92543_[1, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.430198"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_1888_[1, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.433358"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_40867_[1, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.436560"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_35967_[1, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.439765"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_458_[1, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.442987"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_68130_[1, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.446186"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_25270_[1, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.450454"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_41327_[1, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.453665"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_45466_[1, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.456984"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_90863_[1, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.461146"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_25915_[1, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.465450"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_59389_[1, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.468717"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_68283_[1, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.473099"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_65153_[1, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.481795"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_43095_[2, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.526513"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_16366_[2, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.532117"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_19323_[2, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.535789"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_66232_[2, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.539400"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_28357_[2, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.543006"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_21883_[2, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.548718"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_7743_[2, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.563021"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_105_[2, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.960846"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_4734_[64, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.240048"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_33573_[128, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.274842"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_53928_[128, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.302290"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_72726_[64, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.360403"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_65040_[512, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.422562"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_18269_[512, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.437208"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_534_[2, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.566649"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_8099_[4, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.971918"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_41587_[512, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.274446"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_10432_[512, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.309120"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_59562_[8, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.308751"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_1521_[1024, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.427141"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_42458_[16, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.429859"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_98758_[16, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.445041"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_91854_[2, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.612637"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_48833_[4, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.017304"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_95724_[512, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.306423"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_55799_[8, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.313867"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_43779_[8, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.312853"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_81335_[8, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.324157"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_2956_[16, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.433958"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_85216_[16, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.452084"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_83542_[2, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.619486"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_44057_[4, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.028680"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_47313_[8, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.312261"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_10030_[16, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.433957"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_56586_[8, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.318979"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_91944_[1024, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.390555"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_62483_[16, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.438256"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_79500_[32, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.458259"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_54904_[2, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.638151"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_65837_[4, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.038089"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_97373_[8, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.316916"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_60467_[16, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.439132"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_65485_[1024, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.382075"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_60652_[2048, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.534998"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_48799_[16, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.442094"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_19398_[32, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.464560"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_58241_[2, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.647476"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_99381_[4, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.046088"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_10740_[1024, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.379686"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_79148_[16, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.444494"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_27058_[2048, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.515498"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_5140_[4, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.543756"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_3579_[16, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.445864"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_89444_[32, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.469876"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_66121_[2, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.693818"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_81120_[4, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.054647"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_9235_[2048, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.510738"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_22903_[16, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.449155"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_37436_[64, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.528486"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_3769_[128, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.555915"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_33914_[16, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 4095, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.453086"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_10850_[32, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.476721"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_89349_[64, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.709346"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_20242_[128, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.093697"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_85427_[2, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.518198"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_57474_[16, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.458763"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_30303_[64, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.537774"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_42779_[128, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.569972"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_29992_[32, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.460085"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_1477_[32, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.489198"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_46086_[64, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.726409"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_59173_[128, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.107375"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_47940_[64, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.528408"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_2104_[32, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.466503"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_67408_[4, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.543400"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_38822_[256, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.591116"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_76018_[32, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.466455"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_54387_[1, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.495811"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_6973_[64, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.737416"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_83804_[128, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.132644"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_59962_[64, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.535215"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_67015_[32, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.471944"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_60027_[4, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.552686"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_1885_[512, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.627013"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_11919_[32, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.471840"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_90000_[1, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.499972"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_17423_[64, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.748179"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_55897_[128, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.150992"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_39124_[4, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.541335"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_60127_[32, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.481002"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_91738_[128, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.564690"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_22930_[1024, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.692439"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_75066_[2048, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.839474"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_52848_[32, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.480216"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_10314_[64, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.774198"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_53141_[256, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.183752"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_17392_[4, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.547053"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_649_[1, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.486093"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_72025_[256, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.581105"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_98962_[1, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.505769"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_80179_[256, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.861370"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_26484_[1, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.485168"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_22726_[64, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.786667"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_77768_[256, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.210975"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_41597_[128, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.558062"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_635_[1, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.489272"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_84408_[512, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.615323"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_19978_[1, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.493514"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_48774_[512, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.891270"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_11516_[1, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.489249"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_38933_[64, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.836889"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_97541_[256, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.234262"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_48771_[256, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.575661"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_11042_[2, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.510699"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_30133_[8, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.622577"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_97555_[1, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.496707"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_28033_[8, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.897428"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_60234_[1, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.494500"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_38490_[1, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.497721"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_14554_[256, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.603287"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_26610_[8, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.608969"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_86889_[256, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.257843"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_54262_[8, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.630824"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_94159_[1, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.499959"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_29493_[8, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.904418"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_24520_[1024, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.969263"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_32793_[64, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.854970"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_26715_[2, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.516088"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_74926_[8, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.613168"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_92978_[2048, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.766016"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_9537_[512, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.295790"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_16921_[1, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.504377"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_87865_[1, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.501028"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_57420_[16, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.976759"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_38248_[2, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.505194"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_16222_[64, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.876382"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_30889_[8, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.619507"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_13245_[1, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.776733"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_17483_[8, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.303635"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_80798_[2, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.508444"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_14501_[16, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.980897"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_98871_[16, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.985360"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_26222_[16, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.993265"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_11552_[2, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.509551"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_69147_[4, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.893662"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_15124_[2, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.780844"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_38706_[8, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.308788"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_88409_[2, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.511631"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_92888_[2, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.523042"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_78827_[32, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.999642"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_72791_[8, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.624004"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_61877_[2, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.513816"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_52722_[4, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.946455"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_78497_[2, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.785090"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_38307_[8, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.313172"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_10220_[2, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.515890"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_740_[64, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.532217"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_89741_[32, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.005094"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_57822_[1024, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.687291"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_76792_[2, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.518399"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_79403_[4, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:48.970372"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_32984_[2, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.789411"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_19031_[64, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.796621"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_73779_[8, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 8191, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.319545"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_68326_[4, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.537265"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_73874_[32, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.010442"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_53025_[2048, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.817182"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_24956_[64, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.529125"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_63519_[4, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.016132"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_53309_[2, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.522362"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_87351_[64, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.804065"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_55606_[1024, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.382416"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_4560_[4, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.543584"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_47252_[32, 1023, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1023, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.017551"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_18801_[128, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.831999"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_84699_[64, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.539432"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_54642_[4, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.026204"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_32874_[64, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.529694"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_89960_[64, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.816659"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_38640_[2048, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.515056"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_29982_[4, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.554047"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_63612_[1, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.022473"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_43688_[128, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.845955"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_75488_[4, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.546932"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_32749_[4, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 511, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.035525"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_22648_[64, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.543218"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_34355_[4, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.824789"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_87553_[128, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.569419"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_46187_[256, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.589829"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_94750_[2, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.524578"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_6772_[256, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.863834"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_19782_[128, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.558631"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_34490_[4, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 2047, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.044393"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_44352_[4, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 16383, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.055900"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_15945_[128, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.834711"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_58494_[1, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.026696"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_13652_[512, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.624058"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_94414_[1024, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.692356"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_81809_[64, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.533261"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_93368_[256, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.578690"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_59446_[128, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.092284"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_61678_[128, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.558111"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_28300_[128, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.851347"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_33951_[1, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.029891"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_9002_[512, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.894011"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_80624_[8, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.899146"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_77271_[2048, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.851300"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_90379_[512, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.615682"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_55216_[128, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 15, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.107338"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_53270_[256, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.575891"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_42711_[256, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.872824"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_38910_[1, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.034167"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_27820_[1024, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.960260"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_7330_[4, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.538470"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_86925_[512, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.887803"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_1906_[8, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.623860"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_10244_[128, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 127, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.137096"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_32748_[512, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.612492"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_52756_[512, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.908742"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_77090_[1, 4095, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 4095, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.039549"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_63745_[2048, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.092501"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_90768_[4, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.543812"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_85605_[8, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.892684"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_75471_[1024, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.696073"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_43715_[128, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.155528"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_95372_[8, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.619453"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_6924_[2048, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.037422"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_22132_[2, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.045840"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_14310_[128, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.107264"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_55869_[128, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.557532"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_59704_[8, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.897979"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_29408_[16, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.707516"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_70633_[256, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.183335"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_64432_[8, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.623796"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_70652_[1, 16383, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 16383, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.045781"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_12878_[2, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.050087"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_15420_[256, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.124393"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_33639_[512, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.158107"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_6833_[1024, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.962263"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_65280_[16, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.712586"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_28205_[256, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 7, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.211548"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_5452_[8, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 16383, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.637919"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_30613_[2, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.049502"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_60041_[2, 8191, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 8191, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.054787"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_73000_[128, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.577140"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_74621_[8, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.168988"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_51964_[2048, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.118260"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_29499_[16, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 511, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.717090"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_63970_[256, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 63, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.233799"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_46251_[2048, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.768246"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_42631_[2, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.052775"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_39707_[64, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.062814"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_82708_[512, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 3, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.613683"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_9188_[8, 16383, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 16383, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.177952"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_78770_[256, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.146324"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_70907_[16, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.725275"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_59967_[256, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 255, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.257068"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_68064_[1, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.778273"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_54101_[64, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.071546"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_26735_[64, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.059917"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_14813_[8, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.621942"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_13475_[2048, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.307292"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_69922_[8, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.153339"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_20059_[32, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.732505"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_78192_[512, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.296792"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_2860_[2, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.782193"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_19702_[4, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.075561"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_82280_[64, 63, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 63, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.066310"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_12018_[8, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.631004"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_55272_[1, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.316694"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_91506_[8, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.159055"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_12054_[32, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.739920"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_32276_[8, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 3, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.304747"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_9721_[2, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.785431"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_54676_[4, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.079797"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_42314_[64, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.078888"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_85217_[1024, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.694179"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_44467_[2, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.320768"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_83686_[8, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.169538"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_89020_[32, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.745442"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_17326_[8, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 31, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.309951"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_21711_[2, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.789900"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_20780_[4, 1023, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 1023, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.085205"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_57093_[4, 511, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 511, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.084552"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_45614_[16, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.706681"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_29185_[2, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.325007"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_64402_[1024, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.234676"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_5481_[32, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.753891"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_62963_[8, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1023, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.314265"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_55186_[64, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.797005"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_89040_[128, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.095377"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_34605_[4, 16383, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 16383, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.091501"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_43768_[16, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.711737"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_45647_[2, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.329391"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_26469_[16, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.249718"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_48858_[1, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.759515"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_78743_[1024, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.374483"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_3552_[64, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.804570"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_18946_[128, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.108105"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_51191_[128, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.104550"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_67560_[16, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 127, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.716025"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_70273_[64, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.336552"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_9187_[16, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.255791"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_45191_[1, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.764762"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_94304_[2048, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 1, 64, 64, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.512968"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_10902_[4, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.808832"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_57405_[256, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.124783"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_24401_[256, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.121064"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_65737_[64, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.343089"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_3879_[16, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1023, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.720725"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_25848_[16, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.730350"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_43844_[2, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 4095, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.522799"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_46108_[1, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.769016"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_48505_[4, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.813076"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_4541_[512, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.158248"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_50023_[256, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.143902"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_16864_[4, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.347339"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_4082_[32, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.739117"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_68378_[16, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 255, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.259960"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_89366_[64, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.532149"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_62672_[1, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.776522"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_53876_[4, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.817366"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_42025_[8, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.165055"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_86164_[512, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 127, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.179503"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_58900_[4, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.351580"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_72548_[32, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.744349"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_11563_[4, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 1, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.536309"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_86113_[16, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.266277"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_54392_[2, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.780807"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_18513_[4, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.824586"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_17637_[8, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 2047, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.170788"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_78639_[2048, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.309007"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_35229_[4, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.355986"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_76630_[32, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.750094"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_6313_[4, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 31, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.541614"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_54503_[32, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.272204"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_1084_[2, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.785066"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_75111_[128, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.835239"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_5102_[1024, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.234852"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_71335_[1, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.319363"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_70932_[4, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.360301"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_66809_[32, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.760896"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_57543_[4, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.549264"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_78998_[32, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.277461"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_8427_[2, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.789481"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_12045_[256, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.853010"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_9604_[2048, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 31, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.373666"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_51786_[2, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.323046"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_21418_[128, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.373599"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_51859_[1, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.766121"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_97579_[128, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.559707"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_7736_[32, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.283113"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_8498_[64, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.797078"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_79381_[256, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.874787"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_38460_[128, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.393910"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_49780_[2, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1023, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.326279"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_50192_[128, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.387229"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_28596_[1, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.772418"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_44627_[256, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 15, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.578572"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_81980_[32, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.289961"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_34295_[64, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.804818"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_78314_[8, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.880868"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_22667_[256, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.415791"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_92659_[2, 8191, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 8191, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.329874"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_15123_[256, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.404488"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_76602_[1, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 4095, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.777856"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_19517_[512, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.614155"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_72638_[32, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.301927"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_18718_[4, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.809509"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_58558_[8, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.885084"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_64308_[8, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.420819"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_17965_[64, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.336699"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_17781_[512, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.435987"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_12921_[2, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.782039"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_28609_[8, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.622789"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_27877_[1, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.307772"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_90849_[4, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.813865"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_66244_[8, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.424995"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_63893_[8, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.889333"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_73136_[64, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.343497"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_32720_[1024, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.497949"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_24176_[2, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.786300"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_80116_[8, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 8191, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.631975"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_62056_[1, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.312966"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_61750_[4, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.818166"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_34713_[8, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.429228"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_24068_[8, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.893599"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_77250_[4, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.347505"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_82298_[2048, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.631529"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_92005_[4, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.351730"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_43503_[128, 255, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 255, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.646909"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_61763_[1024, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.696993"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_22320_[4, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.827507"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_26989_[8, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.433544"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_26029_[8, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.897981"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_15417_[2, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.790401"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_42026_[4, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 255, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.356101"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_99360_[1, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.318437"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_70535_[256, 63, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 63, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.663929"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_88913_[16, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 7, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.707947"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_13728_[128, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.839604"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_43284_[8, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.438702"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_64793_[1024, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.959245"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_28255_[64, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.798035"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_76601_[4, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.360775"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_56809_[2, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.322558"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_55699_[512, 63, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 63, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.695404"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_59040_[16, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 63, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.712219"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_66958_[256, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.860746"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_11365_[1024, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.501733"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_21134_[2048, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.088029"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_27913_[64, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 511, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.806297"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_68380_[128, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 7, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.373907"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_86803_[2, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.326939"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_90878_[8, 2047, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 2047, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.702888"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_17544_[16, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 255, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.716614"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_64192_[512, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.893430"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_4852_[16, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 3, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.508641"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_65412_[128, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.104935"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_99360_[4, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.810805"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_2535_[128, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.388858"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_77324_[64, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.334449"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_43750_[1024, 15, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 15, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.765060"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_11982_[16, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 2047, 64, 64, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.723950"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_44476_[8, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.899570"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_80010_[16, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 15, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.512814"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_15255_[256, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.121580"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_55977_[4, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.815041"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_20778_[256, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.407854"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_45797_[64, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.342872"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_77450_[512, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.443876"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_88666_[64, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 2047, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.356839"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_24354_[2048, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 1, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.573678"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_18193_[32, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.731188"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_30530_[512, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 1, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.154765"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_70943_[4, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.820576"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_912_[16, 1, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.773521"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_930_[1024, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.962710"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_29323_[16, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 63, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.517051"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_75714_[2, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.580799"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_83651_[4, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 16383, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.365553"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_38233_[32, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.739573"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_37300_[8, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.164996"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_88638_[128, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.831851"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_91215_[16, 7, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 7, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.778715"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_4503_[16, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.971853"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_87179_[16, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 511, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.521527"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_83395_[2, 127, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 127, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.584854"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_53739_[128, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 127, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.380135"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_95673_[32, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.744991"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_55575_[8, 1023, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 1023, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.170500"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_89389_[128, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[128, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.843331"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_90831_[16, 63, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 63, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.782971"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_2572_[16, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.976957"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_8272_[16, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 4095, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.528429"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_86548_[2, 1023, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 1023, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.589158"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_1446_[256, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.400785"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_19102_[32, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 2047, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.754154"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_67988_[1024, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1024, 3, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.231632"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_29205_[256, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[256, 31, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.862031"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_75561_[16, 511, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 511, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.787447"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_38848_[16, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 127, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.981281"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_23294_[32, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.534768"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_41683_[2, 16383, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2, 16383, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.595315"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 6,
      "task_id": "trtllm.attention_generation_run_attention_torch_19816_[512, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 31, 40, 40, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.432724"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_74081_[1, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 3, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.759188"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 0,
      "task_id": "trtllm.attention_generation_run_attention_torch_62998_[2048, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[2048, 7, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.362405"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_6047_[512, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[512, 15, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.892687"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_80445_[16, 4095, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 4095, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.795332"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_74179_[16, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.987151"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_5398_[32, 15, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 15, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.540034"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_55581_[64, 15, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 15, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.602713"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_70031_[16, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[16, 8191, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.996666"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_42664_[32, 127, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 127, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.545427"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_65025_[64, 511, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[64, 511, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.612360"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_29550_[1, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 7, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.764409"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_12321_[32, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 3, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.802785"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_95177_[1, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 63, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.768660"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_50563_[32, 1023, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 1023, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.552645"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_66562_[1, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1023, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.776123"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_37287_[4, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.617757"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_79655_[1, 1, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 1, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.557579"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 3,
      "task_id": "trtllm.attention_generation_run_attention_torch_58359_[1, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 16383, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.780807"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 4,
      "task_id": "trtllm.attention_generation_run_attention_torch_45868_[4, 127, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[4, 127, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.621986"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 7,
      "task_id": "trtllm.attention_generation_run_attention_torch_26279_[32, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 31, 32, 32, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.808074"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 2,
      "task_id": "trtllm.attention_generation_run_attention_torch_75730_[32, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[32, 15, 48, 48, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.004566"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 1,
      "task_id": "trtllm.attention_generation_run_attention_torch_96228_[8, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[8, 255, 48, 48, 64, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:49.897701"
    },
    {
      "module": "trtllm.attention_generation",
      "device_id": 5,
      "task_id": "trtllm.attention_generation_run_attention_torch_31078_[1, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "task_params": "[1, 3, 40, 40, 128, 0, False, False, False, 'generation_attention_perf.txt']",
      "error_type": "RuntimeError",
      "error_message": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
      "traceback": "Traceback (most recent call last):\n  File \"/workspace/aiconfigurator/collector/collect.py\", line 120, in worker\n    result = func(*task, device)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/workspace/aiconfigurator/collector/trtllm/collect_attn.py\", line 141, in run_attention_torch\n    attn_metadata = TrtllmAttentionMetadata(max_num_requests=batch_size,\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 11, in __init__\n  File \"/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/attention_backend/interface.py\", line 187, in seq_lens\n    self._seq_lens = self._seq_lens.pin_memory()\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py\", line 104, in __torch_function__\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned\n",
      "timestamp": "2025-10-07T23:32:50.560748"
    }
  ]
}